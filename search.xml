<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux开机启动的多种实现方式]]></title>
    <url>%2F2019%2F04%2F23%2F00060_Linux%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8%E7%9A%84%E5%A4%9A%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[开机启动是运维自动化的重要组成部分。 /etc/rc.local 可将开机启动命令追加到/etc/rc.local中 12# readlink /etc/rc.localrc.d/rc.local // /etc/rc.d/rc.local chkconfig123456# readlink /etc/init.drc.d/init.d // /etc/rc.d/init.d/chkconfig --add servicename # 使服务会被在/etc/rc.d/rcN.d中赋予K/S入口chkconfig --level 35 servicename on 或 sudo update-rc.d servicename defaults 95chkconfig --list 服务脚本必须存放在/etc/ini.d/目录下 /etc/ini.d/下的脚本最开始必须包含以下三行 123#! /bin/sh# chkconfig: - 58 74 # 分别代表运行级别，启动优先权，关闭优先权，此行代码必须# description: 将脚本放在/etc/profile.d/下 登陆自动执行(/etc/profile.d/)，不仅仅是开机自动执行。 必须是.sh后缀的脚本文件 systemd1234567systemctl list-unit-files --type=service | grep enabled # 查看允许开机启动的服务进程systemctl list -units --type=service # 查看所有已启动的服务systemctl mask daemon.service # 在任何情况下系统启动时都不启动该进程systemctl enable daemon.service # 设置开机启动systemctl disable daemon.service # 禁止开机启动systemctl is-enabled daemon.service # 确认服务是否开机启动ll /etc/systemd/system/multi-user.target.wants/ # 查看所有开启启动的服务 crontab1@reboot root ( sleep 30; sh /path/to/script.sh ) # 经验证，cron配置中支持小括号 cron支持的关键字12345678@reboot at startup@yearly once a year@annually ( == @yearly)@monthly once a month@weekly once a week@daily once a day@midnight ( == @daily)@hourly once an hour]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>chkconfig</tag>
        <tag>systemd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux环境中精确控制普通用户的sudo权限]]></title>
    <url>%2F2019%2F02%2F07%2F00059_Linux%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%B2%BE%E7%A1%AE%E6%8E%A7%E5%88%B6%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%E7%9A%84sudo%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[精准施控才能游刃有余。 需求背景 在持续集成的实践中,为了保障生产环境安全可靠避免意外事故的发生。需要限制用户的操作权限，又要满足构建需要，因此需要对持续集成过程中的操作命令权限进行精准控制。实现最小权限开放，最大灵活性保障。 sudo配置 配置文件名不能包含.后缀(文件名中不能包含.)，否则配置不生效 生成配置 1234567cat &gt; /etc/sudoers.d/jenkins_deploy &lt;&lt; EOFHost_Alias JENKINS_SERVERS = $(echo -n $(ip addr show dev eth0 | awk &apos;/inet/ &#123;sub(/\//, &quot; &quot;); print $2&#125;&apos;|head -1)), 127.0.0.1Cmnd_Alias JENKINS_CMD = $(which rsync), $(which ln), $(which unlink), $(which readlink), $(which test), $(which mv), $(which mkdir)Defaults:jenkins !requirettyDefaults!JENKINS_CMD !syslogjenkins JENKINS_SERVERS=(root) NOPASSWD: JENKINS_CMDEOF 配置范例 12345Host_Alias JENKINS_SERVERS = 10.0.0.1, 127.0.0.1Cmnd_Alias JENKINS_CMD = /usr/bin/rsync, /bin/ln, /bin/unlink, /usr/bin/readlink, /usr/bin/test, /bin/mv, /bin/mkdirDefaults:jenkins !requirettyDefaults!JENKINS_CMD !syslogjenkins JENKINS_SERVERS=(root) NOPASSWD: JENKINS_CMD 主机别名定义 sudo 用户有权在哪个服务器（或特定范围内的服务器）上发出命令。在主机别名中，可以使用 DNS 名称或 IP 地址，或者指定整个网络范围（例如 172.17.12.0/24）。要限制访问范围，应该仅指定群集节点的主机名。别名必须全部而且只能使用大写英文字母的组合 centos 5 的默认版本sudo-1.7.2p1-14.el5_8.4 不支持JENKINS_SERVERS中使用网段掩码 ALL ALL=(ALL) ALL 配置字段解释12345ALL ALL=(ALL) ALLThe first ALL is the users allowedThe second one is the hostsThe third one is the user as you are running the commandThe last one is the commands allowed 参考文档 What does “ALL ALL=(ALL) ALL” mean in sudoers? sudo)]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>权限管理</tag>
        <tag>sudoers</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache No space left on device]]></title>
    <url>%2F2019%2F01%2F31%2F00058-Apache-No-space-left-on-device%2F</url>
    <content type="text"><![CDATA[Inter-Process Communication，进程间通信 报错信息1234567891011121314151617181920212223242526272829303132cat /var/logs/httpd/error_log |grep -i device[Wed Nov 21 20:15:01 2018] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Wed Nov 21 20:15:01 2018] [notice] sohudb_post_config begin[Wed Nov 21 20:15:01 2018] [notice] create_server_temp_conf begin[Wed Nov 21 20:15:01 2018] [notice] create_server_temp_conf end[Wed Nov 21 20:15:01 2018] [notice] Digest: generating secret for digest authentication ...[Wed Nov 21 20:15:01 2018] [notice] Digest: done[Wed Nov 21 20:15:01 2018] [notice] sohudb_post_config begin[Wed Nov 21 20:15:01 2018] [notice] cp_create: ok[Wed Nov 21 20:15:01 2018] [notice] qdb_cp_create: ok[Wed Nov 21 20:15:01 2018] [notice] socket_cp_create: ok[Wed Nov 21 20:15:01 2018] [notice] schat_cp_create: ok[Wed Nov 21 20:15:01 2018] [notice] set_mc_host_sc end[Wed Nov 21 20:15:01 2018] [notice] cp_initialize: begin 23014[Wed Nov 21 20:15:01 2018] [notice] cp_initialize: for loop i=0, server_no:1[Wed Nov 21 20:15:01 2018] [notice] cp_initialize: ok[Wed Nov 21 20:15:01 2018] [notice] set_qdb_host_sc end[Wed Nov 21 20:15:01 2018] [notice] qdb_cp_initialize: begin 23014[Wed Nov 21 20:15:01 2018] [notice] qdb_cp_initialize: for loop i=0, server_no:1[Wed Nov 21 20:15:01 2018] [notice] qdb_cp_initialize: ok[Wed Nov 21 20:15:01 2018] [notice] set_socket_host_sc end[Wed Nov 21 20:15:01 2018] [notice] socket_cp_initialize: begin 23014[Wed Nov 21 20:15:01 2018] [notice] socket_cp_initialize: for loop i=0, server_no:1[Wed Nov 21 20:15:01 2018] [notice] socket_cp_initialize: ok[Wed Nov 21 20:15:01 2018] [notice] set_schat_host_sc end[Wed Nov 21 20:15:01 2018] [notice] schat_cp_initialize: begin 23014[Wed Nov 21 20:15:01 2018] [notice] schat_cp_initialize: for loop i=0, server_no:1[Wed Nov 21 20:15:01 2018] [notice] schat_cp_initialize: for loop i=0, server_no:1,0,900,1000[Wed Nov 21 20:15:01 2018] [notice] schat_cp_initialize: ok[Wed Nov 21 20:15:01 2018] [notice] sohudb_post_config end[Wed Nov 21 20:15:01 2018] [warn] pid file /etc/httpd/run/httpd.pid overwritten -- Unclean shutdown of previous Apache run?[Wed Nov 21 20:15:01 2018] [emerg] (28)No space left on device: Couldn&apos;t create accept lock (/etc/httpd/logs/accept.lock.23014) (5) 1234567891011121314151617181920212223242526272829303132333435# ipcs -s------ Semaphore Arrays --------key semid owner perms nsems0x000000a7 0 root 600 10x00000000 65273857 apache 600 10x00000000 65372162 apache 600 10x00000000 65470467 apache 600 10x00000000 65568772 apache 600 10x00000000 65667077 apache 600 10x00000000 65765382 apache 600 10x00000000 65863687 apache 600 10x00000000 65961992 apache 600 10x00000000 66060297 apache 600 10x00000000 66158602 apache 600 10x00000000 66256907 apache 600 10x00000000 66355212 apache 600 10x00000000 66453517 apache 600 10x00000000 66551822 apache 600 10x00000000 66650127 apache 600 10x00000000 66748432 apache 600 10x00000000 66846737 apache 600 10x00000000 66945042 apache 600 10x00000000 67043347 apache 600 10x00000000 67141652 apache 600 10x00000000 67239957 apache 600 10x00000000 67338262 apache 600 10x00000000 67436567 apache 600 10x00000000 67534872 apache 600 10x00000000 67633177 apache 600 10x00000000 67731482 apache 600 10x00000000 67829787 apache 600 10x00000000 67928092 apache 600 10x00000000 68026397 apache 600 10x00000000 68124702 apache 600 1 12345678910111213141516171819# ipcs -l------ Shared Memory Limits --------max number of segments = 4096max seg size (kbytes) = 67108864max total shared memory (kbytes) = 17179869184min seg size (bytes) = 1------ Semaphore Limits --------max number of arrays = 512max semaphores per array = 25032000max semaphores system wide = 32max ops per semop call = 512semaphore max value = 32767------ Messages: Limits --------max queues system wide = 16max size of message (bytes) = 65536default max size of queue (bytes) = 65536 12345678910111213141516171819# ipcs -a------ Shared Memory Segments --------key shmid owner perms bytes nattch status0x74008327 3440640 root 600 4 00x740082fd 4128769 root 600 4 00x00000000 4489218 root 644 80 20x740082fc 4096003 root 600 4 00x00000000 4521988 root 644 16384 20x00000000 4554757 root 644 280 2------ Semaphore Arrays --------key semid owner perms nsems0x000000a7 0 root 600 10x00000000 170524673 apache 600 10x00000000 170557442 apache 600 1------ Message Queues --------key msqid owner perms used-bytes messages 处理方案12345678# for i in $(/usr/bin/ipcs -s | awk &apos;/apache/ &#123;print $2&#125;&apos;); do /usr/bin/ipcrm -s $i; done# ipcs -s------ Semaphore Arrays --------key semid owner perms nsems0x000000a7 0 root 600 10x00000000 170524673 apache 600 10x00000000 170557442 apache 600 1 linux/unix下的进程间两类通信方式基于文件的IPC 基于普通文件的IPC 基于管道文件的IPC 普通管道 匿名管道 匿名管道只能使用在父子进程之间 基于socket文件的IPC 对等模型 对等模型主要用于udp编程 C/S模型 C/S模型主要用于TCP编程 基于内存的IPC 基于共享内存的IPC， 基于共享队列的IPC， 基于信号量的IPC。 内核内存的工具（ipcs） ipcs命令往标准输出写入一些关于活动进程间通信设施的信息. ipcs可以指定查看的具体信息， 如ipcs -m 查看共享内存， -q：查看共享队列， ipcs -s查看共享信号量， 以上3中都不指定时则是查看共享内存、共享队列和共享信号量 参考文档 Apache: No space left on device: Couldn’t create accept lock ipcs命令详解]]></content>
      <categories>
        <category>IPC</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>httpd</tag>
        <tag>IPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用开发的12要素]]></title>
    <url>%2F2019%2F01%2F25%2F00057_%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E7%9A%8412%E8%A6%81%E7%B4%A0%2F</url>
    <content type="text"><![CDATA[12-Factor 为构建 SaaS 应用提供方法论。 基准代码 一份基准代码，多份部署 依赖 显式声明依赖关系 配置 在环境中存储配置 后端服务 把后端服务当作附加资源 构建，发布，运行 严格分离构建和运行 进程 以一个或多个无状态进程运行应用 端口绑定 通过端口绑定提供服务 并发 通过进程模型进行扩展 易处理 快速启动和优雅终止可最大化健壮性 开发环境与线上环境等价 尽可能的保持开发，预发布，线上环境相同 日志 把日志当作事件流 管理进程 后台管理任务当作一次性进程运行 转载自 THE TWELVE-FACTOR APP]]></content>
      <categories>
        <category>12factor</category>
      </categories>
      <tags>
        <tag>12factor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git 常用命令]]></title>
    <url>%2F2018%2F12%2F28%2F00056_git-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Git 是 Linus Torvalds为了帮助管理Linux内核开发而开发的一个开放源码的版本控制软件。 列出当前配置 1git config --list 列出repository配置 1git config --local --list 列出全局配置 1git config --global --list 列出系统配置 1git config --system --list 配置用户名 1git config --global user.name &quot;your name&quot; 配置用户邮箱 1git config --global user.email &quot;youremail@github.com&quot; 配置git命令输出为彩色 1git config --global color.ui auto 查看当前工作区的所有文件的状态 1git status 查看提交历史： 1git log 参数-p展开每次提交的内容差异，如-2显示最近的两次更新 1git log -p -2; 提交工作区所有文件到暂存区 1git add . 删除工作区文件并且也从暂存区删除对应文件的记录 1git rm &lt;file1&gt; &lt;file2&gt; 比较工作区中当前文件和暂存区之间的差异 1git diff &lt;file-name&gt; 隐藏当前变更 1git stash 查看当前所有的储藏 1git stash list 应用最新的储藏 1git stash apply 将暂存区中的文件提交到本地仓库 1git commit -m &quot;commit_info&quot; 将所有已经使用git管理过的文件暂存并提交,相当于执行git add和git commit 1git commit -a -m &quot;commit_info&quot; 撤销上一次提交 1git commit --amend 比较暂存区与上一版本的差异 1git diff --cached 指定文件在暂存区和本地仓库的不同 1git diff &lt;file-name&gt; --cached 列出现在所有的标签 1git tag 使用特定的搜索模式列出符合条件的标签 1git tag -l &quot;v1.*&quot; 创建一个含附注类型的标签，加-a参数 1git tag -a v1.4 -m &quot;my version 1.4&quot; 使用git show命令查看相应标签的版本信息 1git show v2.0 将标签推送到远程仓库中 12git push origineg: git push origin v2.0 将本地所有的标签全部推送到远程仓库中： 1git push origin --tags 创建分支 1git branch &lt;branch name&gt; 切换分支 1git checkout &lt;branch name&gt; 创建并切换到分支 1git checkout -b &lt;new branch name&gt; 删除分支 1git branch -d &lt;branch name&gt; 将当前分支与指定分支进行合并 1git merge &lt;another branch name&gt; 显示本地仓库的所有分支 1git branch 显示各个分支最新一次提交对象的信息 1git branch -v 查看哪些分支已经合并到了当前分支 1git branch --merged 查看哪些分支还没有合并到当前分支 1git branch --no-merged 把远程分支合并到当前分支 123git merge &lt;remote-name&gt;/&lt;branch name&gt;eg:git merge origin/devel 在远程分支的基础上创建新的本地分支(跟踪分支) 123git checkout -b &lt;branch name&gt; &lt;remote-name&gt;/&lt;branch name&gt;eg:git checkout -b devel orgin/devel 查看本地仓库关联的远程仓库，-v参数会显示远程仓库的url地址 12git remotegit remote -v 添加远程仓库 123git remote add &lt;remote-name&gt; &lt;url&gt;eg:git remote add blog https://github.com/blog/blog.git 从远程仓库中拉取更新 12git fetch &lt;remote-name&gt;git fetch origin git fetch 只会讲远端数据拉到本地仓库，并不会自动合并到当前工作分支，需要人为合并，如果设置了某个分支关联到远程仓库的某个分支可以使用git pull来拉取远程分支的数据自动合并到当前分支； 将本地仓库分支推送到远程仓库 12git push &lt;remote name&gt; &lt;branch name&gt;git push origin master 将本地分支推送到远程仓库不同名分支 1git push &lt;remote name&gt; &lt;local branch&gt;:&lt;remote branch&gt; 删除远程分支(本地内容为空) 12git push &lt;remote name&gt; :&lt;remote branch&gt;git push origin 查看远程仓库的详细信息 1git remote show origin 修改远程仓库在本地的简称 12git remote rename &lt;old name&gt; &lt;new name&gt;git remote rename origin ori 移除远程仓库 1git remote rm &lt;remote name&gt; 常见报错处理 报错内容 12345678910fatal: unable to access &apos;https://github.com/xxxx/xxxx.github.io.git/&apos;: SSL certificate problem: self signed certificate in certificate chainFATAL Something&apos;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.htmlError: fatal: unable to access &apos;https://github.com/xxxx/xxxx.github.io.git/&apos;: SSL certificate problem: self signed certificate in certificate chain at ChildProcess.&lt;anonymous&gt; (H:\hexo-Blog\node_modules\hexo-util\lib\spawn.js:37:17) at emitTwo (events.js:126:13) at ChildProcess.emit (events.js:214:7) at ChildProcess.cp.emit (H:\hexo-Blog\node_modules\cross-spawn\lib\enoent.js:40:29) at maybeClose (internal/child_process.js:925:16) at Process.ChildProcess._handle.onexit (internal/child_process.js:209:5) 解决方法1git config --global http.sslVerify false 报错内容 12Cloning into &apos;jplot&apos;...fatal: unable to access &apos;https://github.com/rs/jplot.git/&apos;: Peer certificate cannot be authenticated with known CA certificates 解决方法1git config --global http.sslVerify false 参考 learn git branching git-fast-version-control git - 简易指南 githowto]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>版本控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux OOM Killer 保护机制]]></title>
    <url>%2F2018%2F12%2F25%2F00055_Linux-OOM-Killer-%E4%BF%9D%E6%8A%A4%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[OOM killer（Out Of Memory killer） linux下允许程序申请比系统可用内存更多的内存，这个特性叫Overcommit（过度分配）。在系统内存耗尽的情况下，OOM killer机制选择性的干掉一些进程以求释放一些内存。默认具体的记录日志是在/var/log/messages中。 参数配置 参数/proc/sys/vm/overcommit_memory可以控制进程对内存过量使用的应对策略 123overcommit_memory=0，这是缺省值，表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。overcommit_memory=1，内核会永远认为有充足的内存可用，进程申请内存时总是允许。overcommit_memory=2，表示系统所能分配的内存不会超过swap+RAM*系数（/proc/sys/vm/overcommit_ratio，默认50%，可以调整），如果这么多资源已经用光，那么后面任何尝试申请内存的行为都会返回错误，这通常意味着此时没法运行任何新程序。 内核决策依据 /proc/[pid]/oom_adj，该pid进程被oom killer杀掉的权重，一般介于 [-17,15]（具体具体权重的范围需要查看内核确认）之间，越高的权重，意味着更可能被oom killer选中，-17表示禁止被kill掉。 /proc/[pid]/oom_score，当前该pid进程的被kill的分数，越高的分数意味着越可能被kill，这个数值是根据oom_adj运算（2ⁿ，n就是oom_adj的值）后的结果，本身oom_score是不能修改值。 两种进程保护措施 修改权重 1echo -17 &gt; /proc/[PID]/oom_adj（输入-17，禁止被OOM机制处理） 开启OOM较为的保险机制 12echo “vm.panic_on_oom=2” &gt;&gt; /etc/sysctl.confsystcl -p 参考https://www.linuxba.com/archives/7744]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>OOM</tag>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux防火墙之iptables]]></title>
    <url>%2F2018%2F12%2F08%2F00054_Linux%E9%98%B2%E7%81%AB%E5%A2%99%E4%B9%8Biptables%2F</url>
    <content type="text"><![CDATA[iptables是Linux防火墙的管理工具，位于/sbin/iptables。真正实现防火墙功能的是位于内核空间的netfilter，它是Linux内核中实现包过滤的内部结构。 过滤 IPv4 数据包的代码已经内置于内核中，并且按照不同的目的被组织成表的集合。表由一组预先定义的链组成，链包含遍历顺序规则。每一条规则包含一个谓词的潜在匹配和相应的动作(称为目标)，如果谓词为真，该动作会被执行。也就是说条件匹配。iptables 是用户工具，允许用户使用链和规则。 iptables命令简介 iptables [-t 表名: filter/nat/mangle/raw] 命令选项 [链名: PREROUTING/INPUT/OUTPUT/FORWARD/POSTROUTING] [条件匹配] [-j 目标动作或跳转: ACCEPT/DROP/REJECT/LOG/REDIRECT/SNAT/DNAT] 常用的命令选项 12345678910111213141516171819202122-t：指定要操纵的表(四个表)；-A：向规则链中添加条目；-D：从规则链中删除条目；-i：向规则链中插入条目；-R：替换规则链中的条目；-L：显示规则链中已有的条目；-F：清楚规则链中已有的条目；-Z：清空规则链中的数据包计算器和字节计数器；-N：创建新的用户自定义规则链；-P：定义规则链中的默认目标；-h：显示帮助信息；-p：指定要匹配的数据包协议类型；-s：指定要匹配的数据包源；-i -in-interface 进入的网络接口-o --out-interface 输出的网络接口-m state 当与连接跟踪结合使用时，允许访问包的连接跟踪状态。--state state state是一个逗号分割的匹配连接状态列表。 INVALID 表示包是未知连接， ESTABLISHED 表示是双向传送的连接， NEW 表示包 为新的连接，否则是非双向传送的， RELATED 表示包由新连接开始，但是和一个已存在的连接在一起，如FTP数据传送，或者一个ICMP错误。 常用的条件匹配： 123456789101112131、状态匹配：-m state --state 连接状态NEW：与任何连接无关的ESTABLISHED：响应请求或已建立连接的RELATED：与已有连接有相关性的，如FTP数据连接2、MAC地址匹配：-m mac --mac-source MAC地址eg：iptables -A INPUT -m mac --mac-source f0:1b:12:12:22:4f -j DROP3、IP范围匹配：-m iprange --src-range IP范围eg：iptables -A FORWARD -p tcp -m iprange --src-range 192.168.0.1-192.168.0.10 -j ACCEPT4、多端口匹配：-m multiport --sports 源端口列表 和 -m multiport --sports 目的端口列表eg：iptables -A INPUT -p tcp -m multiport --dport 11,29,116,121 -j ACCEPT iptables基础操作 以下内容基于centos6系统环境。 服务安装 1yum -y install iptables 保存iptables到文件 1234iptables-save &gt; ~/iptables.rules或/etc/rc.d/init.d/iptables save 默认将规则写入/etc/sysconfig/iptables重启service iptables restart生效 从文件中还原iptables规则 1iptables-restore &lt; ~/iptables.rules 监控iptables 查看规则命中的次数 1iptables -L -v -n --line-numbers 删除不必要的规则 1iptables -nvL | grep -v &quot;0 0&quot; 监控iptables活动 1watch --interval=5 &apos;iptables -nvL | grep -v &quot;0 0&quot;&apos; 使用FWLogwatch分析iptables日志生成报告 清空所有默认规则 1iptables -F 清空所有自定义规则 1iptables -X 所有计数器归0 1iptables -Z iptables应用实例基本规则 预设规则（默认为ACCEPT） 123iptables -P INPUT DROPiptables -P OUTPUT ACCEPTiptables -P FORWARD DROP 查看当前规则： 1iptables -nvL --line-number 追加规则 1iptables -A INPUT -s 10.1.1.1 -j DROP 插入规则 1iptables -I INPUT 3 -s 10.1.1.2 -j DROP 删除规则 123iptables -D INPUT -s 10.1.1.1 -j DROP按行号删iptables -D INPUT 1 修改规则 12将第2条规则改为ACCEPTiptables -R INPUT 3 -j ACCEPT 清空规则 1iptables -F 规则案例ACCEPT 放行ping 12iptables -A INPUT -p icmp -j ACCEPTiptables -A OUTPUT -p icmp -j ACCEPT 允许lookback 12345iptables -A INPUT -i lo -p all -j ACCEPTiptables -A OUTPUT -o lo -p all -j ACCEPT或iptables -A INPUT -i lo -j ACCEPTiptables -A OUTPUT -o lo -j ACCEPT 放行80端口 12iptables -A INPUT -p tcp --dport 80 -j ACCEPTiptables -A OUTPUT -p tcp --sport 80 -j ACCEPT //如果设置了iptables -P OUTPUT DROP，需要添加该条，否则远程无法连接 允许防火墙转发除ICMP协议以外的所有数据包 12iptables -A FORWARD -p ! icmp -j ACCEPT` 注：”!” 条件取反 允许某个特定网络 rsync 进入本机 12iptables -A INPUT -i eth0 -p tcp -s 192.168.1.0/24 --dport 873 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 873 -m state --state ESTABLISHED -j ACCEPT 仅允许来自指定网络的ssh连接请求 12iptables -A INPUT -i eth0 -p tcp -s 192.168.1.0/24 --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT 仅允许从本地发起到指定网络的SSH连接请求 12iptables -A OUTPUT -o eth0 -p tcp -d 192.168.1.0/24 --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A INPUT -i eth0 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT 允许转发来自192.168.1.0/24局域网段的DNS解析请求数据包。 12iptables -A FORWARD -s 192.168.1.0/24 -p udp --dport 53 -j ACCEPTiptables -A FORWARD -d 192.168.1.0/24 -p udp --sport 53 -j ACCEPT 允许本机开放从TCP端口1000-1024提供的应用服务。 12iptables -A INPUT -p tcp --dport 1000:1024 -j ACCEPTiptables -A OUTPUT -p tcp --sport 1000:1024 -j ACCEPT 使用Multiport放行多个端口 12iptables -A INPUT -p tcp -m multiport --dports 22,80,443 -j ACCEPTiptables -A OUTPUT -p tcp -m multiport --sports 22,80,443 -j ACCEPT 允许防火墙本机对外开放TCP端口20、21、25、110以及被动模式FTP端口1250-1280 1iptables -A INPUT -p tcp -m multiport --dport 20,21,25,110,1250:1280 -j ACCEPT 注意：这里用“-m multiport –dport”来指定多个目的端口 针对端口访问的过滤。下面表示除了192.168.1.1-192.168.1.10之间的ip能访问192.168.0.1机器的80端口以外，其他ip都不可以访问！ 1iptables -A INPUT -d 192.168.0.1 -p tcp --dport 80 -m iprange --src-range 192.168.1.1-192.168.1.10 -j ACCEPT 只允许管理员从192.168.1.0/24网段使用SSH远程登录防火墙主机。 12iptables -A INPUT -p tcp --dport 22 -s 202.13.0.0/16 -j ACCEPTiptables -A INPUT -p tcp --dport 22 -j DROP 允许192.168.1.0网段的服务器访问（-t filter表配置可以省略，默认就是这种表的配置） 123iptables -A INPUT -s 192.168.1.0/24 -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT或者iptables -t filter -A INPUT -s 192.168.1.0/24 -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT 如果本地主机有两块网卡，一块连接内网(eth0)，一块连接外网(eth1)，那么可以使用下面的规则将eth0的数据路由到eht1： 1iptables -A FORWARD -i eth0 -o eth1 -j ACCEPT 允许所有本机向外的访问 1iptables -A OUTPUT -j ACCEPT DROP 屏蔽环回(loopback)访问 12iptables -A INPUT -i lo -j DROPiptables -A OUTPUT -o lo -j DROP 屏蔽 ping 1iptables -A INPUT -p icmp -i eth0 -j DROP 屏蔽来自外部的ping，即禁止外部机器ping本机 12iptables -A INPUT -p icmp --icmp-type echo-request -j DROPiptables -A OUTPUT -p icmp --icmp-type echo-reply -j DROP 屏蔽从本机ping外部主机，禁止本机ping外部机器 12iptables -A OUTPUT -p icmp --icmp-type echo-request -j DROPiptables -A INPUT -p icmp --icmp-type echo-reply -j DROP –icmp-type 8 同样表示 Echo request（Ping回显请求） 允许本机 ping 别的主机；但不开放别的主机 ping 本机； 12345iptables -I INPUT -p icmp --icmp-type echo-request -j DROPiptables -I INPUT -p icmp --icmp-type echo-reply -j ACCEPTiptables -I INPUT -p icmp --icmp-type destination-Unreachable -j ACCEPT或者下面禁ping操作：echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all 屏蔽指定mac地址 1iptables -A INPUT -m mac --mac-source 00:00:00:00:00:00 -j DROP 屏蔽某个IP 1iptables -A INPUT -s xxx.xxx.xxx.xxx -j DROP 拒绝转发来自192.168.0.1主机的数据 1iptables -A FORWARD -s 192.168.0.1 -j REJECT 屏蔽从192.168.0.1到192.168.0.254 1iptables -I INPUT -s 192.168.0.0/24 -j DROP 过滤源地址段： 1iptables -A INPUT -m iprange --src-range 192.168.1.1-192.168.1.10 -j DROP 过滤目标地址段： 1iptables -A INPUT -m iprange --dst-range 192.168.1.11-192.168.1.20 -j DROP 丢弃无效的数据包 1iptables -A INPUT -m conntrack --ctstate INVALID -j DROP 拒绝转发来自192.168.1.1主机的数据，允许转发来自192.168.0.0/24网段的数据 12iptables -A FORWARD -s 192.168.1.1 -j REJECTiptables -A FORWARD -s 192.168.0.0/24 -j ACCEPT 说明：注意一定要把拒绝的放在前面不然就不起作用了！ 丢弃从外网接口（eth1）进入防火墙本机的源地址为私网地址的数据包 123iptables -A INPUT -i eth1 -s 192.168.0.0/16 -j DROPiptables -A INPUT -i eth1 -s 172.16.0.0/12 -j DROPiptables -A INPUT -i eth1 -s 10.0.0.0/8 -j DROP 拒绝 TCP 标志位全部为 1 及全部为 0 的报文访问本机 1iptables -A INPUT -p tcp --tcp-flags ALL ALL -j DROP 禁止转发来自MAC地址为aa:aa:aa:45:75:d0的和主机的数据包 1iptables -A FORWARD -m mac --mac-source aa:aa:aa:45:75:d0 -j DROP iptables中使用“-m 模块关键字”的形式调用显示匹配。咱们这里用“-m mac –mac-source”来表示数据包的源MAC地址 禁止转发源IP地址为192.168.1.1-192.168.1.100的TCP数据包 1iptables -A FORWARD -p tcp -m iprange --src-range 192.168.1.1-192.168.1.100 -j DROP 此处用“-m iprange –src-range”指定IP范围 禁止转发与正常TCP连接无关的非–syn请求数据包 1iptables -A FORWARD -m state --state NEW -p tcp ! --syn -j DROP “-m state”表示数据包的连接状态，“NEW”表示与任何连接无关的 拒绝访问防火墙的新数据包，但允许响应连接或与已有连接相关的数据包 12iptables -A INPUT -p tcp -m state --state NEW -j DROPiptables -A INPUT -p tcp -m state --state ESTABLISHED,RELATED -j ACCEPT “ESTABLISHED”表示已经响应请求或者已经建立连接的数据包，“RELATED”表示与已建立的连接有相关性的，比如FTP数据连接等 为某个端口访问设置白名单 123456iptables -A INPUT -s &lt;YOUR_IP&gt; -p tcp -m tcp --dport 22 -j ACCEPTiptables -D INPUT -p tcp -m tcp --dport 22 -j DROPeg:iptables -A INPUT -p tcp --dport 21 -s 113.128.0.0/16 -j ACCEPT;iptables -A INPUT -p tcp --dport 21 -s 120.0.0.0/8 -j ACCEPT;iptables -A INPUT -p tcp --dport 21 -j DROP LIMIT 防止DoS攻击 1iptables -A INPUT -p tcp --dport 80 -m limit --limit 25/minute --limit-burst 100 -j ACCEPT -m limit: 启用limit扩展，限制速度。 –limit 25/minute: 允许最多每分钟25个连接 –limit-burst 100: 当达到100个连接后，才启用上述25/minute限制（连接上限） 限制并发连接数 12iptables -A INPUT -p tcp --syn --dport 22 -m connlimit --connlimit-above 3 -j REJECT //限制每客户端不超过 3 个连接iptables -A INPUT -p tcp --syn -m multiport --dport http,https –m connlimit --connlimit-above 20 -j REJECT --reject-with-tcp-reset 开放本机的ssh服务给192.168.1.1-192.168.1.100 中的主机；新请求建立的速率一分钟不得超过5个；仅允许响应报文通过其服务端口离开本机； 12iptables -A INPUT -p tcp --dport 22 -m iprange --src-rang 192.168.1.1-192.168.1.100 -m limit --limit 5/m -j ACCEPTiptables -A OUTPUT -p tcp --sport 22 -m iprange --dst-rang 192.168.1.1-192.168.1.100 -m state --state ESTABLISHED -j ACCEPT PREROUTINGIPtables中可以灵活的做各种网络地址转换（NAT）。 网络地址转换主要有两种：SNAT和DNAT SNAT是source network address translation的缩写，即源地址目标转换。 MASQUERADE，地址伪装，在iptables中有着和SNAT相近的效果，但也有一些区别：使用SNAT的时候，出口ip的地址范围可以是一个，也可以是多个。 DNAT是destination network address translation的缩写，即目标网络地址转换。 把所有10.0.0.0网段的数据包SNAT成192.168.1.1的ip然后发出去 1iptables -t nat -A POSTROUTING -s 10.0.0.0/255.255.255.0 -o eth0 -j SNAT --to-source 192.168.1.1 把所有10.0.0.0网段的数据包SNAT成192.168.1.1/192.168.1.2/192.168.1.3等几个ip然后发出去 1iptables -t nat -A POSTROUTING -s 10.0.0.0/255.255.255.0 -o eth0 -j SNAT --to-source 192.168.1.1-192.168.1.3 对于SNAT，不管是几个地址，必须明确的指定要SNAT的IP 动态SNAT地址转换,不管现在eth0的出口获得了怎样的动态ip，MASQUERADE会自动读取eth0现在的ip地址然后做SNAT出去 1iptables -t nat -A POSTROUTING -s 10.0.0.0/255.255.255.0 -o eth0 -j MASQUERADE MASQUERADE的作用是，从服务器的网卡上，自动获取当前ip地址来做NAT 8022映射22端口 1iptables -t nat -A PREROUTING -p tcp -d 192.168.1.1 --dport 8022 -j DNAT --to-destination 192.168.1.1:22 将所有到达eth0网卡80端口的流量重定向转发到8080端口 1iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 89 -j REDIRECT --to-port 8080 设置 8080 端口转发到 80 端口 123iptables -t nat -A PREROUTING -p tcp -d 10.1.1.1 --dport 8080 -j DNAT --to 10.1.1.1:80iptables -A INPUT -i eth0 -p tcp --dport 8080 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 8080 -m state --state ESTABLISHED -j ACCEPT 实践场景 按时段限制(需要模块支持) 123iptables –A OUTPUT -p tcp -m multiport --dport http,https -i eth0 -o eth1 -m time --timestart 12:00 –timestop 13:00 –d 10.0.0.0/8 -j ACCEPTiptables -A INPUT -p tcp -m time --timestart 02:00 --timestop 03:00 -j DROPiptables -A INPUT -p udp -m time --timestart 02:00 --timestop 03:00 -j DROP 限制本机的web服务器在周一不允许访问；新请求的速率不能超过100个每秒；web服务器包含了admin字符串的页面不允许访问： 123456789101112# web服务器仅允许响应报文离开本机；周一不允许访问iptables -A INPUT -p tcp --dport 80 -m time ! --weekdays Mon -j ACCEPTiptables -A OUTPUT -p tcp --dport 80 -m state --state ESTABLISHED -j ACCEPT# 新请求速率不能超过100个每秒iptables -A INPUT -p tcp --dport 80 -m limit --limit 100/s -j ACCEPT# web包含admin字符串的页面不允许访问，源端口：dportiptables -A INPUT -p tcp --dport 80 -m string --algo bm --string &apos;admin&apos; -j REJECT# web服务器仅允许响应报文离开主机,放行端口（目标端口）：sportiptables -A OUTPUT -p tcp --dport 80 -m state --state ESTABLISHED -j ACCEPT 在工作时间，即周一到周五的8:30-18:00，开放本机的ftp服务给 192.168.1.0网络中的主机访问；数据下载请求的次数每分钟不得超过5个； 1iptables -A INPUT -p tcp --dport 21 -s 192.168.1.0/24 -m time ! --weekdays 6,7 -m time --timestart 8:30 --timestop 18:00 -m connlimit --connlimit-above 5 -j ACCET 屏蔽ssh和rsync端口，只允许白名单机器访问 12345678910cat &lt;&lt; EOF#!/bin/bash/etc/init.d/iptables stopiptables -A INPUT -s 10.0.0.1 -p tcp --dport 22 -j ACCEPT # 中控白名单iptables -A OUTPUT -d 10.0.0.1 -p tcp --sport 22 -j ACCEPTiptables -A INPUT -s 10.0.0.2 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT # 监控探针通过22端口连通性监控机器存活，开白名单。iptables -A INPUT -p tcp -m multiport --dports 22,873 -j DROPiptables -A OUTPUT -p tcp -m multiport --dports 22,873 -j DROPiptables -L -v -n --line-numbersEOF | bash 参考文档 iptables官方网站 IPTables 整理过程中参考部分微信公众号文章]]></content>
      <categories>
        <category>iptables</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rsync经典用例总结]]></title>
    <url>%2F2018%2F12%2F04%2F00053_rsync%E7%BB%8F%E5%85%B8%E7%94%A8%E4%BE%8B%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[rsync是经典的数据传输工具，但本篇博客总结的既不细致，也不全面。惭愧，惭愧。。。 备份更新1rsync -avzP -b --suffix=$(date &quot;+.bak%Y%m%d%H%M%S&quot;) --backup-dir=/data/backup/ $&#123;src&#125; $&#123;dst&#125; 备份目录下如果存在同名文件会被新的备份文件强制覆盖 -b –suffix 既适用推送也适用于拉取，但是都是在dest侧备份 -b –backup-dir 仅适用于拉取，推送数据时适用会报错 另外mv命令也有备份实现方案alias mv=&#39;mv -v -b -S &quot;$(date &quot;+.mvbak%Y%m%d_%H%M&quot;)&quot;&#39; 递归创建目录1rsync -avzP -R src dest -R 参数会在dest目录基础上递归创建src目录路径，如rsync -avzP -R 10.0.0.1::data/data/test1/test2/test3 /data/test,在本地会生成路径/data/test/data/test1/test2/test3 慎用–delete12345678910rsync -avzP --delete 10.0.0.1::data/data/test /data/test //该种写法会在/data/test下再创建一层test目录，不会删除/data/test的其它目录和rsync -avzP --delete 10.0.0.1::data/data/test/ /data/test //该种写法会将本地/data/test目录下的文件与src目录强一致的效果是截然不同的，自己体会下。细思极恐。。。另外，rsync -avzP --delete 10.0.0.1::data/data/test/ /data/test和rsync -avzP --delete 10.0.0.1::data/data/test/* /data/test //该种写法会将src目录下的子文件和目录和本地/data/test中的同名子文件和目录进行强一致，本地/data/test中的其它文件目录不会被删除的效果也不同，使用时要十分谨慎。 rsync认证 RSYNC_PASSWORD仅适用于rsync协议，rsync配置中指定的用户密码，rsync服务需要通过daemon方式启动； 1export RSYNC_PASSWORD=&quot;passwd&quot; rsync协议使用的两种方式 rsync 协议 12rsync rsync://username@1.2.3.4:/abc /defrsync 1.2.3.4::abc/ /def ssh 协议 1rsync 1.2.3.4:/abc/ /def 仅适用rsync客户端，通过ssh协议传输 参考 http://linuxwiki.github.io/Services/rsync.html https://www.cnblogs.com/shihuc/p/5628893.html https://unix.stackexchange.com/questions/111526/how-can-i-rsync-without-prompt-for-password-without-using-public-key-authentica]]></content>
      <categories>
        <category>rsync</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>rsync</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux环境中alias不生效问题]]></title>
    <url>%2F2018%2F11%2F06%2F00052_Linux%E7%8E%AF%E5%A2%83%E4%B8%ADalias%E4%B8%8D%E7%94%9F%E6%95%88%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[很多时候，实际结果往往和我们的预期不一致，其中必有蹊跷。。。 问题由于公司hadoop集群迁移，需要对线上几百台历史遗留的脚本进行改造，变更hadoop客户端环境。 思虑再三，借鉴python装饰器的思想，部署一个绿色版的hadoop客户端环境。再将线上各式各样的脚本统一加一行alias hadoop=&quot;/path/to/hadoop&quot;成本最低。 无奈alias貌似并没有生效，实际操作结果和预期不一致。。。 结果alias 在非交互shell环境中不生效，除非手动设置shopt -s expand_aliases 验证 cat aliasVerifi.sh 1234567891011#/bin/bashshopt |grep -i aliaswhoamiwhich whoamiecho &quot;================&quot;shopt -s expand_aliasesshopt |grep -i aliasalias whoami=&apos;date &quot;+%Y-%m-%d %H:%M:%S&quot;&apos;whoamiwhich whoami 通过cron调用脚本并将输出写入log文件aliasVerifi.log cat aliasVerifi.log 1234567expand_aliases offroot/usr/bin/whoami================expand_aliases on2018-11-06 22:20:01/usr/bin/whoami 此处我们注意到expand_aliases在非交互shell中默认关闭，并且用which获取该命令的绝对路径并没有发生改变，但是执行结果已经符合预期。 其它说明 当alias的命令和sudo一起使用时alias命令不生效，此时将sudo加入alias中即可生效。 1234567$ alias mkdir=&apos;mkdir -p&apos;$ sudo mkdir 1/2/3mkdir: cannot create directory ‘1/2/3’: No such file or directory$ mkdir 1/2/3mkdir: cannot create directory ‘1’: Permission denied$ alias mkdir=&apos;sudo mkdir -p&apos;$ mkdir 1/2/3 12345$ alias mv=&apos;/usr/bin/mv -v -b -S $(date &quot;+.mvbak%Y%m%d_%H%M&quot;)&apos;$ sudo mv a.sh b.sh$ alias mv=&apos;sudo /usr/bin/mv -v -b -S $(date &quot;+.mvbak%Y%m%d_%H%M&quot;)&apos;$ mv a.sh b.sh‘a.sh’ -&gt; ‘b.sh’ 前提，mkdir,mv命令已加入sudoers 在xargs命令后命令别名也不生效，因为xargs是一个单独的应用程序，它不是shell，因此没有别名或函数的概念。但可以通过以下两种方式变相使用alias xargs ${BASH_ALIASES[alias_command]} ${BASH_ALIASES[alias_command]}前后不能有引号 xargs -t -i bash -ic “alias_command }” 在sshpass命令后命令别名同样不生效 以下情况不生效alias rsync不生效 123export SSHPASS=&quot;xxxx&quot;alias rsync=&apos;rsync -e &quot;ssh -q -o StrictHostKeyChecking=no&quot; -avzP&apos;sshpass -e rsync ... 可用以下方式变相实现 123export SSHPASS=&quot;xxxx&quot;alias rsync=&apos;sshpass -e rsync -e &quot;ssh -q -o StrictHostKeyChecking=no&quot; -avzP&apos;rsync ... 脚本中使用alias命令别名，通过eval调用命令别名可以生效。 参考文档 alias stackoverflow·Have xargs use alias instead of binary stackoverflow·How can I use aliased commands with xargs? 推荐文章（由hexo文章推荐插件驱动）存储空间计算Linux系统中的tmpfs、/dev/shm、tmp以及共享内存机制Linux系统中的IO模式tmux窗口管理Linux挂载Windows共享目录]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>alias</tag>
        <tag>cron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx代理redmine with thin]]></title>
    <url>%2F2018%2F09%2F10%2F00051_redmine-with-thin%2F</url>
    <content type="text"><![CDATA[Redmine是基于Ruby开发的经典项目管理平台，功能强大。 thin, A fast and very simple Ruby web server。 本文档非操作手册只列出来关键信息，需要对ruby，redmine，nginx稍有些许了解。。。 thin 安装12345bundle exec rake redmine:plugins:migrate RAILS_ENV=productionbundle exec rake redmine:plugins:migrate RAILS_ENV=production --tracegem install thinthin install 创建logrotate配置/etc/logrotate.d/thin12345678910111213/var/log/thin/*.log &#123; daily missingok rotate 52 compress delaycompress notifempty create 640 root adm sharedscripts postrotate /etc/init.d/thin restart &gt;/dev/null endscript&#125; 创建thin配置文件/etc/thin/redmine.yml123456789101112131415pid: /var/run/thin/thin.pidgroup: nginxwait: 30timeout: 30log: /var/log/thin/thin.logmax_conns: 1024require: []environment: productionmax_persistent_conns: 512servers: 4daemonize: trueuser: nginxsocket: /tmp/thin.sockchdir: /data/DevOps/redmine 创建thin启动文件/etc/init.d/thin123456789101112131415161718192021222324252627282930313233343536373839#!/bin/sh### BEGIN INIT INFO# Provides: thin# Required-Start: $local_fs $remote_fs# Required-Stop: $local_fs $remote_fs# Default-Start: 2 3 4 5# Default-Stop: S 0 1 6# Short-Description: thin initscript# Description: thin### END INIT INFO# Original author: Forrest Robertson# Do NOT &quot;set -e&quot;DAEMON=/usr/local/rvm/gems/ruby-2.3.0/bin/thinSCRIPT_NAME=/etc/init.d/thinCONFIG_PATH=/etc/thin# Exit if the package is not installed[ -x &quot;$DAEMON&quot; ] || exit 0case &quot;$1&quot; in start) $DAEMON start --all $CONFIG_PATH ;; stop) $DAEMON stop --all $CONFIG_PATH ;; restart) $DAEMON restart --all $CONFIG_PATH ;; *) echo &quot;Usage: $SCRIPT_NAME &#123;start|stop|restart&#125;&quot; &gt;&amp;2 exit 3 ;;esac: nginx配置文件 /etc/nginx/conf.d/redmine.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869upstream thin_cluster &#123; server unix:/tmp/thin.0.sock; server unix:/tmp/thin.1.sock; server unix:/tmp/thin.2.sock; server unix:/tmp/thin.3.sock;&#125;server &#123; listen 80; server_name redmine.server; #charset koi8-r; access_log /var/log/nginx/log/redmine.access.log main; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; #your redmine path root /data/DevOps/redmine/public; proxy_redirect off; location / &#123; try_files $uri/index.html $uri.html $uri @cluster; &#125; location @cluster &#123; proxy_pass http://thin_cluster; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/share/nginx/html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\.ht &#123; # deny all; #&#125;&#125; 参考文档 thin 官网 Help with Ruby 2.0 + Redmine 2.30 + thin install]]></content>
      <categories>
        <category>redmine</category>
      </categories>
      <tags>
        <tag>redmine</tag>
        <tag>thin</tag>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sed 常见用例总结]]></title>
    <url>%2F2018%2F09%2F08%2F00050_sed%E5%B8%B8%E8%A7%81%E7%94%A8%E4%BE%8B%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[sed 发行于1974年，作者 Lee E. McMahon。awk发行于1977年，作者 阿尔佛雷德·艾侯、彼得·温伯格以及布莱恩·柯林汉。 ——源自维基百科 常见用例 文件最后追加 1sed &apos;$ a\00 08 * * * /sbin/clock -w &gt;/dev/null 2&gt;&amp;1&apos; /var/spool/cron/root 输出满足正则的记录 1sed -n &apos;/正则表达式/p&apos; /var/spool/cron/root 删除满足正则的记录 1sed -i &apos;/正则表达式/d&apos; /var/spool/cron/root sed删除多行 123sed -i &apos;/START/,/END/d&apos; /etc/rsyncd.confeg:sed -i &apos;/\[root\]\s*/,/\s*hosts\s*allow\s*=\s*10.0.0.0\/8\s*192.168.0.0\/16\s*/d&apos; rsyncd.conf 将所有数字版本号统一 sed正则中{}()需要加转义，[]则不用。|和+也需要转义，$不需要转义。 1find /data/daemon/conf/ -name &quot;*.yaml&quot; -type f |xargs grep -irl &quot;version:v&quot; |xargs sed -i &apos;s/version:v[0-9]\&#123;1\&#125;/version:v9/g&apos; 将软件版本号去掉1rpm -qa |grep someone|sed &apos;s/\([0-9]\|\.\|_\|-\)\+\.el.\+\(.x86_64\|.noarch\)/\2/g&apos; 备注说明 有些版本的sed正则中不支持\d，小括号和加号都要加转义符 12eg:rpm -qa |grep php |sed &apos;s/-[0-9]\(.*\)\+$/-flag/g;s/^php-/php71-/g&apos; 参考文档 sed, a stream editor·官方文档 linux下在某行的前一行或后一行添加内容·运维之路 sed命令详解 linux中sed的用法 sed 命令如何替换多行内容 sed与正则表达式 sed命令的入门与进阶·Linux运维部落 推荐文章（由hexo文章推荐插件驱动）awk使用总结]]></content>
      <categories>
        <category>sed</category>
      </categories>
      <tags>
        <tag>sed</tag>
        <tag>文本处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MediaWiki配置文件]]></title>
    <url>%2F2018%2F09%2F05%2F00049_MediaWiki%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[MediaWiki是一款优秀的开源文档系统。功能强大，插件众多，文档完善。 配置文件参考123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316# mediawiki/LocalSettings.php&lt;?php# This file was automatically generated by the MediaWiki 1.26.2# installer. If you make manual changes, please keep track in case you# need to recreate them later.## See includes/DefaultSettings.php for all configurable settings# and their default values, but don&apos;t forget to make changes in _this_# file, not there.## Further documentation for configuration settings may be found at:# https://www.mediawiki.org/wiki/Manual:Configuration_settings# Protect against web entryif ( !defined( &apos;MEDIAWIKI&apos; ) ) &#123; exit;&#125;## Uncomment this to disable output compression# $wgDisableOutputCompression = true;$wgSitename = &quot;WIKI&quot;;## The URL base path to the directory containing the wiki;## defaults for all runtime URL paths are based off of this.## For more information on customizing the URLs## (like /w/index.php/Page_title to /wiki/Page_title) please see:## https://www.mediawiki.org/wiki/Manual:Short_URL$wgScriptPath = &quot;&quot;;## The protocol and server name to use in fully-qualified URLs$wgServer = &quot;http://wiki.domain-name.com&quot;;## The URL path to static resources (images, scripts, etc.)$wgResourceBasePath = $wgScriptPath;$wgArticlePath = &quot;/wiki/$1&quot;;$wgUsePathInfo = true; # Ǵԃ pretty URLs## The URL path to the logo. Make sure you change this from the default,## or else you&apos;ll overwrite your logo when you upgrade!#$wgLogo = &quot;$wgResourceBasePath/resources/assets/wiki.png&quot;;$wgLogo = &quot;$wgResourceBasePath/resources/assets/logo.png&quot;;## UPO means: this is also a user preference option$wgEnableEmail = true;$wgEnableUserEmail = true; # UPO$wgEmergencyContact = &quot;mail@domain-name.com&quot;;$wgPasswordSender = &quot;username@domain-name.com&quot;;$wgEnotifUserTalk = true; # UPO$wgEnotifWatchlist = true; # UPO$wgEmailAuthentication = true;## Database settings$wgDBtype = &quot;mysql&quot;;$wgDBserver = &quot;10.0.0.1&quot;;$wgDBname = &quot;wiki&quot;;$wgDBuser = &quot;root&quot;;$wgDBpassword = &quot;passwd&quot;;# MySQL specific settings$wgDBprefix = &quot;&quot;;# MySQL table options to use during installation or update$wgDBTableOptions = &quot;ENGINE=InnoDB, DEFAULT CHARSET=binary&quot;;# Experimental charset support for MySQL 5.0.$wgDBmysql5 = false;## Shared memory settings$wgMainCacheType = CACHE_ACCEL;$wgMemCachedServers = array();## To enable image uploads, make sure the &apos;images&apos; directory## is writable, then set this to true:$wgEnableUploads = true;#$wgUseImageMagick = true;#$wgImageMagickConvertCommand = &quot;/usr/bin/convert&quot;;# InstantCommons allows wiki to use images from https://commons.wikimedia.org$wgUseInstantCommons = true;## If you use ImageMagick (or any other shell command) on a## Linux server, this will need to be set to the name of an## available UTF-8 locale$wgShellLocale = &quot;en_US.utf8&quot;;## If you want to use image uploads under safe mode,## create the directories images/archive, images/thumb and## images/temp, and make them all writable. Then uncomment## this, if it&apos;s not already uncommented:#$wgHashedUploadDirectory = false;## Set $wgCacheDirectory to a writable directory on the web server## to make your wiki go slightly faster. The directory should not## be publically accessible from the web.#$wgCacheDirectory = &quot;$IP/cache&quot;;# Site language code, should be one of the list in ./languages/Names.php# $wgLanguageCode = &quot;en&quot;;$wgLanguageCode = &quot;zh-cn&quot;;$wgSecretKey = &quot;xxxxxxxxxxxxx&quot;;# Site upgrade key. Must be set to a string (default provided) to turn on the# web installer while LocalSettings.php is in place$wgUpgradeKey = &quot;xxxxxx&quot;;## For attaching licensing metadata to pages, and displaying an## appropriate copyright notice / icon. GNU Free Documentation## License and Creative Commons licenses are supported so far.$wgRightsPage = &quot;&quot;; # Set to the title of a wiki page that describes your license/copyright$wgRightsUrl = &quot;&quot;;$wgRightsText = &quot;&quot;;$wgRightsIcon = &quot;&quot;;# Path to the GNU diff3 utility. Used for conflict resolution.$wgDiff3 = &quot;/usr/bin/diff3&quot;;# The following permissions were set based on your choice in the installer$wgGroupPermissions[&apos;*&apos;][&apos;createaccount&apos;] = true;$wgGroupPermissions[&apos;*&apos;][&apos;edit&apos;] = false;$wgWhitelistRead = array (&quot;首页&quot;,&quot;特殊:创建账户&quot;);$wgGroupPermissions[&apos;*&apos;][&apos;read&apos;] = false;#$wgGroupPermissions[&apos;sysop&apos;][&apos;edit&apos;] = true;#$wgGroupPermissions[&apos;sysop&apos;][&apos;read&apos;] = true;## Default skin: you can change the default skin. Use the internal symbolic## names, ie &apos;vector&apos;, &apos;monobook&apos;:# $wgDefaultSkin = &quot;vector&quot;;# wfLoadSkin( &apos;BlueSky&apos; );# $wgDefaultSkin = &quot;BlueSky&quot;;# wfLoadSkin( &apos;foreground&apos; );# $wgDefaultSkin = &quot;foreground&quot;;# wfLoadSkin( &apos;Metrolook&apos; );# $wgDefaultSkin = &quot;Metrolook&quot;;wfLoadSkin( &apos;Timeless&apos; );$wgDefaultSkin = &quot;Timeless&quot;;# Enabled skins.# The following skins were automatically enabled:wfLoadSkin( &apos;CologneBlue&apos; );wfLoadSkin( &apos;Modern&apos; );wfLoadSkin( &apos;MonoBook&apos; );wfLoadSkin( &apos;Vector&apos; );# Enabled Extensions. Most extensions are enabled by including the base extension file here# but check specific extension documentation for more details# The following extensions were automatically enabled:wfLoadExtension( &apos;Cite&apos; );wfLoadExtension( &apos;CiteThisPage&apos; );wfLoadExtension( &apos;ConfirmEdit&apos; );wfLoadExtension( &apos;Gadgets&apos; );wfLoadExtension( &apos;ImageMap&apos; );wfLoadExtension( &apos;InputBox&apos; );wfLoadExtension( &apos;Interwiki&apos; );wfLoadExtension( &apos;LocalisationUpdate&apos; );wfLoadExtension( &apos;Nuke&apos; );wfLoadExtension( &apos;ParserFunctions&apos; );wfLoadExtension( &apos;PdfHandler&apos; );wfLoadExtension( &apos;Poem&apos; );wfLoadExtension( &apos;Renameuser&apos; );wfLoadExtension( &apos;SpamBlacklist&apos; );#wfLoadExtension( &apos;SyntaxHighlight_GeSHi&apos; );wfLoadExtension( &apos;TitleBlacklist&apos; );wfLoadExtension( &apos;WikiEditor&apos; );# End of automatically generated settings.# Add more configuration options below.#VisualEditor/*require_once &quot;$IP/extensions/VisualEditor/VisualEditor.php&quot;;// Enable by default for everybody$wgDefaultUserOptions[&apos;visualeditor-enable&apos;] = 1;// Don&apos;t allow users to disable it$wgHiddenPrefs[] = &apos;visualeditor-enable&apos;;// OPTIONAL: Enable VisualEditor&apos;s experimental code features#$wgDefaultUserOptions[&apos;visualeditor-enable-experimental&apos;] = 1;$wgVirtualRestConfig[&apos;modules&apos;][&apos;parsoid&apos;] = array( // URL to the Parsoid instance // Use port 8142 if you use the Debian package &apos;url&apos; =&gt; &apos;http://127.0.0.1:8182&apos;, // Parsoid &quot;domain&quot;, see below (optional) &apos;domain&apos; =&gt; &apos;localhost&apos;, // Parsoid &quot;prefix&quot;, see below (optional) &apos;prefix&apos; =&gt; &apos;mediawiki&apos;);*/require_once &apos;extensions/LdapAuthentication/LdapAuthentication.php&apos;;#require_once &apos;includes/AuthPlugin.php&apos;;$wgAuth = new LdapAuthenticationPlugin();$wgLDAPUseLocal = true;$wgLDAPDomainNames = array(&quot;domain-name&quot;);$wgLDAPServerNames = array(&quot;domain-name&quot; =&gt; &quot;ldap.domain-name.com&quot;);$wgLDAPPort = array(&quot;domain-name&quot; =&gt; 389);$wgLDAPEncryptionType = array( &quot;domain-name&quot; =&gt; &quot;clear&quot;);#$wgLDAPProxyAgent = array(&quot;domain-name&quot;=&gt;&quot;cn=username,ou=op,ou=user,ou=xxxxx,dc=domain-name,dc=com&quot;);$wgLDAPProxyAgent = array(&quot;domain-name&quot;=&gt;&quot;cn=username,ou=Special_Account,ou=user,ou=xxxxx,dc=domain-name,dc=com&quot;);$wgLDAPProxyAgentPassword = array( &quot;domain-name&quot;=&gt;&quot;passwd&quot;);$wgLDAPGroupUseRetrievedUsername = array(&quot;domain-name&quot;=&gt;true);#$wgLDAPSearchAttributes = array( &quot;domain-name&quot; =&gt; &quot;uid&quot;);$wgLDAPSearchAttributes = array( &quot;domain-name&quot; =&gt; &quot;sAMAccountName&quot;);$wgLDAPBaseDNs = array( &quot;domain-name&quot;=&gt;&quot;dc=domain-name,dc=com&quot;);$wgLDAPGroupBaseDNs = array( &quot;domain-name&quot;=&gt;&quot;ou=maillist,ou=xxxxx,dc=domain-name,dc=com&quot;);$wgLDAPUserBaseDNs = array( &quot;domain-name&quot;=&gt;&quot;ou=user,ou=xxxxx,dc=domain-name,dc=com&quot;);$wgLDAPGroupUseFullDN = array( &quot;domain-name&quot;=&gt;true );$wgLDAPLowerCaseUsername = array( &quot;domain-name&quot;=&gt;true);$wgLDAPGroupObjectclass = array( &quot;domain-name&quot;=&gt;&quot;groupofuniquenames&quot; );$wgLDAPGroupAttribute = array( &quot;domain-name&quot;=&gt;&quot;uniquemember&quot; );$wgLDAPGroupNameAttribute = array( &quot;domain-name&quot;=&gt;&quot;cn&quot; );#$wgLDAPRequiredGroups = array( &quot;domain-name&quot; =&gt; array(&quot;&quot;));$wgLDAPGroupSearchNestedGroups = array( &quot;domain-name&quot;=&gt;false );$wgLDAPDebug = 5;$wgDebugLogGroups[&quot;ldap&quot;] = &quot;/tmp/ldap.log&quot;;$wgGroupPermissions[&apos;*&apos;][&apos;autocreateaccount&apos;] = true;#UserMergerequire_once &quot;$IP/extensions/UserMerge/UserMerge.php&quot;;// By default nobody can use this function, enable for bureaucrat?$wgGroupPermissions[&apos;bureaucrat&apos;][&apos;usermerge&apos;] = true;// optional: default is array( &apos;sysop&apos; )//$wgUserMergeProtectedGroups = array( &apos;groupname&apos; );# Allow all users to be merged (by default, the &apos;sysop&apos; group is unmergeable)//$wgUserMergeProtectedGroups = array();# Disallow merging of the users in the &apos;sysop&apos; or &apos;awesomeusers&apos; groups//$wgUserMergeUnmergeable = array( &apos;sysop&apos;, &apos;awesomeusers&apos; );#Mail$wgSMTP = array(&quot;host&quot; =&gt; &apos;mail.domain-name.com&apos;,&quot;IDHost&quot; =&gt; &apos;domain-name.com&apos;,&quot;port&quot; =&gt; &quot;25&quot;,&quot;auth&quot; =&gt; true,&quot;username&quot; =&gt; &apos;username&apos;,&quot;password&quot; =&gt; &apos;passpwd&apos;);$wgEnableUserEmail = true;$wgEnableEmail = true;# target set.$wgExternalLinkTarget = &apos;_blank&apos;;#Extension:DynamicSidebarwfLoadExtension( &apos;DynamicSidebar&apos; );// Enable debugging$wgDebugLogGroups[&quot;dynamic-sidebar&quot;] = &quot;/tmp/sidebar-debug.log&quot;;// Allow users to create their own custom sidebars under User:&lt;username&gt;/Sidebar// Default: true$wgDynamicSidebarUseUserpages = true;// Allow group sidebars under MediaWiki:Sidebar/Group:&lt;group&gt;// Default: true$wgDynamicSidebarUseGroups = true;// Allow category based sidebars under MediaWiki:Sidebar/Category:&lt;category&gt;// Default: true$wgDynamicSidebarUseCategories = true;#Extension:CollapsibleVector &amp; TreeOfSiderbarwfLoadExtension( &apos;CollapsibleVector&apos; );$wgCollapsibleVectorFeatures[&apos;collapsiblenav&apos;][&apos;global&apos;] = true;$wgCollapsibleVectorFeatures[&apos;collapsiblenav&apos;][&apos;user&apos;] = true;#Extension:TreeAndMenuwfLoadExtension( &apos;TreeAndMenu&apos; );#MarkdownExtraParser/*require_once &quot;$IP/extensions/MarkdownExtraParser/MarkdownExtraParser.php&quot;;// MarkdownExtraParser$MarkdownExtraParserOptions = array( &apos;use_raw_html&apos; =&gt; true,);*/#SimpleBatchUploadwfLoadExtension(&apos;SimpleBatchUpload&apos;);#Piwik/*require_once &quot;$IP/extensions/piwik-mediawiki/Piwik.php&quot;;$wgPiwikURL = &quot;piwik.domain-name.com/&quot;;$wgPiwikIDSite = &quot;1&quot;;$wgUseSiteJS = true;*/# MobileFrontendwfLoadExtension( &apos;MobileFrontend&apos; );$wgMFAutodetectMobileView = true;$wgMFNearbyEndpoint = &apos;http://en.m.wikipedia.org/w/api.php&apos;;$wgMFNearby = true;# MobileContext::singleton()-&gt;setForceMobileView( true );# $wgMFDefaultSkinClass = &apos;SkinVector&apos;; // use Vector skin$wgMFDefaultSkinClass = &apos;SkinTimeless&apos;; // use Timeless skin# GeoDatarequire_once &quot;$IP/extensions/GeoData/GeoData.php&quot;;# PageImagesrequire_once &quot;$IP/extensions/PageImages/PageImages.php&quot;;# Enable Semantic MediaWiki# require_once &quot;$IP/extensions/SemanticMediaWiki/SemanticMediaWiki.php&quot;;enableSemantics(&apos;wiki.domain-name.com&apos;); 插件列表参考12345678910111213141516171819202122232425262728293031323334BootstrapCiteCiteThisPageCollapsibleVectorConfirmEditDynamicSidebarGadgetsGeoDataImageMapInputBoxInterwikiLdapAuthenticationLocalisationUpdateMarkdownExtraParserMobileFrontendNukeOpenLayersPageImagesParserFunctionsPdfHandlerpiwik-mediawikiPoemREADMERenameuserSemanticFormsSemanticMediaWikiSimpleBatchUploadSpamBlacklistSyntaxHighlight_GeSHiTitleBlacklistTreeAndMenuUserMergeVisualEditorWikiEditor 推荐文章（由hexo文章推荐插件驱动）MediaWiki导航菜单设置MediaWiki常见问题汇总]]></content>
      <categories>
        <category>MediaWiki</category>
      </categories>
      <tags>
        <tag>MediaWiki</tag>
        <tag>插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown格式备注]]></title>
    <url>%2F2018%2F09%2F04%2F00048_Markdown%E6%A0%BC%E5%BC%8F%E5%A4%87%E6%B3%A8%2F</url>
    <content type="text"><![CDATA[好的文档不仅要内容精湛，更要格式优雅。 基本格式就不介绍了，主要备忘一些特殊格式。对，肯定不全面，慢慢完善嘛。。。 表格设置123456789101112131415161718192021222324252627&lt;style&gt; table width: 100%; /*表格宽度*/ max-width: 65em; /*表格最大宽度，避免表格过宽*/ border: 1px solid #dedede; /*表格外边框设置*/ margin: 15px auto; /*外边距*/ border-collapse: collapse; /*使用单一线条的边框*/ empty-cells: show; /*单元格无内容依旧绘制边框*/ tr: hover &#123;background: #efefef;&#125; td: height: 35px; /*统一每一行的默认高度*/ border: 1px solid #dedede; /*内部边框样式*/ padding: 0 10px; /*内边距*/ th: white-space: nowrap; /*表头内容强制在一行显示*/ font-weight: bold; /*加粗*/ text-align: center !important; /*内容居中，加上 !important 避免被 Markdown 样式覆盖*/ background: rgba(158,188,226,0.2); /*背景色*/ nth-of-type(1)&#123;width: 5%; white-space: nowrap;&#125; nth-of-type(2)&#123;width: 15%;&#125; nth-of-type(3)&#123;width: 70%;&#125; nth-of-type(4)&#123;width: 10%;&#125; tbody tr: nth-child(2n)&#123;background: rgba(158,188,226,0.12);&#125;&lt;/style&gt; note 标签官方12345678910使用方式&#123;% note class_name %&#125; Content (md partial supported) &#123;% endnote %&#125;其中，class_name 可以是以下列表中的一个值：defaultprimarysuccessinfowarningdanger 第三方1234567891011121314151617181920212223242526272829&lt;p id=&quot;div-border-top-green&quot;&gt;内容&lt;/p&gt;&lt;p id=&quot;div-border-left-red&quot;&gt;内容[shell tag](/tags/shell)标签&lt;/p&gt;default&lt;div class=&quot;note default&quot;&gt;&lt;p&gt;default&lt;/p&gt;&lt;/div&gt;primary&lt;div class=&quot;note primary&quot;&gt;&lt;p&gt;primary&lt;/p&gt;&lt;/div&gt;success&lt;div class=&quot;note success&quot;&gt;&lt;p&gt;success&lt;/p&gt;&lt;/div&gt;info&lt;div class=&quot;note info&quot;&gt;&lt;p&gt;info&lt;/p&gt;&lt;/div&gt;warning&lt;div class=&quot;note warning&quot;&gt;&lt;p&gt;warning&lt;/p&gt;&lt;/div&gt;danger&lt;div class=&quot;note danger&quot;&gt;&lt;p&gt;danger&lt;/p&gt;&lt;/div&gt;danger no-icon&lt;div class=&quot;note danger no-icon&quot;&gt;&lt;p&gt;danger no-icon&lt;/p&gt;&lt;/div&gt; 可以收缩的内容 可以收缩的内容源码 123456789101112131415161718192021222324252627282930313233## 标题1.1&lt;details&gt;&lt;summary&gt;查看详情&lt;/summary&gt;### 标题1.1.1* [链接1](https://www.baidu.com)### 标题1.1.2* [链接1](https://www.baidu.com)### 标题1.1.3* [链接1](https://www.baidu.com)&lt;/details&gt;## 标题1.2&lt;details&gt;&lt;summary&gt;查看详情&lt;/summary&gt;### 标题1.2.1* [链接1](https://www.baidu.com)### 标题1.2.1* [链接1](https://www.baidu.com)* [链接2](https://www.baidu.com)* [链接3](https://www.baidu.com)&lt;/details&gt;## 标题1.3&lt;details&gt;&lt;summary&gt;查看详情&lt;/summary&gt;### 标题1.3.1* [链接1](https://www.baidu.com)### 标题1.3.2* [链接1](https://www.baidu.com)* [链接2](https://www.baidu.com)&lt;/details&gt; 可以收缩的内容效果 标题1.1 查看详情### 标题1.1.1- 链接1### 标题1.1.2- 链接1### 标题1.1.3- 链接1 标题1.2查看详情### 标题1.2.1- 链接1### 标题1.221- 链接1- 链接2- 链接3 标题1.3查看详情### 标题1.3.1- 链接1### 标题1.3.2- 链接1- 链接2 网页表格 参考文档 Markdown 表格样式调整与自适应优化 Markdown使用问题及解决办法 github·awesome-cheatsheets Markdown-Syntax-CN]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
        <tag>Readme</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行环境下进行URL解码]]></title>
    <url>%2F2018%2F09%2F03%2F00047_Linux-shell-urldecode%2F</url>
    <content type="text"><![CDATA[命令行环境解码url是运维的必备技能，尤其是在排查应用日志的时候。而最佳实践还是不依赖任何编程能直接敲个命令就搞定。。。 以下内容基于CentOS6.9系统环境。 命令行软件包123[root@test-204 ~]# rpm -qf /usr/bin/urlencodegridsite-clients-2.2.6-2.el6.x86_64[root@test-204 ~]# 安装环境123yum -y install http://dl.fedoraproject.org/pub/epel/6/x86_64/Packages/g/gridsite-clients-2.2.6-2.el6.x86_64.rpm \http://dl.fedoraproject.org/pub/epel/6/x86_64/Packages/g/gridsite-libs-2.2.6-2.el6.x86_64.rpm \http://dl.fedoraproject.org/pub/epel/6/x86_64/Packages/c/canl-c-2.1.8-1.el6.x86_64.rpm 使用查看12345# 查看归档日志urlencode -d decode $(zcat access.log.2018_09_01_22.log.gz |awk &apos;&#123;print $7&#125;&apos; |sort |uniq -c |sort -rn |head )#查看实时日志tailf access.log |awk &apos;&#123;print $7&#125;&apos;|xargs urlencode -d decode 参考文档 linux-urldecode 推荐文章（由hexo文章推荐插件驱动）shell脚本传参shell的分批并发操作的简单实现shell printf格式化输出常用shell命令总结]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>urldecode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx访问频率限制]]></title>
    <url>%2F2018%2F04%2F01%2F00046_nginx%E8%AE%BF%E9%97%AE%E9%A2%91%E7%8E%87%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[在nginx服务中通过限制访问频率的策略可以在一定程度上抵御DDoS攻击。 配置范例1234567891011121314151617181920212223242526272829303132333435363738# 白名单# geo $remote_addr $limitedgeo $limited&#123; default 1; 10.0.0.0/8 0; 123.207.144.100/32 0; 123.123.123.248/30 0;&#125;map $limited $limit &#123; 1 $binary_remote_addr; 0 &quot;&quot;;&#125;# nginx.conf 中的http模块中定义limit_req_zonelimit_req_zone $limit zone=reqzone1:10m rate=20r/s;# server模块中的location规则中应用limit_req_zone(也可以直接应用到server或者http模块中)server&#123; ... #limit_req zone=reqzone3 burst=20 nodelay; limit_req zone=reqzone3 burst=20; location xxx1 &#123; ... #limit_req zone=reqzone1 burst=20 nodelay; limit_req zone=reqzone1 burst=20; ... &#125; location xxx2 &#123; ... #limit_req zone=reqzone2 burst=20 nodelay; limit_req zone=reqzone2 burst=20; ... &#125;# 在http, server, location中均可定义limit_req_status code，默认503； 参数说明 geo geo [$address] $variable { … } 定义从指定的变量获取客户端的IP地址。默认情况下，nginx从$remote_addr变量取得客户端IP地址，但也可以从其他变量获得。 map map为一个变量设置的映射表，用来创建变量，映射表由两列组成，匹配模式和对应的值。但是仅在变量被接受的时候执行视图映射操作，对于处理没有引用变量的请求时，这个模块并没有性能上的缺失。 limit_req_zone 第一个字段定义为key，限制对象。$binary_remote_addr(\x0A\x64\xCE\x10)是4字节的IPv4地址，或者16字节的IPv6地址，32位系统上占用32或64个字节，64位系统上占用128字节，占用空间比$remote_addr少64字节。10M大概可以保存160,000条记录。*limit_req_zone中如果key为””表示不对其进行频率限制，所以白名单将用户的key设置为””。 zone=reqzone1:10m，定义名为reqzone1大小为10M(漏桶算法桶的大小)的zone存储访问频率.共享内存空间被耗尽后则服务器将会对后续所有的请求返回503(Service Temporarily Unavailable)错误。 rate=20r/s，定义访问速率阈值，单位可以是r/s(次/秒)或者r/m(次/分钟) limit_req zone=reqzone1，选择应用的限制策略zone名称 burst=20，可选字段，缓冲请求数(特权令牌数，拥有特权令牌可以直接访问服务) nodelay，可选字段，加入该字段后超出令牌数的请求直接返回503 参考 nginx Module ngx_http_limit_req_module w3cschool·Nginx 限制IP访问频率 nginx限制某个IP同一时间段的访问次数 死磕nginx系列–nginx 限流配置 推荐文章（由hexo文章推荐插件驱动）nginx-rewrite指令中的flag参数nginx配置location匹配规则nginx配置中的if指令基于生产环境的仿真流量测试]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>DDoS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程、线程、协程]]></title>
    <url>%2F2018%2F03%2F31%2F00045_%E8%BF%9B%E7%A8%8B%E3%80%81%E7%BA%BF%E7%A8%8B%E3%80%81%E5%8D%8F%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[概念可以帮助我们更好的思考和理解。 进程(process)进程是正在运行的程序的实例，广义上是一个具有一定独立功能的程序关于某个数据集合的一次运行活动。进程是系统进行资源分配和调度的基本单位，是操作系统结构的基础。在面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。 特征： 动态性: 动态产生、动态消亡 并发性: 并发执行 独立性: 独立运行的基本单位，系统分配资源和调度的独立单位 异步性: 按各自独立不可预知的速度向前推进 结构特征： 进程由程序、数据和进程控制块三部分组成。 三种状态 就绪状态（Ready）：进程已获得除处理器外的所需资源，等待分配处理器资源；只要分配了处理器进程就可执行。 运行状态(Running)：进程占用处理器资源；处于此状态的进程的数目小于等于处理器的数目。 阻塞状态(Blocked)：由于进程等待某种条件(如I/O操作或进程同步),在条件满足之前无法继续执行。该事件发生前即使把处理器资源分配给该进程，也无法运行。 线程(thread)线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序中一个单一的顺序控制流程，是程序执行流的最小单元。也是系统独立调度和分派CPU的基本单位指令运行时的程序的调度单位。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。 特征 线程是进程中的实体，是被系统独立调度和分派的基本单位； 一个进程可以拥有多个线程，一个线程必须有一个父进程； 线程自己不拥有系统资源，只拥有一点儿在运行中必不可少的资源，但它可与同属一个进程的其它线程共享进程所拥有的全部资源； 一个线程可以创建和撤消另一个线程，同一进程中的多个线程之间可以并发执行； 线程也有就绪、阻塞和运行三种基本状态； 每一个程序都至少有一个线程，若程序只有一个线程，那就是程序本身。 协程(coroutine)协程不是进程或线程，其执行过程更类似于子例程，或者说不带返回值的函数调用。协程也是一种程序组件。相对子例程而言，协程更为一般和灵活。 特征 一个程序可以包含多个协程，可以对比与一个进程包含多个线程； 有自己的上下文，但是其切换由自己控制，由当前协程切换到其他协程由当前协程来控制； 协程的起始处是第一个入口点，在协程里，返回点之后是接下来的入口点； 协程的生命期完全由他们的使用的需要决定； 协程可以通过yield来调用其它协程。通过yield方式转移执行权的协程之间不是调用者与被调用者的关系，而是彼此对称、平等的； 协程更适合于用来实现彼此熟悉的程序组件，如合作式多任务，迭代器，无限列表和管道。 参考文档 维基百科·进程 维基百科·线程 维基百科·协程 百度百科·进程 百度百科·线程 百度百科·协程]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>进程</tag>
        <tag>线程</tag>
        <tag>协程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis持久化策略]]></title>
    <url>%2F2018%2F03%2F30%2F00044_redis%E6%8C%81%E4%B9%85%E5%8C%96%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存也可以持久化的日志型、Key-Value数据库。 两种方式RDB(Redis DataBase)redis的默认持久化机制，在指定的时间间隔内将内存中的数据集快照写入磁盘。 AOF(Append Only File)以日志的形式记录服务器所处理的每一个写操作，在Redis服务器启动之初会读取该文件来重新构建数据库，以保证启动后数据库中的数据是完整的。 Redis还可以同时使用AOF持久化和RDB持久化。在这种情况下，当 Redis重启时，它会优先使用AOF文件来还原数据集，因为AOF文件保存的数据集通常比RDB文件所保存的数据集更完整。 优缺点RDB： 优点 独立紧凑的数据文件，适用于备份和灾难恢复； RDB在恢复大数据集时的速度比AOF的恢复速度要快。 缺点 服务器故障是可能丢失一个保存时间间隔的数据； AOF: 优点 AOF 的默认策略为每秒钟fsync一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据 缺点: 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。 根据所使用的fsync策略，AOF的速度可能会慢于RDB。 配置开启RDB123save 900 1 #在900秒(15分钟)内，如果至少有1个key发生变化，则dump内存快照。 save 300 10 #在300秒(5分钟)内，如果至少有10个key发生变化，则dump内存快照。 save 60 10000 #在60秒(1分钟)内，如果至少有10000个key发生变化，则dump内存快照。 关闭 RDB1redis-cli config set save &quot;&quot; 或者变更配置 123# save 900 1# save 300 10# save 60 10000 开启 AOF1234redis-cli config set appendonly yesredis-cli config appendfsync always #每次有数据修改发生时都会写入AOF文件。 或者redis-cli config appendfsync everysec #每秒钟同步一次，该策略为AOF的缺省策略。 关闭AOF12redis-cli config set appendonly noappendfsync no #从不同步。高效但是数据不会被持久化。 参考文档 redis持久化 推荐文章（由hexo文章推荐插件驱动）redis数据结构]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>持久化</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP连接过程]]></title>
    <url>%2F2018%2F03%2F29%2F00043_TCP%E8%BF%9E%E6%8E%A5%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[传输控制协议(TCP)是一种面向连接的、可靠的、基于字节流的传输层通信协议。]]></content>
      <categories>
        <category>TCP/IP</category>
      </categories>
      <tags>
        <tag>三次握手</tag>
        <tag>四次挥手</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http协议头字段说明]]></title>
    <url>%2F2018%2F03%2F28%2F00042_http%E5%8D%8F%E8%AE%AE%E5%A4%B4%E5%AD%97%E6%AE%B5%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[HTTP协议头字段定义了一个超文本传输协议事务中的操作参数。 按照惯例，非标准的协议头字段是在字段名称前加上X-前缀来标识。 标准中没有对每个协议头字段的名称和值的大小设置任何限制，也没有限制字段的个数。在实际场景中出于安全性的考虑，大部分的服务器、客户端和代理软件都会实施一些限制。 http请求字段请求字段 协议头字段名 说明 示例 Accept 能够接受的回应内容类型(Content-Types)。 Accept: text/plain Accept-Charset 能够接受的字符集。 Accept-Charset: utf-8 Accept-Encoding 能够接受的编码方式列表。 Accept-Encoding: gzip, deflate Accept-Language 能够接受的回应内容的自然语言列表。 Accept-Language: en-US Accept-Datetime 能够接受的按照时间来表示的版本。 Accept-Datetime: Thu, 31 May 2007 20:35:00 GMT Authorization 用于超文本传输协议的认证的认证信息。 Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Cache-Control 用来指定在这次的请求/响应链中的所有缓存机制 都必须 遵守的指令。 Cache-Control: no-cache Connection 该浏览器想要优先使用的连接类型。 Connection: keep-alive Connection: Upgrade Cookie 之前由服务器通过Set- Cookie发送的一个超文本传输协议Cookie。 Cookie: $Version=1; Skin=new; Content-Length 以八位字节数组(8位的字节)表示的请求体的长度。 Content-Length: 348 Content-MD5 请求体的内容的二进制 MD5 散列值，以 Base64 编码的结果。 Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ== Content-Type 请求体的多媒体类型(用于POST和PUT请求中)。 Content-Type: application/x-www-form-urlencoded Date 发送该消息的日期和时间(按照 RFC 7231 中定义的”超文本传输协议日期”格式来发送)。 Date: Tue, 15 Nov 1994 08:12:31 GMT Expect 表明客户端要求服务器做出特定的行为。 Expect: 100-continue From 发起此请求的用户的邮件地址。 From: user@example.com Host 服务器的域名(用于虚拟主机)，以及服务器所监听的传输控制协议端口号。自HTTP/1.1开始成为必需字段。 Host: lengyuewusheng.com:80 Host: lengyuewusheng.com If-Match 仅当客户端提供的实体与服务器上对应的实体相匹配时，才进行对应的操作。主要作用时，用作像 PUT 这样的方法中，仅当从用户上次更新某个资源以来，该资源未被修改的情况下，才更新该资源。 If-Match: “737060cd8c284d8af7ad3082f209582d” If-Modified-Since 允许在对应的内容未被修改的情况下返回304未修改(304 Not Modified)。 If-Modified-Since: Sat, 29 Oct 1994 19:43:31 GMT If-None-Match 允许在对应的内容未被修改的情况下返回304未修改(304 Not Modified)。 If-None-Match: “a7dc0d7b8902e9c8c096c93eb431d19e” If-Range 如果该实体未被修改过，则向我发送我所缺少的那一个或多个部分；否则，发送整个新的实体 If-Range: “a7dc0d7b8902e9c8c096c93eb431d19e” If-Unmodified-Since 仅当该实体自某个特定时间已来未被修改的情况下，才发送回应。 If-Unmodified-Since: Sat, 29 Oct 1994 19:43:31 GMT Max-Forwards 限制该消息可被代理及网关转发的次数。 Max-Forwards: 10 Origin 发起一个针对跨来源资源共享的请求(要求服务器在回应中加入一个’访问控制-允许来源’(‘Access-Control-Allow-Origin’)字段)。 Origin: http://www.example-social-network.com Pragma 报文指令，与具体的实现相关，这些字段可能在请求/回应链中的任何时候产生多种效果。不常用。 Pragma: no-cache Proxy-Authorization 用来向代理进行认证的认证信息。 Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Range 仅请求某个实体的一部分。字节偏移以0开始。参见字节服务。 Range: bytes=500-999 Referer 表示浏览器所访问的前一个页面，正是那个页面上的某个链接将浏览器带到了当前所请求的这个页面。 Referer: https://www.lengyuewusheng.com TE 浏览器预期接受的传输编码方式：可使用回应协议头 Transfer-Encoding 字段中的值；另外还可用”trailers”(与”分块 “传输方式相关)这个值来表明浏览器希望在最后一个尺寸为0的块之后还接收到一些额外的字段。 TE: trailers, deflate User-Agent 浏览器的浏览器身份标识字符串。 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36 Upgrade 要求服务器升级到另一个协议。 Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11 Via 向服务器告知，这个请求是由哪些代理发出的。 Via: 1.0 fred, 1.1 example.com (Apache/1.1) Warning 一个一般性的警告，告知，在实体内容体中可能存在错误。 Warning: 199 Miscellaneous warning 非标准请求字段 协议头非标准字段名 说明 示例 X-Requested-With 主要用于标识 Ajax 及可扩展标记语言 请求。大部分的JavaScript框架会发送这个字段，且将其值设置为 XMLHttpRequest。 X-Requested-With: XMLHttpRequest DNT 请求某个网页应用程序停止跟踪某个用户。在火狐浏览器中，相当于X-Do-Not-Track协议头字段(自 Firefox/4.0 Beta 11 版开始支持)。Safari和Internet Explorer 9也支持这个字段。 启用：DNT: 1 禁用：DNT: 0 X-Forwarded-For 一个事实标准 ，用于标识某个通过超文本传输协议代理或负载均衡连接到某个网页服务器的客户端的原始互联网地址。 X-Forwarded-For: client1, proxy1, proxy2 X-Forwarded-For: 129.78.138.66, 129.78.64.103 X-Forwarded-Host 一个事实标准 ，用于识别客户端原本发出的 Host 请求头部。 X-Forwarded-Host: lengyuewusheng.com:80 X-Forwarded-Host: lengyuewusheng.com X-Forwarded-Proto 一个事实标准，用于标识某个超文本传输协议请求最初所使用的协议。 X-Forwarded-Proto: https Front-End-Https 被微软的服务器和负载均衡器所使用的非标准头部字段。 Front-End-Https: on X-Http-Method-Override 请求某个网页应用程序使用该协议头字段中指定的方法(一般是PUT或DELETE)来覆盖掉在请求中所指定的方法(一般是POST)。当某个浏览器或防火墙阻止直接发送PUT 或DELETE 方法时，可使用这种方式。 X-HTTP-Method-Override: DELETE X-ATT-DeviceId 使服务器更容易解读AT&amp;T设备User-Agent字段中常见的设备型号、固件信息。 X-Att-Deviceid: GT-P7320/P7320XXLPG X-Wap-Profile 链接到互联网上的一个XML文件，其完整、仔细地描述了正在连接的设备。 以为AT&amp;T Samsung Galaxy S2提供的XML文件为例：x-wap-profile: http://wap.samsungmobile.com/uaprof/SGH-I777.xml Proxy-Connection 该字段源于早期超文本传输协议版本实现中的错误。与标准的连接(Connection)字段的功能完全相同。 Proxy-Connection: keep-alive X-Csrf-Token 用于防止 跨站请求伪造。辅助用的头部有 X-CSRFToken或 X-XSRF-TOKEN。 X-Csrf-Token: i8XNjC4b8KVok4uw5RftR38Wgp2BFwql http回应字段回应字段 协议头字段名 说明 示例 Access-Control-Allow-Origin 指定哪些网站可参与到跨来源资源共享过程中。 Access-Control-Allow-Origin: * Accept-Patch 指定服务器支持的文件格式类型。 Accept-Patch: text/example;charset=utf-8 Accept-Ranges 这个服务器支持哪些种类的部分内容范围。 Accept-Ranges: bytes Age 这个对象在代理缓存中存在的时间，以秒为单位。 Age: 12 Allow 对于特定资源有效的动作。针对HTTP/405这一错误代码而使用。 Allow: GET, HEAD Cache-Control 向从服务器直到客户端在内的所有缓存机制告知，它们是否可以缓存这个对象。其单位为秒。 Cache-Control: max-age=3600 Connection 针对该连接所预期的选项。 Connection: close Content-Disposition 一个可以让客户端下载文件并建议文件名的头部。文件名需要用双引号引起来。 Content-Disposition: attachment; filename=”fname.ext” Content-Encoding 在数据上使用的编码类型。 Content-Encoding: gzip Content-Language 内容所使用的语言。 Content-Language: da Content-Length 回应消息体的长度，以字节(8位为一字节)为单位。 Content-Length: 348 Content-Location 所返回的数据的一个候选位置。 Content-Location: /index.htm Content-MD5 回应内容的二进制 MD5 散列，以 Base64 方式编码。 Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ== Content-Range 这条部分消息是属于某条完整消息的哪个部分。 Content-Range: bytes 21010-47021/47022 Content-Type 当前内容的MIME类型。 Content-Type: text/html; charset=utf-8 Date 此条消息被发送时的日期和时间(按照 RFC 7231 中定义的“超文本传输协议日期”格式来表示) Date: Tue, 15 Nov 2017 08:12:31 GMT ETag 对于某个资源的某个特定版本的一个标识符，通常是一个 消息散列。 ETag: “737060cd8c284d8af7ad3082f209582d” Expires 指定一个日期/时间，超过该时间则认为此回应已经过期。 Expires: Thu, 01 Dec 1994 16:00:00 GMT Last-Modified 所请求的对象的最后修改日期(按照 RFC 7231 中定义的“超文本传输协议日期”格式来表示) Last-Modified: Tue, 15 Nov 1994 12:45:26 GMT Link 用来表达与另一个资源之间的类型关系。 Link: ; rel=”alternate” Location 用来进行重定向，或者在创建了某个新资源时使用。 Location: http://lengyuewusheng.com P3P 用于支持设置P3P策略，标准格式为“P3P:CP=”your_compact_policy””。然而P3P规范并不成功，大部分现代浏览器没有完整实现该功能。 P3P: CP=”This is not a P3P policy!” Pragma 报文指令，与具体的实现相关，这些字段可能在请求/回应链中的任何时候产生多种效果。 Pragma: no-cache Proxy-Authenticate 要求在访问代理时提供身份认证信息。 Proxy-Authenticate: Basic Public-Key-Pins 用于缓解中间人攻击，声明网站认证使用的传输层安全协议证书的散列值。 Public-Key-Pins: max-age=2592000; pin-sha256=”E9CZ9INDbd+2eRQozYqqbQ2yXLVKB9+xcprMF+44U1g=”; Refresh 用于设定可定时的重定向跳转。 5秒后跳转，Refresh: 5; url=http://www.w3.org/pub/WWW/People.html Retry-After 如果某个实体临时不可用，则此协议头用来告知客户端日后重试。其值可以是一个特定的时间段(以秒为单位)或一个超文本传输协议日期。 Example 1: Retry-After: 120 Example 2: Retry-After: Fri, 07 Nov 2014 23:59:59 GMT Server 服务器的名字。 Server: Apache/2.4.1 (Unix) Set-Cookie HTTP cookie Set-Cookie: UserID=JohnDoe; Max-Age=3600; Version=1 Status 通用网关接口 协议头字段，用来说明当前这个超文本传输协议回应的 状态 。 Status: 200 OK Strict-Transport-Security HTTP严格传输安全这一头部告知客户端缓存这一强制 HTTPS 策略的时间，以及这一策略是否适用于其子域名。 Strict-Transport-Security: max-age=16070400; includeSubDomains Trailer 这个头部数值指示了在这一系列头部信息由由分块传输编码编码。 Trailer: Max-Forwards Transfer-Encoding 用来将实体安全地传输给用户的编码形式。当前定义的方法包括：分块（chunked）、compress、deflate、gzip和identity。 Transfer-Encoding: chunked Upgrade 要求客户端升级到另一个协议。 Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11 Vary 告知下游的代理服务器，应当如何对未来的请求协议头进行匹配，以决定是否可使用已缓存的回应内容而不是重新从原始服务器请求新的内容。 Vary: * Via 告知代理服务器的客户端，当前回应是通过什么途径发送的。 Via: 1.0 fred, 1.1 example.com (Apache/1.1) Warning 一般性的警告，告知在实体内容体中可能存在错误。 Warning: 199 Miscellaneous warning WWW-Authenticate 表明在请求获取这个实体时应当使用的认证模式。 WWW-Authenticate: Basic X-Frame-Options 点击劫持保护： deny：该页面不允许在 frame 中展示，即使是同域名内； sameorigin：该页面允许同域名内在 frame 中展示。 allow-from uri：该页面允许在指定uri的 frame 中展示。 allowall：允许任意位置的frame显示，非标准值。 X-Frame-Options: deny 非标准回应字段 协议头字段名 说明 示例 X-XSS-Protection 跨站脚本攻击(XSS)过滤器。 X-XSS-Protection: 1; mode=block Content-Security-Policy, X-Content-Security-Policy, X-WebKit-CSP 内容安全策略定义。 X-WebKit-CSP: default-src ‘self’ X-Content-Type-Options 唯一允许的数值为”nosniff”，防止 Internet Explorer 对文件进行MIME类型嗅探。这也对 Google Chrome 下载扩展时适用。 X-Content-Type-Options: nosniff X-Powered-By 表明用于支持当前网页应用程序的技术。 (例如：PHP)(版本号细节通常放置在X-Runtime或X-Version中) X-Powered-By: PHP/7.1.0 X-UA-Compatible 推荐指定的渲染引擎(通常是向后兼容模式)来显示内容。也用于激活Internet Explorer中的 Chrome Frame。 X-UA-Compatible: IE=EmulateIE7 X-UA-Compatible: IE=edge X-UA-Compatible: Chrome=1 X-Content-Duration 指出音视频的长度，单位为秒。只受Gecko内核浏览器支持。 X-Content-Duration: 42.666 参考文档 wikipedia·http头字段 http首部 推荐文章（由hexo文章推荐插件驱动）http不同版本及特性概括HTTP协议中的8种请求方法http请求常见状态码及解释HTTP协议中的8种请求方法七层网络协议]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RAID技术总结]]></title>
    <url>%2F2018%2F03%2F27%2F00041_RAID%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[独立硬盘冗余阵列(RAID, Redundant Array of Independent Disks),简称磁盘阵列。简单来说，RAID把多个硬盘组合成为一个逻辑扇区，因此，操作系统只会把它当作一个硬盘。 table th:nth-of-type(7){width: 30%;} nth-of-type(8){width: 20%;} 磁盘阵列比较表 RAID档次 最少硬盘 最大容错 磁盘利用率 读取性能 写入性能 安全性 目的 应用产业 0 2 0 100% n n 一个硬盘异常，全部硬盘都会异常 追求最大容量、速度 视频剪接缓存用途 1 2 n-1 1/n n 1 最高，一个正常即可 追求最大安全性 个人、企业备份 5 3 1 (n-1)/n n-1 n-1 高 追求最大容量、最小预算 个人、企业备份 6 4 2 (n-2)/n n-2 n-2 安全性较RAID 5高 同RAID 5，但较安全 个人、企业备份 10 4 n/2 50% n/2 n/2 安全性高，但在同一个子组群中不能出现两颗毁损硬盘 综合RAID 0/1优点，理论速度较快 大型数据库、服务器 50 6 n/m 1-1/m n-n/m n-n/m 安全性高，但在同一个子组群中不能出现两颗毁损硬盘 高可靠性、高读取速度 事务处理 n代表硬盘总数 m 代表 RAID 5 的组盘数量 特点总结 读写性能最高：RAID 0 磁盘利用率最低：RAID 1 (1/n) 可靠性最高：RAID 1 常见RAID级别RAID 0RAID 0亦称为带区集。它将两个以上的磁盘并联起来，成为一个大容量的磁盘。 读写速度最快：因为读写时都可以并行处理，所以在所有的级别中，RAID 0的速度是最快的； 无冗余无容错：RAID 0既没有冗余功能，也不具备容错能力，如果一个磁盘（物理）损坏，所有数据都会丢失。 RAID 1两组以上的N个磁盘相互作镜像。在主硬盘上存放数据的同时也在镜像硬盘上写一样的数据。当主硬盘（物理）损坏时，镜像硬盘则代替主硬盘的工作。 读写速度：在一些多线程操作系统中能有很好的读取速度，理论上读取速度等于硬盘数量的倍数，与RAID 0相同。写入速度有微小的降低； 可靠性最高：只要一个磁盘正常即可维持运作； 数据完全性最好：因为有镜像硬盘做数据备份； 磁盘利用率最低：无论用多少磁盘做RAID 1，仅算一个磁盘的容量； 不同大小磁盘的情况：如果用两个不同大小的磁盘建RAID 1，可用空间为较小的那个磁盘，较大的磁盘多出来的空间也可以分区成一个区来使用，不会造成浪费。 RAID 5RAID 5是一种储存性能、数据安全和存储成本兼顾的存储解决方案。它使用的是Disk Striping（硬盘分区）技术。RAID 5可以理解为是RAID 0和RAID 1的折衷方案。 RAID 5至少需要三个硬盘，RAID 5不是对存储的数据进行备份，而是把数据和相对应的奇偶校验信息分别存储于不同的磁盘上； 可靠性：数据保障程度要比RAID 1低； 读写速度：RAID 5具有和RAID 0相近似的数据读取速度，由于多一个奇偶校验信息，写入数据的速度相对单独写入一块硬盘的速度略慢，使用“回写缓存”可以让性能改善； 磁盘利用率：RAID 5的磁盘空间利用率要比RAID 1高。因为多个数据对应一个奇偶校验信息； RAID 5最多支持坏一块盘。 RAID 6与RAID 5相比，RAID 6增加第二个独立的奇偶校验信息块。两个独立的奇偶系统使用不同的算法。 RAID 6必须具备四个以上的磁盘才能生效。 数据的可靠性：非常高，任意两块磁盘同时失效时不会影响数据完整性。 通常通过硬件方式实现：RAID 6需要分配给奇偶校验信息更大的磁盘空间和额外的校验计算，相对于RAID 5有更大的IO操作量和计算量，因此其“写性能”强烈取决于具体的实现方案。 磁盘利用率：可使用的容量为硬盘总数减去2的差，乘以最小容量。 最多容许两个磁盘损坏。 RAID 10/01RAID 10是先镜像再分区数据，再将所有硬盘分为两组，视为是RAID 0的最低组合，然后将这两组各自视为RAID 1运作。 RAID 01则是先分区再将数据镜像到两组硬盘。它将所有的硬盘分为两组，变成RAID 1的最低组合，并将两组硬盘各自视为RAID 0运作。 RAID 10有一个硬盘受损，其余硬盘会继续运作。 RAID 01只要有一个硬盘受损，同组RAID 0的所有硬盘都会停止运作，只剩下其他组的硬盘运作，可靠性较低。如果以六块硬盘建RAID 01，镜像后再用三块盘建RAID 0，那么坏一块硬盘便会有三个硬盘离线。 RAID 10远较RAID 01常用。 RAID 50RAID 5与RAID 0的组合，先作RAID 5，再作RAID 0，也就是对多组RAID 5彼此构成Stripe访问。以RAID 50最小的6颗硬盘配置为例，先把6颗硬盘分为2组，每组3颗构成RAID 5，如此就得到两组RAID 5，然后再把两组RAID 5构成RAID 0。 RAID 50，至少需要6颗硬盘； 数据可靠性：RAID 50在底层的任一组或多组RAID 5中出现1颗硬盘损坏时，仍能维持运作，不过如果任一组RAID 5中出现2颗或2颗以上硬盘损毁，整组RAID 50就会失效； 读写性能：RAID 50由于在上层把多组RAID 5构成Stripe，性能比起单纯的RAID 5高； 磁盘利用率：((n-m)/n)，比RAID5((n-1)/n)要低。 参考文档 wikipedia·RAID 百度百科·RAID50 RAID技术全解]]></content>
      <categories>
        <category>raid</category>
      </categories>
      <tags>
        <tag>RAID</tag>
        <tag>磁盘阵列</tag>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http请求常见状态码及解释]]></title>
    <url>%2F2018%2F03%2F26%2F00040_http%E8%AF%B7%E6%B1%82%E5%B8%B8%E8%A7%81%E7%8A%B6%E6%80%81%E7%A0%81%E5%8F%8A%E8%A7%A3%E9%87%8A%2F</url>
    <content type="text"><![CDATA[在http请求中，服务器返回的响应报文的第一行包含了状态码以及原因短语，用来告知客户端请求的结果。 table th:nth-of-type(1){width: 10%;} nth-of-type(2){width: 30%;} HTTP 状态码 状态码 含义 解释 1XX Informational（信息性状态码） 接收的请求正在处理 100 Continue 表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。 101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，如，切换到HTTP的新版本协议。 102 Processing WebDAV请求可能包含许多涉及文件操作的子请求，需要很长时间才能完成请求。该代码表示​​服务器已经收到并正在处理请求，但无响应可用。这样可以防止客户端超时，并假设请求丢失。 2XX Success（成功状态码） 请求被成功接收并处理 200 OK 请求已成功，请求所希望的响应头或数据体将随此响应返回。实际的响应将取决于所使用的请求方法。在GET请求中，响应将包含与请求的资源相对应的实体。在POST请求中，响应将包含描述或操作结果的实体。 201 Created 已创建。成功请求并创建了新的资源。 202 Accepted 已接受。已经接受请求，但未处理完成。 203 Non-Authoritative Information 非授权信息。请求成功。但返回的Meta信息不在原始的服务器，而是一个副本。 204 No Content 请求已经成功处理，但未返回内容，即返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。 205 Reset Content 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域。 206 Partial Content 部分内容，表示客户端进行了范围请求。服务器成功处理了部分GET请求，响应报文包含由 Content-Range 指定范围的实体内容。 207 Multi-Status（WebDAV；RFC 4918） 代表之后的消息体将是一个XML消息，并且可能依照之前子请求数量的不同，包含一系列独立的响应代码。 208 Already Reported （WebDAV；RFC 5842） DAV绑定的成员已经在（多状态）响应之前的部分被列举，且未被再次包含。 226 IM Used （RFC 3229） 服务器已经满足了对资源的请求，对实体请求的一个或多个实体操作的结果表示。 3XX Redirection（重定向状态码） 重定向，需要进一步的操作以完成请求 300 Multiple Choices 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择。 301 Moved Permanently 永久性重定向。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替。 302 Found 临时性重定向。与301类似。但资源只是临时被移动。客户端应继续使用原有URI。 303 See Other 查看其它地址。和302有着相同的功能，但是303明确要求客户端应该采用GET方法获取资源。 304 Not Modified 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源。 305 Use Proxy 使用代理。所请求的资源必须通过代理访问。 306 Unused 已经被废弃的HTTP状态码。 307 Temporary Redirect 临时重定向。与302类似。但是307要求浏览器不会把重定向请求的POST方法改成GET方法。 308 Permanent Redirect (RFC 7538) 请求和所有将来的请求应该使用另一个URI重复。 307和308重复302和301的行为，但不允许HTTP方法更改。 例如，将表单提交给永久重定向的资源可能会顺利进行。 4XX Client Error（客户端错误状态码） 服务器无法处理请求 400 Bad Request 请求报文中存在语法错误，服务器无法理解。 401 Unauthorized 该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。 402 Payment Required 保留，将来使用。 403 Forbidden 服务器理解请求客户端的请求，但是拒绝执行此请求。服务器端没有必要给出拒绝的详细理由。 404 Not Found 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置”您所请求的资源无法找到”的个性页面。 405 Method Not Allowed 客户端请求中的方法被禁止。 406 Not Acceptable 服务器无法根据客户端请求的内容特性完成请求。 407 Proxy Authentication Required 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权。 408 Request Time-out 服务器等待客户端发送的请求时间过长，超时。 409 Conflict 服务器完成客户端的PUT请求是可能返回此代码，服务器处理请求时发生了冲突。 410 Gone 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置。 411 Length Required 服务器无法处理客户端发送的不带Content-Length的请求信息。 412 Precondition Failed 客户端请求信息的先决条件错误。 413 Request Entity Too Large 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息。 414 Request-URI Too Large 请求的URI过长（URI通常为网址），服务器无法处理。 415 Unsupported Media Type 服务器无法处理请求附带的媒体格式。 416 Requested range not satisfiable 客户端请求的范围无效。 417 Expectation Failed 服务器无法满足Expect的请求头信息。 421 Misdirected Request （RFC 7540） 该请求针对的是无法产生响应的服务器（例如因为连接重用）。 422 Unprocessable Entity（WebDAV；RFC 4918 ） 请求格式正确，但是由于含有语义错误，无法响应。 423 Locked（WebDAV；RFC 4918） 当前资源被锁定。 424 Failed Dependency（WebDAV；RFC 4918） 由于之前的某个请求发生的错误，导致当前请求失败，例如PROPPATCH。 426 Upgrade Required（RFC 2817） 客户端应当切换到TLS/1.0，并在HTTP/1.1 Upgrade header中给出。 428 Precondition Required (RFC 6585) 原服务器要求该请求满足一定条件。这是为了防止‘未更新’问题，即客户端读取（GET）一个资源的状态，更改它，并将它写（PUT）回服务器，但这期间第三方已经在服务器上更改了该资源的状态，因此导致了冲突。 429 Too Many Requests （RFC 6585） 用户在给定的时间内发送了太多的请求。旨在用于网络限速。 431 Request Header Fields Too Large （RFC 6585） 服务器不愿处理请求，因为一个或多个头字段过大。 444 No Response Nginx上HTTP服务器扩展。服务器不向客户端返回任何信息，并关闭连接（有助于阻止恶意软件）。 450 Blocked by Windows Parental Controls 这是一个由Windows家庭控制（Microsoft）HTTP阻止的450状态代码的示例，用于信息和测试。 451 Unavailable For Legal Reasons 该访问因法律的要求而被拒绝，由IETF在2015核准后新增加。 494 Request Header Too Large 在错误代码431提出之前Nginx上使用的扩展HTTP代码。 499 Client has Closed Connection 客户端已经断开链接。可能是客户端主动断开，也有可能是超时断开。 5XX Server Error（服务器错误状态码） 服务器处理请求出错 500 Internal Server Error 服务器内部错误，无法完成请求。 501 Not Implemented 服务器不支持请求的功能，无法完成请求。通常出现在nginx没有定义对应的server配置时出现。 502 Bad Gateway 充当网关或代理的服务器，从远端服务器接收到了一个无效的请求。 503 Service Unavailable 服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。延时的长度可包含在服务器的Retry-After头信息中。 504 Gateway Time-out 充当网关或代理的服务器，未及时从远端服务器获取请求。 505 HTTP Version not supported 服务器不支持请求的HTTP协议的版本，无法完成处理。 506 Variant Also Negotiates（RFC 2295） 由《透明内容协商协议》（RFC 2295）扩展，代表服务器存在内部配置错误，被请求的协商变元资源被配置为在透明内容协商中使用自己，因此在一个协商处理中不是一个合适的重点。 507 Insufficient Storage（WebDAV；RFC 4918） 服务器无法存储完成请求所必须的内容。这个状况被认为是临时的。 508 Loop Detected （WebDAV；RFC 5842） 服务器在处理请求时陷入死循环。（可代替 208状态码） 510 Not Extended（RFC 2774） 获取资源所需要的策略并没有被满足。 511 Network Authentication Required （RFC 6585） 客户端需要进行身份验证才能获得网络访问权限，旨在限制用户群访问特定网络。（例如连接WiFi热点时的强制网络门户） 虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。 WebDAV是基于Web的分布式编写和版本控制，是超文本传输协议（HTTP）的扩展。有利于用户间协同编辑和管理存储在万维网服务器文档。许多现代操作系统为WebDAV提供了内置的客户端支持。 参考文档 WikiPedia·http状态码 菜鸟教程·http状态码 Interview-Notebook 推荐文章（由hexo文章推荐插件驱动）http不同版本及特性概括HTTP协议中的8种请求方法http协议头字段说明HTTP协议中的8种请求方法七层网络协议]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>协议</tag>
        <tag>状态码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过Zabbix API在告警邮件中插入趋势图]]></title>
    <url>%2F2018%2F03%2F25%2F00039_Zabbix%E5%91%8A%E8%AD%A6%E9%82%AE%E4%BB%B6%E4%B8%AD%E6%8F%92%E5%85%A5%E8%B6%8B%E5%8A%BF%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[告警邮件中嵌入趋势图是非常人性化的设计，只有有温度的告警邮件才会嵌入趋势图。。。 以下内容基于zabbix 3.0.2 测试有效，想必其它版本应该也问题不大。 话不多说，直接上代码： 邮件告警脚本 cat mailAlarm.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#!/bin/bash# Description: 获取某一个监控项在某个时间段的graph# Date: # Author: #=========================================ALERT_SENDTO="$1"ALERT_SUBJECT="$2"ALERT_MESSAGE="$(echo -e "$3"|sed -e '$d' -e 's/$/&lt;br\/&gt;/g')"ITEMID="$(echo -e "$3"|tail -n1|awk -F":" '&#123;print $2&#125;'|sed s/[[:space:]]//g)"USERNAME="$4"PASSWORD="$5"STIME="$(date -d "1 hour ago" "+%Y%m%d%H%M%S")"PERIOD=3600WIDTH=800#=========================================ROOTPATH="$(cd $(dirname $0) &amp;&amp; pwd)"LOGFILE="$&#123;ROOTPATH&#125;/logs/$(basename $0).log.$(date "+%Y-%m-%d")"# 在zabbix-web根目录下创建一个graphs目录用来存放趋势图图片文件GRAPH_DIR="/usr/local/zabbix-web/graphs"COOKIE="$&#123;ROOTPATH&#125;/.zabbixCookie.$&#123;USERNAME&#125;"CURL="/usr/bin/curl -s"ZBX_URL="http://zabbix.server.url"INDEX_URL="$ZBX_URL/index.php"CHART_URL="$ZBX_URL/chart.php"PNG_PATH="$GRAPH_DIR/$STIME.$PERIOD.$&#123;WIDTH&#125;.$ITEMID.png"function help()&#123; cat &lt;&lt; EOFUsage: sh $0 ALERT_SENDTO ALERT_SUBJECT ALERT_MESSAGE USERNAME PASSWORD EOF&#125;# 简单记一下日志function writeLogs()&#123; [ ! -d "$(dirname "$&#123;LOGFILE&#125;")" ] &amp;&amp; mkdir -p "$(dirname "$&#123;LOGFILE&#125;")" echo -e "$(date "+%Y-%m-%d %H:%M:%S")\t$1" &gt;&gt;"$&#123;LOGFILE&#125;"&#125;function check_integer()&#123; local ret=`echo "$*" | sed 's/[0-9]//g'` [ -n "$ret" ] &amp;&amp; return 1 return 0&#125;# 简单校验参数function ParametersVerification()&#123; [ -d "$GRAPH_DIR" ] || mkdir -p "$GRAPH_DIR" check_integer "$ITEMID" || &#123; echo "ERROR: Field 'ITEMID' is not integer."; exit 1;&#125; check_integer "$STIME" || &#123; echo "ERROR: Field 'STIME' is not integer."; exit 1;&#125; check_integer "$PERIOD" || &#123; echo "ERROR: Field 'PERIOD' is not integer."; exit 1;&#125; check_integer "$WIDTH" || &#123; echo "ERROR: Field 'WIDTH' is not integer."; exit 1;&#125; [ $PERIOD -lt 3600 -o $PERIOD -gt 63072000 ] &amp;&amp; &#123; echo "ERROR: Incorrect value $PERIOD for PERIOD field: must be between 3600 and 63072000."; exit 1;&#125; # USERNAME、PASSWORD、ITEMID为必需参数 [ -z "$USERNAME" -o -z "$PASSWORD" -o -z "$ITEMID" ] &amp;&amp; &#123; echo "ERROR: Missing mandatory parameter."; help;&#125; # 如果没有传入STIME参数，STIME的值为当前时间减去PERIOD [ "$STIME" == "" ] &amp;&amp; STIME=`date -d "now -$&#123;PERIOD&#125; second" +%Y%m%d%H%M%S`&#125;# 关键步骤，获取cookie并写入文件function getCookie()&#123; /usr/bin/chattr -i $&#123;COOKIE&#125; $&#123;CURL&#125; -c $&#123;COOKIE&#125; -d "name=$&#123;USERNAME&#125;&amp;password=$&#123;PASSWORD&#125;&amp;autologin=1&amp;enter=Sign+in" $INDEX_URL | egrep -o "(Login name or passwordis incorrect|Account is blocked.*seconds)" # 如果登录失败则退出脚本，并清空cookie文件 [ $&#123;PIPESTATUS[1]&#125; -eq 0 ] &amp;&amp; &#123; echo &gt;"$COOKIE"; exit 1;&#125; /usr/bin/chattr +i $&#123;COOKIE&#125;&#125;# 获取趋势图文件function getGraph()&#123; # zabbix3.0- #$&#123;CURL&#125; -b $&#123;COOKIE&#125; -d "itemid=$&#123;ITEMID&#125;&amp;period=$&#123;PERIOD&#125;&amp;stime=$&#123;STIME&#125;&amp;width=$&#123;WIDTH&#125;" $CHART_URL &gt; "$PNG_PATH" # zabbix3.0+ $&#123;CURL&#125; -b $&#123;COOKIE&#125; -d "itemids%5B0%5D=$&#123;ITEMID&#125;&amp;period=$&#123;PERIOD&#125;&amp;stime=$&#123;STIME&#125;&amp;width=$&#123;WIDTH&#125;" $&#123;CHART_URL&#125; &gt; "$&#123;PNG_PATH&#125;"&#125;# 发送告警function sendMessage()&#123; /usr/bin/php $&#123;ROOTPATH&#125;/mailer/sendmail.php "$&#123;ALERT_SENDTO&#125;" "$&#123;ALERT_SUBJECT&#125;" "$&#123;ALERT_MESSAGE&#125;" "$(basename $&#123;PNG_PATH&#125;)" "$&#123;ITEMID&#125;"&#125;function main()&#123; if [ ! -s "$&#123;COOKIE&#125;" ];then getCookie fi getGraph if [ -s "$&#123;PNG_PATH&#125;" ]; then sendMessage writeLogs "$(date "+%Y-%m-%d %H:%M:%S")\t send to $&#123;ALERT_SENDTO&#125;\t subject:$&#123;ALERT_SUBJECT&#125;\t transmit status:$?" else writeLogs "$(date "+%Y-%m-%d %H:%M:%S")\t send to $&#123;ALERT_SENDTO&#125;\t subject:$&#123;ALERT_SUBJECT&#125;\t transmit status:$? \t $PNG_PATH doesn't exist." fi&#125;[[ "$1" =~ "help" ]] &amp;&amp; &#123; help ; exit 0; &#125;main 邮件告警脚本，同目录下创建一个mailer目录，mailer目录下存放swiftmailer源码 邮件模板及smtp服务 cat mailer/sendmail.php123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185&lt;?phprequire_once ''. dirname(__FILE__) . '/vendor/autoload.php';$sendto = $argv[1];$subject = $argv[2];$content = $argv[3];$graphName = $argv[4];$itemId = $argv[5];// Create the Transport$transport = (new Swift_SmtpTransport('smtp.xxxmail.com', 25)) -&gt;setUsername('AuthenticatedUser@xxxmail.com') -&gt;setPassword('password');// Create the Mailer using your created Transport$mailer = new Swift_Mailer($transport);// To use the ArrayLogger#$logger = new Swift_Plugins_Loggers_ArrayLogger();#$mailer-&gt;registerPlugin(new Swift_Plugins_LoggerPlugin($logger));// Or to use the Echo Logger#$logger = new Swift_Plugins_Loggers_EchoLogger();#$mailer-&gt;registerPlugin(new Swift_Plugins_LoggerPlugin($logger));// Create a message$message = (new Swift_Message($subject)) -&gt;setFrom(['Admin@xxxmail.com' =&gt; 'Notice']) -&gt;setTo([ $sendto =&gt; 'Swift Mailer']);$message-&gt;setBody('&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt; &lt;!-- So that mobile will display zoomed in --&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;!-- enable media queries for windows phone 8 --&gt; &lt;meta name="format-detection" content="telephone=no"&gt; &lt;!-- disable auto telephone linking in iOS --&gt; &lt;title&gt;Two Columns to Rows (Simple)&lt;/title&gt; &lt;style type="text/css"&gt;body &#123; margin: 0; padding: 0; -ms-text-size-adjust: 100%; -webkit-text-size-adjust: 100%;&#125;table &#123; border-spacing: 0;&#125;table td &#123; border-collapse: collapse;&#125;.ExternalClass &#123; width: 100%;&#125;.ExternalClass,.ExternalClass p,.ExternalClass span,.ExternalClass font,.ExternalClass td,.ExternalClass div &#123; line-height: 100%;&#125;.ReadMsgBody &#123; width: 100%; background-color: #ebebeb;&#125;table &#123; mso-table-lspace: 0pt; mso-table-rspace: 0pt;&#125;img &#123; -ms-interpolation-mode: bicubic;&#125;.yshortcuts a &#123; border-bottom: none !important;&#125;@media screen and (max-width: 599px) &#123; .force-row, .container &#123; width: 100% !important; max-width: 100% !important; &#125;&#125;@media screen and (max-width: 400px) &#123; .container-padding &#123; padding-left: 12px !important; padding-right: 12px !important; &#125;&#125;.ios-footer a &#123; color: #aaaaaa !important; text-decoration: underline;&#125;&lt;/style&gt;&lt;/head&gt;&lt;body style="margin:0; padding:0;" bgcolor="#F0F0F0" leftmargin="0" topmargin="0" marginwidth="0" marginheight="0"&gt;&lt;!-- 100% background wrapper (grey background) --&gt;&lt;table border="0" width="100%" height="100%" cellpadding="0" cellspacing="0" bgcolor="#F0F0F0"&gt; &lt;tr&gt; &lt;td align="center" valign="top" bgcolor="#F0F0F0" style="background-color: #F0F0F0;"&gt; &lt;br&gt; &lt;!-- 600px container (white background) --&gt; &lt;table border="0" width="600" cellpadding="0" cellspacing="0" class="container" style="width:600px;max-width:600px"&gt; &lt;tr&gt; &lt;td class="container-padding header" align="left" style="font-family:Helvetica, Arial, sans-serif;font-size:24px;font-weight:bold;padding-bottom:12px;color:#DF4726;padding-left:24px;padding-right:24px"&gt; 告警/恢复信息: &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="container-padding content" align="left" style="padding-left:24px;padding-right:24px;padding-top:12px;padding-bottom:12px;background-color:#ffffff"&gt; &lt;br&gt;&lt;div class="title" style="font-family:Helvetica, Arial, sans-serif;font-size:18px;font-weight:600;color:#374550"&gt; ' . $subject . '&lt;/div&gt;&lt;div class="body-text" style="font-family:Helvetica, Arial, sans-serif;font-size:14px;line-height:20px;text-align:left;color:#333333"&gt; &lt;div class="hr" style="height:1px;border-bottom:1px solid #cccccc;clear: both;"&gt;&amp;nbsp;&lt;/div&gt; &lt;br&gt;&lt;/div&gt;&lt;div class="subtitle" style="font-family:Helvetica, Arial, sans-serif;font-size:16px;font-weight:600;color:#2469A0"&gt; 详细信息：&lt;/div&gt;&lt;br&gt;&lt;div class="body-text" style="font-family:Helvetica, Arial, sans-serif;font-size:14px;line-height:20px;text-align:left;color:#333333"&gt; &lt;ol&gt; ' . $content . ' &lt;/ol&gt;&lt;div class="hr" style="height:1px;border-bottom:1px solid #cccccc"&gt;&amp;nbsp;&lt;/div&gt;&lt;br&gt; &lt;table width="264" border="0" cellpadding="0" cellspacing="0" align="left" class="force-row"&gt; &lt;tr&gt; &lt;td class="col" valign="top" style="font-family:Helvetica, Arial, sans-serif;font-size:14px;line-height:20px;text-align:left;color:#333333;width:100%"&gt; &lt;strong&gt;趋势图&lt;/strong&gt; &lt;br&gt;&lt;br&gt; &lt;a href="http://zabbix.server.url/history.php?action=showgraph&amp;itemids[]=' . $itemId . '"&gt; &lt;img src=http://zabbix.server.url/graphs/' . $graphName . ' /&gt;&lt;/a&gt; &lt;br&gt;&lt;br&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;br&gt;&lt;br&gt;&lt;div class="hr" style="height:1px;border-bottom:1px solid #cccccc;clear: both;"&gt;&amp;nbsp;&lt;/div&gt;&lt;br&gt; &lt;br&gt; &lt;em&gt;&lt;small&gt;Last updated: 08 April 2018&lt;/small&gt;&lt;/em&gt;&lt;/div&gt;&lt;br&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="container-padding footer-text" align="left" style="font-family:Helvetica, Arial, sans-serif;font-size:12px;line-height:16px;color:#aaaaaa;padding-left:24px;padding-right:24px"&gt; &lt;br&gt;&lt;br&gt; Serviced provider: © 2018 XXX-INC. &lt;br&gt;&lt;br&gt; You are receiving this email because you used our team\'s monitoring system. Update your &lt;a href="#" style="color:#aaaaaa"&gt;alarm configuration&lt;/a&gt; or &lt;a href="#" style="color:#aaaaaa"&gt;to unsubscribe.&lt;/a&gt;. &lt;br&gt;&lt;br&gt; &lt;strong&gt;team@xxxmail.om&lt;/strong&gt;&lt;br&gt; &lt;span class="ios-footer"&gt; department signature.&lt;br&gt; team signature&lt;br&gt; &lt;/span&gt; &lt;a href="http://www.Your Company's Official network.com" style="color:#aaaaaa"&gt;www.Your Company's Official network.com&lt;/a&gt;&lt;br&gt; &lt;br&gt;&lt;br&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;!--/600px container --&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;!--/100% background wrapper--&gt;&lt;/body&gt;&lt;/html&gt;','text/html');// Send the message$result = $mailer-&gt;send($message);// Dump the log contents// NOTE: The EchoLogger dumps in realtime so dump() does nothing for it#echo $logger-&gt;dump(); swiftmailer安装123mkdir mailercd mailercomposer require "swiftmailer/swiftmailer:^6.0" swiftmailer官方文档 至此基本差不多了，剩下的就是在zabbix web页面上配置下了。 推荐文章（由hexo文章推荐插件驱动）influxdb+telegraf+Grafana监控解决方案与zabbix监控的对比zabbix实现自定义主机名influxdb+telegraf+Grafana监控解决方案与zabbix监控的对比zabbix实现自定义主机名zabbix表分区优化]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>监控</tag>
        <tag>zabbix</tag>
        <tag>告警</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix实现自定义主机名]]></title>
    <url>%2F2018%2F03%2F24%2F00038_zabbix%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%AE%9A%E4%B9%89%E4%B8%BB%E6%9C%BA%E5%90%8D%2F</url>
    <content type="text"><![CDATA[主机名作为监控系统的关键信息，一定不能太死板。。。 生产环境中通常系统的Hostname定义没有严格规范，一般在做系统时，很少在Hostname定义上花时间。但是Hostname作为关键信息在很多场景下具有非常重要的意义。 zabbix agent的默认配置文件中Hostname配置为# HostnameItem=system.hostname,但是zabbix官方文档中有对system.run[command,&lt;mode&gt;]的描述，从2.2版本开始即支持通过该参数在主机上执行指定命令定义监控项的值。我们可以通过该参数实现对Hostname属性的重写。 配置样例： 1HostnameItem=system.run[/bin/bash /path/to/hostname.sh] zabbix相关资源 Zabbix社区资源共享 Zabbix官方WIKI Zabbix官方文档 推荐文章（由hexo文章推荐插件驱动）influxdb+telegraf+Grafana监控解决方案与zabbix监控的对比通过Zabbix API在告警邮件中插入趋势图influxdb+telegraf+Grafana监控解决方案与zabbix监控的对比zabbix表分区优化通过Zabbix API在告警邮件中插入趋势图]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>监控</tag>
        <tag>zabbix</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix表分区优化]]></title>
    <url>%2F2018%2F03%2F23%2F00037_zabbix%E5%88%86%E5%8C%BA%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Zabbix是一款非常优秀的开源监控系统。 MySQL存储过程定义 cat zabbixPartition.sql 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185# ======partition_create========================================================DELIMITER $$CREATE PROCEDURE `partition_create`(SCHEMANAME varchar(64), TABLENAME varchar(64), PARTITIONNAME varchar(64), CLOCK int)BEGIN /* SCHEMANAME = The DB schema in which to make changes TABLENAME = The table with partitions to potentially delete PARTITIONNAME = The name of the partition to create */ /* Verify that the partition does not already exist */ DECLARE RETROWS INT; SELECT COUNT(1) INTO RETROWS FROM information_schema.partitions WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND partition_description &gt;= CLOCK; IF RETROWS = 0 THEN /* 1. Print a message indicating that a partition was created. 2. Create the SQL to create the partition. 3. Execute the SQL from #2. */ SELECT CONCAT( "partition_create(", SCHEMANAME, ",", TABLENAME, ",", PARTITIONNAME, ",", CLOCK, ")" ) AS msg; SET @sql = CONCAT( 'ALTER TABLE ', SCHEMANAME, '.', TABLENAME, ' ADD PARTITION (PARTITION ', PARTITIONNAME, ' VALUES LESS THAN (', CLOCK, '));' ); PREPARE STMT FROM @sql; EXECUTE STMT; DEALLOCATE PREPARE STMT; END IF;END$$DELIMITER ;# ======partition_drop==========================================================DELIMITER $$CREATE PROCEDURE `partition_drop`(SCHEMANAME VARCHAR(64), TABLENAME VARCHAR(64), DELETE_BELOW_PARTITION_DATE BIGINT)BEGIN /* SCHEMANAME = The DB schema in which to make changes TABLENAME = The table with partitions to potentially delete DELETE_BELOW_PARTITION_DATE = Delete any partitions with names that are dates older than this one (yyyy-mm-dd) */ DECLARE done INT DEFAULT FALSE; DECLARE drop_part_name VARCHAR(16); /* Get a list of all the partitions that are older than the date in DELETE_BELOW_PARTITION_DATE. All partitions are prefixed with a "p", so use SUBSTRING TO get rid of that character. */ DECLARE myCursor CURSOR FOR SELECT partition_name FROM information_schema.partitions WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND CAST(SUBSTRING(partition_name FROM 2) AS UNSIGNED) &lt; DELETE_BELOW_PARTITION_DATE; DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE; /* Create the basics for when we need to drop the partition. Also, create @drop_partitions to hold a comma-delimited list of all partitions that should be deleted. */ SET @alter_header = CONCAT("ALTER TABLE ", SCHEMANAME, ".", TABLENAME, " DROP PARTITION "); SET @drop_partitions = ""; /* Start looping through all the partitions that are too old. */ OPEN myCursor; read_loop: LOOP FETCH myCursor INTO drop_part_name; IF done THEN LEAVE read_loop; END IF; SET @drop_partitions = IF(@drop_partitions = "", drop_part_name, CONCAT(@drop_partitions, ",", drop_part_name)); END LOOP; IF @drop_partitions != "" THEN /* 1. Build the SQL to drop all the necessary partitions. 2. Run the SQL to drop the partitions. 3. Print out the table partitions that were deleted. */ SET @full_sql = CONCAT(@alter_header, @drop_partitions, ";"); PREPARE STMT FROM @full_sql; EXECUTE STMT; DEALLOCATE PREPARE STMT; SELECT CONCAT(SCHEMANAME, ".", TABLENAME) AS `table`, @drop_partitions AS `partitions_deleted`; ELSE /* No partitions are being deleted, so print out "N/A" (Not applicable) to indicate that no changes were made. */ SELECT CONCAT(SCHEMANAME, ".", TABLENAME) AS `table`, "N/A" AS `partitions_deleted`; END IF;END$$DELIMITER ;# ======partition_maintenance===================================================DELIMITER $$CREATE PROCEDURE `partition_maintenance`(SCHEMA_NAME VARCHAR(32), TABLE_NAME VARCHAR(32), KEEP_DATA_DAYS INT, HOURLY_INTERVAL INT, CREATE_NEXT_INTERVALS INT)BEGIN DECLARE OLDER_THAN_PARTITION_DATE VARCHAR(16); DECLARE PARTITION_NAME VARCHAR(16); DECLARE OLD_PARTITION_NAME VARCHAR(16); DECLARE LESS_THAN_TIMESTAMP INT; DECLARE CUR_TIME INT; CALL partition_verify(SCHEMA_NAME, TABLE_NAME, HOURLY_INTERVAL); SET CUR_TIME = UNIX_TIMESTAMP(DATE_FORMAT(NOW(), '%Y-%m-%d 00:00:00')); SET @__interval = 1; create_loop: LOOP IF @__interval &gt; CREATE_NEXT_INTERVALS THEN LEAVE create_loop; END IF; SET LESS_THAN_TIMESTAMP = CUR_TIME + (HOURLY_INTERVAL * @__interval * 3600); SET PARTITION_NAME = FROM_UNIXTIME(CUR_TIME + HOURLY_INTERVAL * (@__interval - 1) * 3600, 'p%Y%m%d%H00'); IF(PARTITION_NAME != OLD_PARTITION_NAME) THEN CALL partition_create(SCHEMA_NAME, TABLE_NAME, PARTITION_NAME, LESS_THAN_TIMESTAMP); END IF; SET @__interval=@__interval+1; SET OLD_PARTITION_NAME = PARTITION_NAME; END LOOP; SET OLDER_THAN_PARTITION_DATE=DATE_FORMAT(DATE_SUB(NOW(), INTERVAL KEEP_DATA_DAYS DAY), '%Y%m%d0000'); CALL partition_drop(SCHEMA_NAME, TABLE_NAME, OLDER_THAN_PARTITION_DATE);END$$DELIMITER ;# ======partition_verify========================================================DELIMITER $$CREATE PROCEDURE `partition_verify`(SCHEMANAME VARCHAR(64), TABLENAME VARCHAR(64), HOURLYINTERVAL INT(11))BEGIN DECLARE PARTITION_NAME VARCHAR(16); DECLARE RETROWS INT(11); DECLARE FUTURE_TIMESTAMP TIMESTAMP; /* * Check if any partitions exist for the given SCHEMANAME.TABLENAME. */ SELECT COUNT(1) INTO RETROWS FROM information_schema.partitions WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND partition_name IS NULL; /* * If partitions do not exist, go ahead and partition the table */ IF RETROWS = 1 THEN /* * Take the current date at 00:00:00 and add HOURLYINTERVAL to it. This is the timestamp below which we will store values. * We begin partitioning based on the beginning of a day. This is because we don't want to generate a random partition * that won't necessarily fall in line with the desired partition naming (ie: if the hour interval is 24 hours, we could * end up creating a partition now named "p201403270600" when all other partitions will be like "p201403280000"). */ SET FUTURE_TIMESTAMP = TIMESTAMPADD(HOUR, HOURLYINTERVAL, CONCAT(CURDATE(), " ", '00:00:00')); SET PARTITION_NAME = DATE_FORMAT(CURDATE(), 'p%Y%m%d%H00'); -- Create the partitioning query SET @__PARTITION_SQL = CONCAT("ALTER TABLE ", SCHEMANAME, ".", TABLENAME, " PARTITION BY RANGE(`clock`)"); SET @__PARTITION_SQL = CONCAT(@__PARTITION_SQL, "(PARTITION ", PARTITION_NAME, " VALUES LESS THAN (", UNIX_TIMESTAMP(FUTURE_TIMESTAMP), "));"); -- Run the partitioning query PREPARE STMT FROM @__PARTITION_SQL; EXECUTE STMT; DEALLOCATE PREPARE STMT; END IF;END$$DELIMITER ;#======partition_maintenance_all================================================DELIMITER $$CREATE PROCEDURE `partition_maintenance_all`(SCHEMA_NAME VARCHAR(32))BEGIN CALL partition_maintenance(SCHEMA_NAME, 'history', 180, 24, 90); CALL partition_maintenance(SCHEMA_NAME, 'history_log', 180, 24, 90); CALL partition_maintenance(SCHEMA_NAME, 'history_str', 180, 24, 90); CALL partition_maintenance(SCHEMA_NAME, 'history_text', 180, 24, 90); CALL partition_maintenance(SCHEMA_NAME, 'history_uint', 180, 24, 90); CALL partition_maintenance(SCHEMA_NAME, 'trends', 730, 24, 365); CALL partition_maintenance(SCHEMA_NAME, 'trends_uint', 730, 24, 365);END$$DELIMITER ; 参数说明 SCHEMA_NAME = 数据库 TABLE_NAME = 表 KEEP_DATA_DAYS = 要保留的分区的最大天数。所有超过此天数的分区将被删除。 HOURLY_INTERVAL = 分区的时间间隔(小时为单位) CREATE_NEXT_INTERVALS = 创建的未来分区数 Housekeeper配置修改123"Administration" -&gt; "General" -&gt; "Housekeeping"将History&amp;Trends "Enable internal housekeeping"取消，勾选"Override item trend period",将"Data storage period (in days)"的值改成和存储过程中变量KEEP_DATA_DAYS的值一致。 存储过程导入1/usr/bin/mysql -uroot -p zabbix &lt; zabbixPartition.sql crontab配置100 01 01 * * /usr/bin/mysql -uroot -pPASSWD zabbix -e"CALL partition_maintenance_all('zabbix')" &gt;/dev/null 2&gt;&amp;1 查看分区结果12mysql&gt; use zabbix;mysql&gt; showcreate table history; 以上在zabbix3.0.2版本上执行通过，其它版本根据实际情况判断是否微调。。。 参考 Zabbix wiki Zabbix 分区优化 Zabbix数据库优化(Zabbix分区表) 推荐文章（由hexo文章推荐插件驱动）MySQL常见的两种数据库引擎比较influxdb+telegraf+Grafana监控解决方案与zabbix监控的对比zabbix实现自定义主机名通过Zabbix API在告警邮件中插入趋势图]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>zabbix</tag>
        <tag>表分区</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum/rpm常用命令总结]]></title>
    <url>%2F2018%2F03%2F22%2F00036_yum%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Yum (Yellow dog Updater, Modified) ,Fedora、RedHat以及CentOS中的Shell前端软件包管理器，基于RPM。 yum常用命令 显示可用的yum仓库 1yum repolist 指定某一个repo内搜索某个rpm包 1yum --disablerepo=* --enablerepo=xxx search xxxx 列出某个yum源中可用的rpm包 1sudo yum --disablerepo=&quot;*&quot; --enablerepo=&quot;xxxx&quot; list available 查找某条命令的yum源 1yum whatprovides &quot;*/whoami&quot; 查找某条命令由什么包提供 1yum provides $&#123;cmd&#125; 替换安装某个rpm包 12yum install yum-plugin-replaceyum replace php-common --replace-with=php56-common 降级安装 1yum downgrade packages 安装程序组 1yum groupinstall &apos;Development Tools’ 从yum源中下载rpm包 12yum -y install yum-utilsyumdownloader xxxx yum下载依赖文件 123456789101112131415方法一： yumdownloader 下载包名称 --resolve --destdir=/tmp/openresty 参考： http://www.cnblogs.com/toSeek/p/6093679.html方法二： 1.安装yum-plugin-downloadonly yum -y install ftp://ftp.pbone.net/mirror/ftp5.gwdg.de/pub/opensuse/repositories/Virtualization:/Appliances/CentOS_CentOS-6/noarch/yum-plugin-downloadonly-1.1.31-2.2.noarch.rpm 2.下载： yum install -y --downloadonly --downloaddir=/tmp/php php 参考： http://graybull.is-programmer.com/posts/37702.html http://www.jianshu.com/p/5930545b5591 yum 查看so库文件所在的rpm包 1yum whatprovides libXpm.so.4 Yum 事务完整的历史记录 12345678yum history list all # 查看历史yum命令yum history info nginx # 查看yum涉及指定软件包的事务详情yum history summary nginx # 查看yum涉及指定软件包的事务摘要yum history package-list nginx # 查看yum涉及指定软件包的历史记录yum history addon-info # 提供更多的信息来源yum history stats # 显示当前历史数据库的统计信息yum history sync # 更改为所有已安装软件包存储的rpmdb/yumdb数据yum history new # 创建新的历史文件 rpm常用命令 强制降级 123rpm -Uvh oldpackage.rpm --oldpackage 或rpm -Uvh oldpackage.rpm --force 查看rpm包安装前后执行的脚本 1rpm -qp --scripts xxxx.rpm rpm包安装前后执行脚本被传入参数$1的意义 1230:卸载1:安装、升级卸载2:升级 查看rpm包提供的命令 1rpm -qp --provides xxxx.rpm 查看rpm包注册的冲突信息 1rpm -qp --conflicts xxxx.rpm 查看rpm包注册的依赖信息 1rpm -qpR xxxx.rpm 查看rpm包中注册的配置文件 1rpm -qpc xxxx.rpm 查看rpm包的打包信息 1rpm -qpi xxxx.rpm 查看打包spec文件中的tag信息 12345rpm -q --qf %&#123;tag&#125; rpm_nametag list: Name|Version|Release|Summary|Group|License|URLeg：rpm -q --qf %&#123;Version&#125; rpm_name 内网yum源维护 创建repodata 12yum -y install createrepocreaterepo /path/to/RPMS/epel/7/x86_64/ 更新repodata 1createrepo --update /path/to/RPMS/epel/7/x86_64 镜像yum源 1234567reposync -r &quot;repoid&quot;eg:reposync -r webtatic-archive -nu-r 指定镜像源-n 只下载最新镜像-u 只列出，不下载 自定义yum源配置 123456789101112[epel.xxx]name=repo.xxx.xxxbaseurl=http://repo.xxx/epel/$releasever/$basearchskip_if_unavailable=True # 在CentOS7系统上测试当前yum源如果不可用，会直接跳过，默认False，提示错误.gpgcheck=0enabled=1[epel-archive.xxx]name=archive.xxx.xxxbaseurl=http://repo.xxx/archive/$releasever/$basearchgpgcheck=0enabled=0 配置文件中$releasever变量是取redhat-release-server(redhat)或centos-release(centos) rpm包的属性 %{version} 的值。验证方法:rpm -q --qf %{version} redhat-release-server rh和centos的$releasever稍有不同，一般rh的$releasever值是${Version}Server,centos的$releasever值直接是${Version}数值，所以在定义配置文件的时候要注意验证。 常见yum报错处理 yum报错：Rpmdb checksum is invalid: dCDPT(pkg checksums) 解决方案12rpm --rebuilddbyum clean all 备注 CentOS5社区yum源 推荐文章（由hexo文章推荐插件驱动）存储空间计算Linux系统中的tmpfs、/dev/shm、tmp以及共享内存机制Linux系统中的IO模式tmux窗口管理Linux挂载Windows共享目录]]></content>
      <categories>
        <category>yum</category>
      </categories>
      <tags>
        <tag>rpm</tag>
        <tag>Linux</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[drupal应用部署]]></title>
    <url>%2F2018%2F03%2F21%2F00035_drupal%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[Drupal是一款诞生于2000年的基于PHP语言编写的经典开源内容管理框架。 坊间传说drupal使用成本比wp高，偶然的机会看到一个基于drupal搭建的网站还不赖。兴趣使然，简单研究了一下drupal的搭建和使用。以下简单给出搭建的关键步骤： composer工具准备123curl -sS https://getcomposer.org/installer | phpmv composer.phar /usr/sbin/composer self-update 以lightning为例部署12composer create-project acquia/lightning-project drupalchown -R nobody:nobody drupal drupal/docroot为应用根目录 drupal默认使用sqlite数据库不需要单独配置 nginx配置以上方式部署完成后，用nginx的默认php应用配置会导致除了首页能访问，其它所有页面全部404，根据drupal的路由特点需要简单配置rewrite规则，nginx应用的基本配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445server &#123; listen *:80; # include vhosts/vhosts.listen.addr; # server_name localhost; #charset koi8-r; access_log logs/host.access.log main; location / &#123; root html/drupal/docroot; index index.php index.htm; try_files $uri $uri/ @rewrite; &#125; location ~ ^/sites/.*/private/ &#123; access_log off; internal; &#125; location @rewrite &#123; rewrite ^/(.*)$ /index.php?q=$1; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; location ~ \.php$ &#123; root html/drupal/docroot; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; location ~ /\.ht &#123; deny all; &#125;&#125; 如此一来，基本上就可以用了。。。]]></content>
      <categories>
        <category>drupal</category>
      </categories>
      <tags>
        <tag>drupal</tag>
        <tag>CMS</tag>
        <tag>搭建部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[confluence 自动备份策略不生效]]></title>
    <url>%2F2018%2F03%2F20%2F00034_confluence-%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD%E7%AD%96%E7%95%A5%E4%B8%8D%E7%94%9F%E6%95%88%2F</url>
    <content type="text"><![CDATA[一切问题都有答案。。。 ##问题现象 confluence从备份文件中降级恢复后，配置没有任何错误提示，但是发现备份策略不生效，备份目录为空。查看日志后发现，没有取到backupPath，但是实际配置中是有显示配置路径的。 错误日志123456backupAttachmentsDaily = truedailyBackupFilePrefix = backup-backupDaily = truebackupPath = null2018-03-20 02:00:00,022 WARN [Caesium-1-2] [confluence.importexport.impl.BackupJob] runJob No daily backup directory specified to store the backups. Taking no action!2018-03-20 02:00:00,038 WARN [Caesium-1-2] [impl.schedule.caesium.JobRunnerWrapper] runJob Scheduled job BackupJob#BackupJob completed unsuccessfully with response JobRunnerResponse[runOutcome=ABORTED,message=&apos;No daily backup directory specified to store the backups. Taking no action!&apos;] 问题解决参考了一些官网给出的case,将 ${CONFLUENCE_HOME}目录下的配置文件confluence.cfg.xml中的&lt;property name=&quot;admin.ui.allow.daily.backup.custom.location&quot;&gt;false&lt;/property&gt;属性值变更为true,重启confluence，然后将每日备份管理-&gt;备份设置-&gt;备份路径设置为默认,最后重新手动触发备份任务，成功生成备份文件。 备注由于之前有过confluence从备份文件中降级恢复操作，怀疑是由于恢复操作，导致备份路径没有生效，猜测不用修改confluence.cfg.xml，直接重新提交一下备份路径设置也是可以的，因为问题的根本原因是backupPath = null。由于生产环境不便于验证，反复修改验证。有兴趣的读者可以验证一下，以后有机会也会再做验证。 confluence的备份恢复机制还是很好用的。wiki作为团队的重要资源，做好备份恢复还是非常重要和必要的。]]></content>
      <categories>
        <category>confluence</category>
        <category>填坑指南</category>
      </categories>
      <tags>
        <tag>confluence</tag>
        <tag>wiki</tag>
        <tag>备份</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xshell常用快捷键]]></title>
    <url>%2F2018%2F03%2F19%2F00033_xshell%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[常用但不全面，会持续总结完善。。。 table th:nth-of-type(1){width: 30%;} nth-of-type(2){width: 70%;} 快捷键 功能 ctrl + k 删除光标后面所有字符 ctrl + u 删除光标前面所有字符 ctrl + w 删除光标前一个单词相当于VIM里db ctrl + y 粘贴ctrl+u上次执行时删除的字符 ctrl + ? 撤消前一次输入 ctrl + 方向键 光标以单词为单位移动 ctrl + s 锁住终端 ctrl + q 解锁终端 alt + 数字 切换到第N个标签页 alt + r 透明窗口切换 Shift + Home 顶部 Shift + End 底部 Shift + PgUp 向上翻页 Shift + PgDn 向下翻页]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>xshell</tag>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[influxdb+telegraf+Grafana监控解决方案与zabbix监控的对比]]></title>
    <url>%2F2018%2F03%2F18%2F00032_influxdb-telegraf-Grafana%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E4%B8%8Ezabbix%E7%9B%91%E6%8E%A7%E7%9A%84%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[术业有专攻，各有所长。。。 table th:nth-of-type(1){width: 50%;} nth-of-type(2){width: 50%;} influxdb+telegraf+Grafana监控解决方案角色分工 telegraf 根据配置采集数据，输出数据；拥有丰富强大的输出输出插件，influxdb官方推出的数据采集方案，对influxdb的支持非常好； influxdb 时序数据库，chronograf是官方提供的替代内置方案的web Admin； Grafana 出图告警。出图功能灵活强大，告警功能目前还比较简单单一。 部署 官方提供的rpm包安装，无依赖，操作简单。 高可用实现方案 influxdb社区版不支持集群方案； telegraf支持写双份数据，来降低influxdb的单点风险； Grafana可以通过MySQL替代SQLite,redis共享session，nginx代理多个应用的方式实现高可用。 监控项 对java应用的监控 Jolokia httpjson jmxtrans Actuator 对http请求的监控 http httprespone 对日志的监控 logparser tail 支持exec脚本 其它常见应用 apache ceph consul docker elasticsearch fluentd graylog haproxy influxdb iptables kubernetes memcached mesos mongodb mysql nginx openldap phpfpm postfix postgresql prometheus rabbitmq redis solr tomcat varnish zookeeper telegraf支持的常见写入方式或介质 influxdb rabbitmq aws cloudwatch elasticsearch file graphite graylog kafka mqtt opentsdb prometheus socket_writer tcp udp … 出图 Grafana社区提供了丰富的Dashboard模板 可以自定义 导入导出 Dashboard、Row、查询SQL中均支持Variables，出图非常灵活 告警 支持较为简单的告警逻辑处理 告警关联的SQL中不支持Variables解析 目前单个panel只支持一个告警规则，因此在配置告警时要进行panel拆分 部署过程中的要点 数据库使用域名，或绑hosts，避免迁移修改配置的问题 http接口鉴权、绑定必要的IP list 定义influxdb定期清理策略 influxdb认证 特点 秒级数据采集 自动上报 部署简单 插件丰富，开箱即用 支持协议数据 缺陷 告警能力（策略相对简单、渠道固定） 跨网部署 和zabbix的优劣对比 telegraf+influxdb+Grafana Zabbix 部署及使用简单 部署使用相对复杂 内置监控项丰富 内置监控项支持相对少一些，但是社区提供了丰富的监控采集方案 不支持跨机房部署 支持跨机房部署 审计功能相对较弱 审计功能成熟完善 出图能力灵活强大 出图功能相对弱一些，图形化定制方面操作复杂 告警功能简单 告警强大，支持告警依赖，告警升级 支持通过webhook方式触发命令 支持服务器端/客户端的命令自动触发，支持命令推送 权限管理相对简单 支持细粒度的权限定制，权限体系成熟完善 数据采集方式相对单一，仅支持自动上报，但支持较为丰富的数据源 支持多种数据采集方式/协议，数据源相对单一，v3.4.7版本开始支持ES存储历史数据 总结 zabbix 更加成熟完善，侧重告警能力。 telegraf+influxdb+Grafana相对轻量，侧重出图能力。 推荐文章（由hexo文章推荐插件驱动）zabbix实现自定义主机名通过Zabbix API在告警邮件中插入趋势图zabbix实现自定义主机名zabbix表分区优化通过Zabbix API在告警邮件中插入趋势图]]></content>
      <categories>
        <category>开源技术栈</category>
      </categories>
      <tags>
        <tag>监控</tag>
        <tag>influxdbdata</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七层网络协议]]></title>
    <url>%2F2018%2F03%2F16%2F00031_%E4%B8%83%E5%B1%82%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[简单概括,不一定准确。。。 table th:nth-of-type(1){width: 10%;} nth-of-type(2){width: 10%;} nth-of-type(3){width: 30%;} nth-of-type(4){width: 50%;} 总结 TCP/IP模型 OSI模型 分布的应用 协议说明 应用层 应用层 nginx、Apache、HAProxy、LVS、keepalived DHCP(v6)、DNS、FTP、Gopher、HTTP(SPDY、HTTP/2)、IMAP4、IRC、NNTP、XMPP、POP3、SIP、SMTP、SNMP、SSH、TELNET、RPC、SOAP、NTP、等 应用层 表示层 - 该层被弃用。应用层的HTTP、FTP、Telnet等协议有类似的功能。传输层的TLS/SSL也有类似功能。 应用层 会话层 - 该层被弃用。应用层的HTTP、RPC、SDP、RTCP等协议有类似的功能。 传输层 传输层 LVS、keepalived TCP、UDP、DCCP、RSVP、PPTP、TLS/SSL等。IP+端口 网际互连层 网络层 keepalived IP(v4·v6)、ICMP(v6)、IGMP、IPsec、BGP、RIP、OSPF、RARP等 网络接口层 数据链路层 - Wi-Fi(IEEE 802.11)、ARP、ATM、令牌环、以太网、FDDI、帧中继、GPRS、HDLC、PPP、PPPoE、L2TP、ISDN、SPB、STP等 网络接口层 物理层 - 以太网、调制解调器、电力线通信、同步光网络、光导纤维、同轴电缆、双绞线等 思考 heartbeat工作在几层？ 推荐文章（由hexo文章推荐插件驱动）HTTP协议中的8种请求方法http请求常见状态码及解释http协议头字段说明]]></content>
      <categories>
        <category>TCP/IP</category>
      </categories>
      <tags>
        <tag>协议</tag>
        <tag>OSI</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis数据结构]]></title>
    <url>%2F2018%2F03%2F15%2F00030_redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[只是redis的基本数据类型。 5中数据结构 table th:nth-of-type(1){width: 10%;} nth-of-type(2){width: 90%;} 数据结构 说明 String(字符串) Strings 类型，可以完全实现目前Memcached的功能，并且效率更高。还可以享受 Redis 的定时持久化，操作日志及 Replication 等功能，并提供更多的操作命令支持。 Hash(字典) 可以像在数据库中Update一个属性一样只修改某一项属性值。 List(列表) 链表，可以轻松实现最新消息排行等功能。另一个应用就是消息队列，Redis提供了操作List中某一段元素的 API。 Set(集合) 集合的概念就是一堆不重复值的组合。利用 Redis 提供的 Set 数据结构，可以存储一些集合性的数据。 Sorted Set(有序集合) 和Sets相比，Sorted Sets是将Set中的元素增加了一个权重参数score，使得集合中的元素能够按 score 进行有序排列,适用于比较复杂的数据结构和带有权重的元素。 应用场景 缓存 消息队列 订阅-发布系统 TimeLine 加权元素 事务处理(Transactions) 参考 Redis 数据结构使用场景 Redis教程 推荐文章（由hexo文章推荐插件驱动）redis持久化策略]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>数据结构</tag>
        <tag>kv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux挂载Windows共享目录]]></title>
    <url>%2F2018%2F03%2F14%2F00029_Linux%E8%AE%BF%E9%97%AEWindows%E5%85%B1%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[CIFS(Common Internet File System)：通用网络文件系统 软件环境 1yum -y install cifs-utils.x86_64 挂载目录 12mkdir -p /opt/sharemount -t cifs -o username=&apos;domain-name.com\username&apos; &quot;//10.0.0.1/share&quot; /opt/share 永久挂载(直接暴露用户密码，一般不建议，除非免密码公共共享) 12echo -e &quot;\&quot;//10.0.0.1/share\&quot; /opt/share cifs auto,username=&apos;domain-name.com\username&apos;,password=&apos;passwd&apos; 0 0\&quot; &gt;&gt;/etc/fstabmount -a 卸载 1umount //10.0.0.1/share 中文乱码 1234567891011121314# yum install system-config-language# system-config-language # 选择中文简体# 将/etc/sysconfig/i18n中以下两项设置为LANG=&quot;zh_CN.UTF-8&quot;SYSFONT=&quot;lat0-sun16&quot;# source /etc/sysconfig/i18n #即使配置不需要改变也需要source一下# 如果没有中文语言包，执行此命令安装# yum groupinstall chinese-support# 最后将ssh客户端的编码设置为Unicode(UTF-8) 参考 Linux访问Windows共享 推荐文章（由hexo文章推荐插件驱动）存储空间计算Linux系统中的tmpfs、/dev/shm、tmp以及共享内存机制Linux系统中的IO模式tmux窗口管理常用shell命令总结]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Windows</tag>
        <tag>共享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP协议中的8种请求方法]]></title>
    <url>%2F2018%2F03%2F13%2F00028_HTTP%E5%8D%8F%E8%AE%AE%E4%B8%AD%E7%9A%848%E7%A7%8D%E8%AF%B7%E6%B1%82%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[根据HTTP标准，HTTP请求可以使用多种请求方法。。。 table th:nth-of-type(1){width: 10%;} nth-of-type(2){width: 90%;} 八种请求方法 请求方法 说明 GET 请求指定的页面信息，并返回实体主体。 HEAD 类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头。 POST 向指定资源提交数据进行处理请求，主要用于向数据处理过程提供数据块，如递交表单或上传文件。 PUT 从客户端向服务器传送的数据取代指定的文档的内容。由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。 DELETE 请求服务器删除指定的页面。同样不带验证机制。 CONNECT HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器，使请求连接转换到透明的 TCP/IP 通道。 OPTIONS 返回服务器支持的 HTTP 方法，允许客户端查看服务器的性能。 TRACE 回显服务器收到的请求，主要用于测试或诊断。通常不会使用 TRACE，并且它容易受到 XST(跨站追踪)攻击。 其中HTTP1.0定义了三种请求方法： GET、POST、和HEAD，HTTP1.1新增了OPTIONS、PUT、DELETE、TRACE和CONNECT方法。 GET和POST比较 GET方法GET方法请求有长度限制，保留在浏览器历史记录中，请求可被缓存，可被收藏为书签。请求只应当用于取回数据，不应在处理敏感数据时使用。 POST方法POST方法请求对数据长度没有要求，请求不会保留在浏览器历史记录中，请求不能被缓存，不能被收藏为书签。 参考HTTP请求方法 HTTP 协议基础*HTTP 方法：GET 对比 POST 推荐文章（由hexo文章推荐插件驱动）http不同版本及特性概括http请求常见状态码及解释http协议头字段说明七层网络协议http请求常见状态码及解释]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk使用总结]]></title>
    <url>%2F2018%2F03%2F12%2F00027_awk%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[AWK是一款优秀的文本处理工具，Linux及类Unix环境中功能最强大的数据处理引擎之一。awk的衍生版本主要有nawk，gawk。linux系统下默认版本为gawk。 table th:nth-of-type(2){width: 20%;} nth-of-type(3){width: 70%;} 参数说明 短参数 长参数 说明 -F fs –field-separator=fs 指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如-F: -v var=val –assign=var=val 赋值一个用户定义变量 -f 脚本文件 –file=脚本文件 从脚本文件中读取awk命令 -m[fr] val – 对val值设置内在限制，-mf选项限制分配给val的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用 -W compat –compat 在兼容模式下运行awk。所以gawk的行为和标准的awk完全一样，所有的awk扩展都被忽略 -W traditional –traditional – -W posix –posix 打开兼容模式。但有以下限制，不识别：/x、函数关键字、func、换码序列以及当fs是一个空格时，将新行作为一个域分隔符；操作符和=不能代替^和^=；fflush无效 -W re-interval –re-interval 允许间隔正则表达式的使用，参考(grep中的Posix字符类)，如括号表达式[[:alpha:]] -W source=program-text –source=program-text 使用program-text作为源代码，可与-f命令混用 -W lint[=fatal] –lint[=fatal] 打印不能向传统unix平台移植的结构的警告 -W lint-old –lint-old 打印关于不能向传统unix平台移植的结构的警告 -W help –help 打印全部awk选项和每个选项的简短说明 -W usage –usage – -W copyright –copyright 打印简短的版权信息 -W copyleft –copyleft – -W copyright –copyright – -W version –version 打印bug报告信息的版本 table th:nth-of-type(1){width: 10%;} nth-of-type(2){width: 90%;} 内置变量常见内置变量 变量 说明 \$n 当前记录的第n个字段，字段间由FS分隔 \$0 完整的输入记录 NF 一条记录的字段的数目 FS 字段分隔符(默认是任何空格) OFS 输出记录分隔符（输出换行符），输出时用指定的符号代替换行符 RS 记录分隔符(默认是一个换行符) ORS 输出记录分隔符(默认值是一个换行符) NR 已经读出的记录数，就是行号，从1开始 FNR 各文件分别计数的行号 不常见内置变量 变量 说明 FILENAME 当前文件名 ARGC 命令行参数的数目 ARGV 包含命令行参数的数组 ARGIND 命令行中当前文件的位置(从0开始算) FIELDWIDTHS 字段宽度列表(用空格键分隔) IGNORECASE 如果为真，则进行忽略大小写的匹配 RLENGTH 由match函数所匹配的字符串的长度 RSTART 由match函数所匹配的字符串的第一个位置 CONVFMT 数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组 OFMT 数字的输出格式(默认值是%.6g) SUBSEP 数组下标分隔符(默认值是/034) ERRNO 最后一个系统错误的描述 table th:nth-of-type(2){width: 20%;} nth-of-type(3){width: 70%;} 常用函数 函数 说明 使用范例 sub(regexp, replacement [, target]) 匹配记录中最大、最靠左边的子字符串的正则表达式，并用替换字符串替换这些字符串。如果没有指定目标字符串就默认使用整个记录。替换只发生在第一次匹配时 awk ‘BEGIN { str = “water, water, everywhere”;sub(/at/, “ith”, str);print str}’ gsub(regexp, replacement [, target]) 整个文档中进行匹配 { gsub(/Britain/, “United Kingdom”); print } index(in, find) 返回子字符串第一次被匹配的位置，偏移量从位置1开始 awk ‘BEGIN { print index(“peanut”, “an”) }’ substr(string, start [, length ]) 返回从位置1开始的子字符串，如果指定长度超过实际长度，就返回整个字符串 awk ‘BEGIN {string = “abcdef”;string = substr(string, 1, 2) “CDE” substr(string, 6);print string}’ split(string, array [, fieldsep [, seps ] ]) 可按给定的分隔符把字符串分割为一个数组。如果分隔符没提供，则按当前FS值进行分割 split(“cul-de-sac”, a, “-“, seps) length([string]) 返回记录的字符数 length(“abcde”) match(string, regexp [, array]) 返回在字符串中正则表达式位置的索引，如果找不到指定的正则表达式则返回0 awk 'BEGIN {{if ($1 == "FIND") regex = $2; else { where = match($0, regex); if (where != 0) print "Match of", regex, "found at", where, "in", $0;}}}' toupper和tolower 可用于字符串大小间的转换，该功能只在gawk中有效 toupper(“MiXeD cAsE 123”); tolower(“MiXeD cAsE 123”); int(x) 取整,直接舍弃小数点后的数字 awk ‘BEGIN {print int(9999.99)}’ rand() 随机数，产生一个大于等于0而小于1的随机数 awk ‘BEGIN {print rand()}’ table th:nth-of-type(1){width: 10%;} nth-of-type(2){width: 90%;} 运算符 运算符 说明 &lt; &lt;= &gt; &gt;= != == 关系运算符 = += -= *= /= %= ^= **= 赋值 &amp;&amp; 逻辑与 &#124;&#124; 逻辑或 + - ! 一元加 减 逻辑非 ~和~! 匹配正则表达式和不匹配正则表达式 ?: C条件表达式 空格 连接 $ 字段引用 in 数组成员 + - 加减 * / &amp; 乘 除 求余 ++ – 增加 减少 作为前缀或后缀 awk正则 匹配符 说明 \w 匹配一个字母数字下划线任意组成的字符串 \W 匹配一个非字母数字下划线组成的字符串 \s 匹配任意空格类字符串，[[:space:]]的缩写 \S 匹配任意非空格类字符串，[^[:space:]]的缩写 \y 匹配一个单词开头或者末尾的空字符串。eg: &#39;\yballs?\y&#39; matches either ‘ball’ or ‘balls’, as a separate word. \B 匹配单词内的空字符串，eg：/\Brat\B/ matches’crate’ \&lt; 匹配一个单词的开头的空字符串，锚定开始。eg: /\&lt;away/ matches ‘away’ but not ‘stowaway’. > 匹配一个单词的末尾的空字符串，锚定末尾。eg: /stow\&gt;/ matches ‘stow’ but not ‘stowaway’. ` 匹配字符串起始的一个空字符串 \’ 匹配字符串末尾的一个空字符串 常用的format格式化输出 符号 说明 %s 显示字符串 %d, %i 十进制整数 %u 无符号整数 %f 显示浮点数 %g, %G 以科学计数法的格式或浮点数的格式显示数值 %e, %E 科学计数法显示数值 %c 显示字符的ASCII码 %% 显示%自身 修饰符:N 显示宽度 修饰符:- 左对齐 修饰符:+ 显示数值符号 应用范例 格式化输出 1234# echo 99 | awk &apos;BEGIN&#123; n=100 &#125;&#123; printf(&quot;%s %s &lt; &quot;n&quot;\n&quot;,$1,($1 &lt; n ? &quot;is&quot; : &quot;is not&quot;)) &#125;&apos;99 is &lt; 100# echo 199 | awk &apos;BEGIN&#123; n=100 &#125;&#123; printf(&quot;%s %s &lt; &quot;n&quot;\n&quot;,$1,($1 &lt; n ? &quot;is&quot; : &quot;is not&quot;)) &#125;&apos;199 is not &lt; 100 使用正则，字符串匹配 123# awk &apos;$9 ~ /500/ &#123;print $1,$7&#125;&apos; nginx_access_log# awk &apos;$9 !~ /200/ &#123;print $1,$7&#125;&apos; nginx_access_log# awk &apos;!/200/ &#123;print $1,$7&#125;&apos; nginx_access_log if复合条件判断 123&#123;% raw %&#125;cat nginx_access_log |awk &apos;&#123;if($9!=&quot;\&quot;200\&quot;&quot; &amp;&amp; $9 != &quot;\&quot;304\&quot;&quot; &amp;&amp; $9 != &quot;\&quot;302\&quot;&quot; &amp;&amp; $9 != &quot;\&quot;403\&quot;&quot;) &#123;print $9&quot;:&quot;$11&quot;:&quot;$7&#125;&#125;&apos; |sort |uniq -c |sort -rn |head&#123;% endraw %&#125; 使用数组进行分类汇总 1234&#123;% raw %&#125;# netstat -ant | awk &apos;/^tcp/ &#123;state[$NF]++&#125; END &#123;for(s in state)&#123;if(state[s]&gt;10)print s,state[s]&#125;&#125;&apos;# tail -n 1000 nginx_access_log| awk &apos;&#123;stat[$9]++&#125; END &#123;for(c in stat)&#123;if(c !~ 200)print c,stat[c]&#125;&#125;&apos;&#123;% endraw %&#125; 参考 The GNU Awk User’s Guide AWK程序设计语言 详解 awk 工具的使用方法 awk Linux Awk使用案例总结（nginx日志统计，文件对比合并等） 推荐文章（由hexo文章推荐插件驱动）存储空间计算Linux系统中的tmpfs、/dev/shm、tmp以及共享内存机制Linux系统中的IO模式tmux窗口管理Linux挂载Windows共享目录]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文本处理</tag>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tmux窗口管理]]></title>
    <url>%2F2018%2F03%2F03%2F00026_tmux%E7%AA%97%E5%8F%A3%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[工欲善其事必先利其器。。。 对于tmux简单来说，一个会话里面可以有多个窗口，一个窗口里面可以有多个面板。 安装1yum -y install tmux table th:nth-of-type(2){width: 80%;} 会话（Session）概念：我们拿终端工具如：XShell、SecureCRT 等去连接正在运行的服务器的时候，每新建一个连接，就是一个新的会话。使用 Tmux 新建会话的时候，也是一样，一个新的会话就表示一个新的连接。 常用操作 创建一个新的会话test1：tmux new -s sessionName 断开当前会话：tmux detach(快捷键：Ctrl+b+d) 进入之前的会话：tmux attach-session -t sessionName，简写：tmux a -t sessionName 关闭会话：tmux kill-session -t sessionName 查看所有会话：tmux list-session 简写：tmux ls（快捷键：Ctrl+b+s） 关闭所有会话：tmux kill-server 强制重载当前会话：（快捷键：Ctrl+b+r） 重新开启某一会话: tmux attach -t sessionName 切换到某一会话：tmux switch -t sessionName 重命名会话: tmux rename -t oldName newName 默认会话快捷键 列出所有快捷键：Ctrl + b,?，按q返回 脱离当前会话：Ctrl + b,d，输入tmux attach能够重新进入之前会话 选择并切换会话：Ctrl + b,s 选择要脱离的会话：Ctrl + b,D 挂起当前会话：Ctrl + z 列出提示信息缓存：Ctrl + b,~，含tmux返回的各种提示信息 进入命令行模式：Ctrl + b,:，可输入tmux命令，如kill-server 复制模式：Ctrl + b,[，光标移动到复制内容位置，空格键开始，方向键选择复制，回车确认，q/Esc退出 粘贴模式：Ctrl + b,]，粘贴在复制模式中复制的内容，按q/Esc退出 显示当前的时间：ctrl + b,t 窗口（Window）概念窗口：窗口的概念，可以类比于 Windows 里面的窗口的概念。之前我们连服务器的时候，终端工具每次连接只有一个界面，当我们需要同时操作多个过程的时候，我们就需要建立新的连接。这样很不方便。Tmux 里面的窗口的概念，就可以让我们在一个会话里有多个界面，就不需要去建立的一个会话。 常用操作 创建一个新的窗口：tmux new-window 列出所有窗口：tmux list-windows 根据序列索引选择窗口 tmux select-window -t :0-9 重命名当前窗口：tmux rename-window 默认窗口快捷键 创建新窗口：Ctrl + b,c 关闭当前窗口：Ctrl + b,&amp; 切换到指定窗口：Ctrl + b,数字键 重命名当前窗口，便于识别：Ctrl + b,, 修改当前窗口编号，相当于重新排序：Ctrl + b,. 切换至上一窗口：Ctrl + b,p 切换至下一窗口：Ctrl + b,n 前后窗口间互相切换：Ctrl + b,l 通过窗口列表切换窗口：Ctrl + b,w 在所有窗口中查找关键词，便于窗口多了切换：Ctrl + b,f 面板（Panel）概念面板是用于对界面的布局而言的。就是将一个界面划分为多个不同的区域，每个区域我们称之为一个面板 常用操作 垂直切分窗口：tmux split-window 水平切分窗口：tmux split-window -h 在指定方向交换面板：tmux swap-pane -[UDLR] 在指定方向选择下一个面板：tmux select-pane -[UDLR] 默认面板快捷键 将当前面板上下分屏：Ctrl + b,&quot; 将当前面板左右分屏：Ctrl + b,% 选择当前窗口中下一个面板：Ctrl + b,o 移动光标选择对应面板：Ctrl + b,方向键 向前置换当前面板：Ctrl + b,{ 向后置换当前面板：Ctrl + b,} 逆时针旋转当前窗口的面板：Ctrl + b,Alt+o 顺时针旋转当前窗口的面板：Ctrl + b,Ctrl+o 显示面板编号：Ctrl + b,q 关闭当前分屏：Ctrl + b,x 将当前面板置于新窗口,即新建一个窗口,其中仅包含当前面板：Ctrl + b,! 以1个单元格为单位移动边缘以调整当前面板大小：Ctrl + b,Ctrl+方向键 以5个单元格为单位移动边缘以调整当前面板大小：Ctrl + b,Alt+方向键 切换默认面板布局：Ctrl + b,空格键 最大化当前所在面板：Ctrl + b,z，tmux 1.8新特性 其它 列出所有tmux命令及其参数：tmux list-commands 列出所有可以的快捷键和其运行的 tmux 命令：tmux list-keys 流出所有的 session、window、pane、运行的进程号：tmux info 变更配置文件后重新加载配置文件：tmux source-file ~/.tmux.conf 重命名会话tmux rename -t 原会话名 新会话名 会话间移动窗口： 123`Ctrl + b,:` 进入命令行模式;move-window -s 源会话名:窗口号 -t 目标会话名 //move-window可以简写为movewmovew -d 源会话名:窗口号 //将某个窗口移动到当前会话 复制模式 1234`Ctrl+b [`进入复制模式，按`q`退出按下`空格键`开始复制，移动光标选择复制区域按下`回车键`复制选中文本并退出复制模式按下`Ctrl+b ]`粘贴复制模式中复制的文本 复制模式中不接受键盘的字符输入，如果误入复制模式，可以直接按q键退出复制模式。 另外复制模式中可以上翻查看在普通模式下无法查看的屏幕输出内容。 窗口自动调整大小问题12345 tmux默认会同步同一个会话的操作到所有会话连接的终端窗口中，这种同步机制，限制了窗口的大小为最小的会话连接。 为了避免窗口自动调整大小，终端剩余空间填充小圆点可以执行 tmux a -d或在会话命令行模式下执行: a -d 调整窗口排序顺序 1234命令行模式下swap-window -s 1 -t 2 交换1、2窗口swap-window -t 1 当前窗口和1号窗口交换move-window -t 1 将当前窗口移动到1号窗口位置 终端类型与配色方案 123456789101112131415161718192021222324252627282930ncurses库包名 CentOS 5: ncurses-5.5-24.20060715 CentOS 6/7: ncurses-base-5.9-13.20130511.el7.noarch文件路径 /usr/share/terminfo/ eg: /usr/share/terminfo/s/screen-256color /usr/share/terminfo/x/xterm-256color终端配置 echo $TERM echo $TERMINFO export TERM=screen-256color export TERM=xterm export TERMINFO=/user/share/terminfotmux 临时设置默认终端类型 set -g default-terminal &quot;xterm&quot;当终端不支持screen-256color，vim编辑文件报错时，将TERM修改为xterm # echo $TERM screen-256color export TERM=xterm备注： vim ~/.tmux.conf 必须设置成 set -g default-terminal &quot;screen-256color&quot; 不能设置成 set -g default-terminal &quot;xterm-256color&quot; 否则tmux新开的窗口中默认的$TERM就是xterm-256color， 开启omnitty 会有阴影，显示会有问题。也可以手动修改窗口中的$TERM环境变量消除阴影。 screen-256color和xterm-256color的区别？ 参考 tmux wiki Tmux使用手册 linux term zsh：在tmux中设置TERM = screen-256color，但在没有tmux的情况下设置xterm-256color xterm-256color’: unknown terminal type. GNU Screen#%E4%BD%BF%E7%94%A8_256_%E8%89%B2) 推荐文章（由hexo文章推荐插件驱动）存储空间计算Linux系统中的tmpfs、/dev/shm、tmp以及共享内存机制Linux系统中的IO模式Linux挂载Windows共享目录常用shell命令总结]]></content>
      <categories>
        <category>tmux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>tmux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MediaWiki常见问题汇总]]></title>
    <url>%2F2017%2F12%2F26%2F00025_MediaWiki%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[MediaWiki是一个非常成熟完善的文档框架，也许是因为太过成熟，官方给出的文档太过全面，一些问题就连google都很难搜出有效信息。 登录问题 问题现象： 现象描述： 登录时报错：似乎您的登录会话有问题；为了防止会话劫持，这个操作已经被取消。请返回先前的页面，重新载入这个页面，然后重试。 从服务器端看session文件写入为空，但是session配置、权限等都没有问题。报错如下图： 解决方案：该问题一般是由于php 序列化导致，多数情况是由于服务器端环境缺少apcu扩展。 访问问题 问题现象： 访问直接报错：Exception encountered, of type “InvalidArgumentException” 无任何其它的nginx或php层面的报错日志输出 解决方案：MediaWiki要求服务器端php环境默认关闭session.auto_start属性，因此php.ini配置文件中session.auto_start = 0 即可。 推荐文章（由hexo文章推荐插件驱动）MediaWiki导航菜单设置MediaWiki配置文件]]></content>
      <categories>
        <category>MediaWiki</category>
        <category>填坑指南</category>
      </categories>
      <tags>
        <tag>MediaWiki</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[腾讯云虚机自动挂载数据盘脚本]]></title>
    <url>%2F2017%2F12%2F18%2F00024_%E8%85%BE%E8%AE%AF%E4%BA%91%E8%99%9A%E6%9C%BA%E8%87%AA%E5%8A%A8%E6%8C%82%E8%BD%BD%E6%95%B0%E6%8D%AE%E7%9B%98%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[把之前在腾讯云上部署环境过程中遇到的可以抽象摘取出来的固定逻辑，稍加整理供大家参考。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#!/bin/bashfunction Usage()&#123;cat &lt;&lt; EOFUsage: sh $0 sh $0 -d MOUNTDIRECTORY sh $0 -h|--help Options: -d|--MountDirectory &#123;eg:/data&#125;: Mount directory. -h|--help: Show help. EOF&#125;OPTS=$(getopt -o d:h -a --long help,MountDirectory: -n 'warning' -- "$@")eval set -- "$OPTS"while true;do case "$1" in -d|--MountDirectory) MountDirectory=$2; shift 2 ;; -h|--help) Usage; shift; exit 0 ;; --) shift; break ;; *) echo -e "\nParameter error.\n"; Usage; exit 1 ;; esacdonefunction disk_mount()&#123; if [ -b /dev/vdb ]; then echo -e "\033[32m$(date "+%Y-%m-%d %H:%M:%S") \tfdisk /dev/vdb \033[0m" fdisk /dev/vdb 1&gt;/dev/null &lt;&lt; EOFnp1wqEOF wait if [ -b /dev/vdb1 ]; then echo -e "\033[32m$(date "+%Y-%m-%d %H:%M:%S")\t mkfs.ext4 /dev/vdb1 \033[0m" mkfs.ext4 /dev/vdb1 1&gt;/dev/null sleep 3 echo -e "\033[32m$(date "+%Y-%m-%d %H:%M:%S")\t mounting -a \033[0m" mkdir -p $&#123;MountDirectory&#125; if ! grep "$&#123;MountDirectory&#125;" /etc/fstab &gt;/dev/null 2&gt;&amp;1 ; then echo -e "/dev/disk/by-uuid/$(ls -l /dev/disk/by-uuid/ |grep vdb1 |awk '&#123;print $9&#125;') $&#123;MountDirectory&#125; ext4 defaults,nofail 0 2" &gt;&gt;/etc/fstab &amp;&amp; mount -a echo -e "\033[32m$(date "+%Y-%m-%d %H:%M:%S")\t Finished. \033[0m" df -h |grep "$&#123;MountDirectory&#125;" else echo -e "\033[31m /etc/fstab record has already existed. \033[0m" fi else echo -e "\033[31m fdisk failed. \033[0m" fi else echo -e "\033[31m/dev/vdb does not exist. \033[0m" fi&#125;function main()&#123; MountDirectory="$(echo "$&#123;MountDirectory&#125;" |grep -Po '^/(\w+/)*\w+')" [ -z "$&#123;MountDirectory&#125;" ] &amp;&amp; MountDirectory=/tencentCloud/data; disk_mount&#125;main]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>自动化</tag>
        <tag>脚本</tag>
        <tag>腾讯云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MediaWiki导航菜单设置]]></title>
    <url>%2F2017%2F11%2F14%2F00023_MediaWiki%E5%AF%BC%E8%88%AA%E8%8F%9C%E5%8D%95%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[侧边栏导航(MediaWiki:Sidebar)1234567891011121314151617181920* CATEGORY-SIDEBAR* navigation** mainpage|mainpage-description** recentchanges-url|recentchanges** randompage-url|randompage** helppage|help* 自定义一级导航1** http://www.lengyuewusheng.com/ |自定义二级级导航1** http://www.lengyuewusheng.com/ |自定义二级级导航2* 自定义一级导航2** http://www.lengyuewusheng.com/ |自定义二级级导航1** http://www.lengyuewusheng.com/ |自定义二级级导航2* 自定义一级导航3** http://www.lengyuewusheng.com/ |自定义二级级导航1** http://www.lengyuewusheng.com/ |自定义二级级导航2* SEARCH* TOOLBOX* LANGUAGES 右侧悬浮目录12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364MediaWiki:Common.css/* 放置于这里的CSS将应用于所有皮肤 */#toc&#123; display: block; position: fixed; top: 100px; right: 0px; min-width: 200px; max-width: 350px; max-height: 10px; overflow-y: scroll; border: 1px solid #aaa; border-radius: 0 0 1px 1px; -moz-border-radius: 0 0 1px 1px; background: rgba(249,249,249,0.75); padding: 12px; box-shadow: 0 1px 8px #000; -webkit-box-shadow: 0 1px 8px #000; -moz-box-shadow: 0 1px 8px #000;&#125; #toc:hover&#123; display: block; position: fixed; top: 100px; right: 0px; min-width: 200px; max-width: 350px; max-height: 100px; max-height: 600px; overflow-y: scroll; border: 1px solid #aaa; border-radius: 0 0 1px 1px; -moz-border-radius: 0 0 1px 1px; background: rgba(249,249,249,0.75); padding: 12px; box-shadow: 0 1px 8px #000; -webkit-box-shadow: 0 1px 8px #000; -moz-box-shadow: 0 1px 8px #000; &#125; body &#123; overflow-x: hidden;&#125;/*Extension:TreeAndMenu*/.fancytree ul &#123; background: none; border: none; font-size: 12px;&#125;ul.fancytree-container &#123; outline: 0; border: none; overflow: hidden;&#125;.fancytree p &#123; display: none;&#125;span.fancytree-title &#123; cursor: default;&#125;span.fancytree-title a &#123; color: black;&#125; 参考 Mediawiki修改左侧导航条 MediaWiki-目录悬浮+隐藏 推荐文章（由hexo文章推荐插件驱动）MediaWiki常见问题汇总MediaWiki配置文件]]></content>
      <categories>
        <category>MediaWiki</category>
      </categories>
      <tags>
        <tag>MediaWiki</tag>
        <tag>开源工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统中的IO模式]]></title>
    <url>%2F2017%2F08%2F22%2F00021_Linux%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84IO%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[一次IO的两个阶段： Waiting for the data to be ready(等待数据到达内核缓冲区)； Copying the data from the kernel to the process(从内核缓冲区拷贝数据到程序缓冲区)） table th:nth-of-type(2){width: 80%;} IO模式 模式 特点 阻塞 I/O（blocking IO） 在IO执行的两个阶段都处于blocked（阻塞）状态 非阻塞 I/O（nonblocking IO） 用户进程需要不断的主动询问kernel数据，相当于copy data from kernel to user)依然处于一个阻塞状态 I/O 多路复用（ IO multiplexing） 两个阶段的都是阻塞状态，但是可以同时监听多个文件描述符。 信号驱动 I/O（ signal driven IO） 在实机生产环境中并不常用 异步 I/O（asynchronous IO） 相比信号驱动IO，异步IO两个阶段都是非阻塞的 阻塞式IO(默认)，非阻塞式IO(nonblock)，IO复用(select/poll/epoll)，signal driven IO(信号驱动IO)都是属于同步型IO。 IO多路复用的机制 机制 特点 select 良好跨平台支持,单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024 poll pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。 epoll Linux系统专有，在2.6内核中新增。更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。 select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 epoll的两种模式 边缘触发(ET:edge-triggered):是高速工作模式，只支持no-block socket，当状态有变化或发生了某种事件就发出通知； 水平触发(LT:level triggered):是默认的工作方式，同时支持block和no-block socket，当处于某种状态或具备某种条件就发出通知； ET和LT的区别：LT事件不会丢弃，只要读buffer里面有数据可以让用户读，则会不断通知你。而ET则只在事件发生之时通知。 epoll优点 当检查大量的文件描述符时，epoll的性能延展性比select和poll高很多； epoll API既支持水平触发也支持边缘触发，select和poll只支持水平触发，信号驱动只支持边缘触发； 性能方面，epoll可以避免复杂的信号处理流程； 灵活性高，可以指定我们希望检查的事件类型。 参考Linux五种IO模型浅谈Linux IO模式及 select、poll、epoll详解 推荐文章（由hexo文章推荐插件驱动）存储空间计算Linux系统中的tmpfs、/dev/shm、tmp以及共享内存机制tmux窗口管理Linux挂载Windows共享目录常用shell命令总结]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C10K问题]]></title>
    <url>%2F2017%2F08%2F14%2F00018_C10K%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[维基百科描述 The C10k problem is the problem of optimising network sockets to handle a large number of clients at the same time. The name C10k is a numeronym for concurrently handling ten thousand connections. Note that concurrent connections are not the same as requests per second, though they are similar: handling many requests per second requires high throughput (processing them quickly), while high number of concurrent connections requires efficient scheduling of connections. In other words, handling many requests per second is concerned with the speed of handling requests, whereas a system capable of handling a high number of concurrent connections does not necessarily have to be a fast system, only one where each request will deterministically return a response within a (not necessarily fixed) finite amount of time. The problem of socket server optimisation has been studied because a number of factors must be considered to allow a web server to support many clients. This can involve a combination of operating system constraints and web server software limitations. According to the scope of services to be made available and the capabilities of the operating system as well as hardware considerations such as multi-processing capabilities, a multi-threading model or a single threading model can be preferred. Concurrently with this aspect, which involves considerations regarding memory management (usually operating system related), strategies implied relate to the very diverse aspects of the I/O management. 简单概括Web2.0时代，由于互联网用户的快速增长，以及应用程序的日趋复杂。最初的服务器都是基于进程/线程模型的，新到来一个TCP连接，就需要分配1个进程或线程。一台机器的资源有限，无法创建很多进程。C10K就要创建1万个进程，操作系统会出现效率低下或崩溃的情况。 问题解决 FreeBSD推出了kqueue Linux推出了epoll Windows推出了IOCP 参考文档 http://rango.swoole.com/archives/381 http://www.52im.net/thread-566-1-1.html http://www.52im.net/thread-578-1-1.html https://segmentfault.com/a/1190000007240744]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于生产环境的仿真流量测试]]></title>
    <url>%2F2017%2F08%2F13%2F00017_%E5%9F%BA%E4%BA%8E%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E7%9A%84%E4%BB%BF%E7%9C%9F%E6%B5%81%E9%87%8F%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[虽然业界的Web应用测试工具众多，但多数是基于压力的离线测试，很多时候很难发现所有问题，往往测试上线后依然存在各种问题。基于实际生产环境的仿真流量测试，无疑能够覆盖更多的问题，达到更好的测试效果。以下介绍三种实现仿真流量测试环境的实现工具。 goreplay 源码下载 下载 文档 GitHubWiki 特点 Go语言编写 功能强大，简单易用 资源消耗少 简单用例 将本地8080端口流量复制到 10.0.0.2 的80端口1./goreplay --http-original-host --input-raw :8080 --input-raw-realip-header &quot;X-Real-IP&quot; --output-http &quot;http://10.0.0.2:80&quot; --exit-after 259200s Tcpcopy 源码下载 Tcpcopy intercept 文档 GitHub·READEME 特点 C语言编写 使用复杂 依赖root权限或CAP_NET_RAW capability(e.g. setcap CAP_NET_RAW=ep tcpcopy) 依赖于 assistant server的intercept截获应答 简单用例 12310.0.0.1 生产环境10.0.0.2 测试环境10.0.0.3 assistant server 生产环境 12./tcpcopy -x 8080-10.0.0.2:80 -s 10.0.0.3 -d -n2# 将生产环境本地8080端口流量放大2倍复制到10.0.0.2的80端口，并指定10.0.0.3为assistant server 测试服务器（10.0.0.2）上添加路由 123route add -net 10.0.0.0 netmask 255.255.255.0 gw 10.0.0.3或：route add -host 10.0.0.1 gw 10.0.0.3 assistant server 12./intercept -i eth0 -F ‘tcp and src port 80’ -d# assistant server的intercept捕获eth0网卡的80端口的响应包 ngx_http_mirror_module mirror模块默认开启，编译时加–without-http_mirror_module参数可禁用此功能。 版本 Nginx 1.13.4 + 作用域 http, server, location mirror 模块配置分为两部分：源地址和镜像地址配置。 简单用例配置 12345678910111213141516171819# original配置location / &#123; mirror /mirror; mirror /mirror2; mirror_request_body off; //是否镜像请求Body部分 proxy_pass http://prod.env:8080;&#125;# mirror配置 //mirror不会输出http返回内容location /mirror &#123; internal; //指定此location只能被内部的请求调用，外部的调用请求会返回404 proxy_pass http://test.env:8000$request_uri; //指定上游Server的地址 proxy_set_header X-Original-URI $request_uri; //镜像流量的头部&#125;location /mirror2 &#123; internal; proxy_pass http://test2.env:8000$request_uri; proxy_set_header X-Original-URI $request_uri;&#125; 推荐文章（由hexo文章推荐插件驱动）nginx-rewrite指令中的flag参数nginx配置location匹配规则nginx配置中的if指令nginx访问频率限制]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>仿真测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统中的tmpfs、/dev/shm、tmp以及共享内存机制]]></title>
    <url>%2F2017%2F08%2F12%2F00016_Linux%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[共享内存允许两个或更多进程访问同一块内存。 tmpfstmpfs一种基于内存的临时文件系统，tmpfs可以使用RAM，但它也可以使用swap分区来存储。传统的ramdisk是个块设备，要用mkfs来格式化它，才能真正地使用它；tmpfs是一个文件系统，并不是块设备，安装即可以使用。tmpfs是最好的基于RAM的文件系统。 特征： 动态文件系统大小 存取速度快 /dev/shm是利用内存虚拟出来的磁盘空间。通常是内存空间大小的一半，该目录下创建的文件存取速度优于普通硬盘挂载的目录下的文件，该目录下的文件在机器重启时会丢失。 /tmp目录存放临时文件的目录。由于通常/dev/shm挂载在/tmp目录下，该目录会被不同用户读写，因此该目录的权限建议设置成777。之前就在生产环境中遇到过/tmp目录权限被旁路流程误修改为755，导致普通用户启动的C++的应用无法写入共享内存，导致线上服务异常的惨痛教训。希望大家吸取教训。这种目录权限导致的问题，恢复较为容易，但是定位问题原因较为复杂，由于之前的代码中没有调试逻辑，出现问题时，开发临时新上了一版代码增加了详细的错误输出，最后才定位到共享内存写入失败导致，此过程花费相对较长的时间。 文件系统挂载关系123# cat /etc/fstab |egrep &quot;tmp|shm&quot;tmpfs /dev/shm tmpfs defaults 0 0/dev/shm /tmp none rw,bind 0 0 Linux的两种共享内存机制: POSIX共享内存(结合内存映射mmap使用) mmap映射的内存是非持久化的，随着进程关闭，映射会随即失效。 mmap内存映射机制标准的系统调用，分为： 匿名映射 文件映射，又分为： MAP_PRIVATE MAP_SHARED System V共享内存(经典方案) sysv shm是持久化的，除非被进程明确的删除，否则在系统关机前始终存在于内存中。 虽然System V与POSIX共享内存都是通过tmpfs实现，但由于内核在mount tmpfs时，指定了MS_NOUSER，所以该tmpfs没有大小限制。因此/proc/sys/kernel/shmmax只会限制System V共享内存，/dev/shm只限制Posix共享内存,默认是物理内存的一半。 System V共享内存的最大值 12# cat /proc/sys/kernel/shmmax68719476736 /dev/shm空间大小设定 1mount -t tmpfs -o size=2G tmpfs -o remount /dev/shm 修改tmpfs大小 /etc/fstab 字段介绍 12/etc/fstab# &lt;file system&gt; &lt;dir&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt; file system: 要挂载的分区或存储设备 dir: file systems的挂载位置 type: 要挂载设备或是分区的文件系统类型 ext2, ext3, ext4, reiserfs, xfs, jfs, smbfs, iso9660, vfat, ntfs, swap 及 auto options: 挂载时使用的参数 defaults dump: dump工具通过它决定何时作备份 0和1,0表示忽略，1则进行备份。大部分的用户是没有安装 dump 的，对他们而言应设为 0。 pass fsck 读取 pass的数值来决定需要检查的文件系统的检查顺序。允许的数字是0,1,和2。 根目录应当获得最高的优先权 1, 其它所有需要被检查的设备设置为 2. 0表示设备不会被 fsck 所检查。 centos5修改tmpfs大小 123cat /etc/fstabtmpfs /dev/shm tmpfs defaults 0 0 //修改这行不起作用/dev/shm /tmp none rw,bind,size=55g 0 0 centos6/7修改tmpfs大小 123cat /etc/fstabtmpfs /dev/shm tmpfs defaults,size=30g 0 0/dev/shm /tmp none rw,bind 0 0 // 修改这行不起作用 挂载命令 12mount -a //加载文件&quot;/etc/fstab&quot;中描述的所有文件系统。mount -o remount /dev/shm //重新加载设备 要直接执行 mount -a 命令，因为可能造成无法访问当前目录中的文件（比如你应该保证 lockfiles 的正常存在）。 然而，如果它们都是空的，那么就可以直接执行 mount -a 而不必重启电脑。 应用更改后，可以通过 findmnt 检查是否生效： 1findmnt --target /tmp tmpfs 可以设置成比物理内存大，但是只能存储小于物理内存空间的数据，之后会出现登录掉线等异常. 推荐文章（由hexo文章推荐插件驱动）存储空间计算Linux系统中的IO模式tmux窗口管理Linux挂载Windows共享目录常用shell命令总结]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>共享内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[存储空间计算]]></title>
    <url>%2F2017%2F08%2F11%2F00015_%E5%AD%98%E5%82%A8%E7%A9%BA%E9%97%B4%E8%AE%A1%E7%AE%97%2F</url>
    <content type="text"><![CDATA[最基础的知识往往是最容易被忽略的点，放低姿态，夯实基础，才能行稳致远。 存储空间单位换算12345671 B = 8 bit1 KB = 1024 B = 8192 bit1 MB = 1024 KB = 1048576 B = 8388608 bit1 GB = 1024 MB = 1048576 KB = 1073741824 B = 8589934592 bit1 TB = 1024 GB = 1048576 MB = 1073741824 KB = 1099511627776 B = 8796093022208 bit1 PB = 1024 TB = 1048576 GB = 1073741824 MB = 1099511627776 KB = 1125899906842624 B = 9007199254740992 bit1 EB = 1024 PB = 1048576 TB = 1073741824 GB = 1099511627776 MB = 1125899906842624 KB = 1.152921504606847e+18 B = 9.223372036854776e+18 bit ASCII编码 一个ASCII码占一个字节 一个英文字母占一个字节 一个中文汉字占两个字节 UTF-8编码 一个英文字符等于一个字节 一个中文（含繁体）占三个字节 Unicode编码 一个英文字占两个字节 一个中文（含繁体）占两个字节 符号 英文标点占一个字节 中文标点占两个字节 推荐文章（由hexo文章推荐插件驱动）Linux系统中的tmpfs、/dev/shm、tmp以及共享内存机制Linux系统中的IO模式tmux窗口管理Linux挂载Windows共享目录常用shell命令总结]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>磁盘存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用shell命令总结]]></title>
    <url>%2F2017%2F08%2F10%2F00014_%E5%B8%B8%E7%94%A8shell%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Linux常用低端入门命令。 table th:nth-of-type(2){width: 80%;} 系统监控、审计 ssh 远程执行命令，屏蔽连接警告、提示 1ssh -o StrictHostKeyChecking=no -q 127.0.0.1 &quot;whoami&quot; history命令记录加时间戳 1234export HISTTIMEFORMAT=&quot;%F %T `whoami` &quot;# 或echo &apos;export HISTTIMEFORMAT=&quot;%F %T `whoami` &quot;&apos; &gt;&gt; /etc/profilesource /etc/profile 操作审计 1script -qaf /tmp/audit.log 查看命令执行输出变化 1watch -n1 -d -t &quot;date +%s&quot; 输出命令执行消耗的时间 1234567# /usr/bin/time -f &quot;time: %E&quot; sleep 10 &amp;&amp; echo &quot;OK&quot;time: 0:10.00OK%E real时间，显示格式为[小时:]分钟:秒;%U user时间;%S sys时间。 编程方式重置用户密码 1echo 密码|passwd --stdin 用户名 输入输出 读取键盘输入 123456789read默认将读取到的数据保存到变量REPLY中-p &quot;tips:&quot;输出提示-s 密码方式输入，不回显-r 允许读取反斜杠-t timeout 设置等待超时时间-n number 设置读取变量的最大长度，不需回车结束-d &quot;@&quot; 定义结束符，默认回车-a arrayName 将单词存入数组 终端输出 12stty -echo 禁止将输出发送到终端stty echo 允许将输出发送到终端 彩色输出 12345678echo -e &quot;\033[30m 黑色字 \033[0m&quot;echo -e &quot;\033[31m 红色字 \033[0m&quot;echo -e &quot;\033[32m 绿色字 \033[0m&quot;echo -e &quot;\033[33m 黄色字 \033[0m&quot;echo -e &quot;\033[34m 蓝色字 \033[0m&quot;echo -e &quot;\033[35m 紫色字 \033[0m&quot;echo -e &quot;\033[36m 天蓝字 \033[0m&quot;echo -e &quot;\033[37m 白色字 \033[0m&quot; json格式化输出 12345678910111213141516171819curl -s http://ip.taobao.com/service/getIpInfo.php?ip=8.8.8.8|python -m json.tool&#123; &quot;code&quot;: 0, &quot;data&quot;: &#123; &quot;area&quot;: &quot;&quot;, &quot;area_id&quot;: &quot;&quot;, &quot;city&quot;: &quot;&quot;, &quot;city_id&quot;: &quot;&quot;, &quot;country&quot;: &quot;\u7f8e\u56fd&quot;, &quot;country_id&quot;: &quot;US&quot;, &quot;county&quot;: &quot;&quot;, &quot;county_id&quot;: &quot;&quot;, &quot;ip&quot;: &quot;8.8.8.8&quot;, &quot;isp&quot;: &quot;&quot;, &quot;isp_id&quot;: &quot;&quot;, &quot;region&quot;: &quot;&quot;, &quot;region_id&quot;: &quot;&quot; &#125;&#125; 将Windows格式转换成unix格式,去掉^M 1dos2unix windows.txt 用sed消除空格 1sed s/[[:space:]]//g 文件属性 文件只读属性 12345678910# 增加只读属性chattr +i filename# 删除只读属性chattr -i filename# 增加追加属性chattr +a filename# 删除追加属性chattr -a filename# 查看文件属性lsattr filename 输出文件属性 1234# 数字格式输出文件或目录的权限值stat -c&quot;%a&quot; /tmp# 显示某一文件或目录的创建时间stat -c&quot;%Z&quot; /tmp 获取软链实际指向的路径 1readlink /usr/local/test/link 显示文件或目录的绝对路径 1ls -1d /data/files/* 文本、文件操作 生成随机字符串显示成三列 1tr -dc &apos;A-Za-z0-9!@#$%^&amp;*&apos; &lt; /dev/urandom | fold -w 30 | head -n 30|paste - - - 生成随机密码 12345# 方式一echo `tr -dc &apos;a-zA-Z0-9&apos; &lt; /dev/urandom | head -c20`cat /dev/urandom | tr -dc &apos;a-zA-Z0-9&apos; | head -c 10# 方式二tr -dc &apos;A-Za-z0-9!@#$%^&amp;*&apos; &lt; /dev/urandom | fold -w 20 | head -n 1 cut命令方式截取 1234cut -c N-Meg: 获取系统版本lsb_release -r |awk &apos;&#123;print $2&#125;&apos;|cut -c 1-3 根据已有字符串生成随机临时文件名后缀 1FileName=$(echo $SERV | md5sum | cut -d&quot; &quot; -f1) 日志文件切割 123456789# 按行数切割split -l 行数 -d -a 3 文件 文件前缀 #-d：数字后缀 #-a length 指定后缀的长度 eg: split -l 100000 -d -a 4 nginx_access_log /var/log/nginx_access_log_# 按文件大小切割split -b 大小 文件 文件前缀 # -b：指定文件大小，单位为byte # 默认分隔为字母后缀的文件 多行文本转换成一行(将目录中的子文件或目录一行输出) 12345678910# awk方式ls -1 /var/log/ |awk &apos;BEGIN&#123;printf(&quot;%s&quot;,&quot;&#123;&quot;)&#125;&#123;printf(&quot;%s,&quot;,$0);&#125;END&#123;print &quot;&#125;&quot;&#125;&apos;# sed方式ls -1 /var/log/ |sed &apos;:a;N;s/\n/\t/;t a;&apos;# paste方式ls -1 /var/log/ |paste -d&quot; &quot; -s# tr方式ls -1 /var/log/ |tr -s &quot;\n&quot; &quot;\t&quot;# xargs方式ls -1 /var/log/ |xargs echo 输出重定向副本到文件 1whoami |tee -a /tmp/script.log diff命令常用参数 1234567891011-b或--ignore-space-change：不检查空格字符的不同； -B或--ignore-blank-lines：不检查空白行；-H或--speed-large-files：比较大文件时，可加快速度； -i或--ignore-case：不检查大小写的不同； -q或--brief：仅显示有无差异，不显示详细的信息； -s或--report-identical-files：若没有发现任何差异，仍然显示信息； -T或--initial-tab：在每行前面加上tab字符以便对齐； -w或--ignore-all-space：忽略全部的空格字符；-y或--side-by-side：以并列的方式显示文件的异同之处；--left-column：在使用-y参数时，若两个文件某一行内容相同，则仅在左侧的栏位显示该行内容；--suppress-common-lines：在使用-y参数时，仅显示不同之处。 文件备份 1234mv -bf -S &quot;_$(date &quot;+%Y-%m-%d_%H%M%S&quot;)&quot; /tmp/test /tmp/ &gt;/dev/null 2&gt;&amp;1-b：需要覆盖时，备份源文件；-f：若目标文件或目录存在，则强制覆盖；-S&lt;后缀&gt;：为备份文件指定后缀，默认后缀为~，当备份文件或目录已存在时，mv操作报错中止； 网络、端口、进程 释放已删除文件占用的磁盘空间 1lsof |grep delete |awk &apos;&#123;print $2&#125;&apos;|xargs kill -9 ping 命令输出结果前加时间戳前缀 1ping 127.0.0.1| awk &apos;&#123; now=strftime(&quot;%Y-%m-%d %H:%M:%S&quot;,systime()); printf(&quot;%s:%s\n&quot;,now,$0);&#125;&apos; 解析与反解析 123dig +short www.lengyuewusheng.com# 主要在内网环境中应用dig +short -x 10.0.0.1 输出本地启动的服务及端口 1netstat -anltp|awk &apos;&#123;if($NF==&quot;*&quot;) &#123;print $4&quot;:&quot; $(NF-1)&#125; else &#123;print $4&quot;:&quot; $NF&#125;&#125;&apos;|sed &apos;s/\//:/g&apos;|egrep -v &quot;:::|::&quot; |awk -F&apos;:&apos; &apos;&#123;if ($2~/^[0-9]*$/) print $2&quot; &quot;$NF&#125;&apos;|sort -u 统计TCP不同连接状态的连接数 1netstat -n|awk &apos;/^tcp/ &#123;++a[$NF]&#125; END &#123;for (b in a) print b,&quot;\t&quot;,a[b]&#125;&apos; 探测端口是否开放 12345nc -w1 -s &quot;$&#123;SourceIP&#125;&quot; -z &quot;$&#123;TargetIP&#125;&quot; &quot;$&#123;TargetPort&#125;&quot; &gt;/dev/null 2&gt;&amp;1 &amp;# 指定本地IP本地端口nc -v -s 10.0.0.1 -p 50000 -w3 -z 10.0.0.2 80# 简单模式nc -w3 -z 10.0.0.2 80 探测机器活性 1ping -c 1 -w 2 $&#123;TargetIP&#125; &gt;/dev/null 2&gt;&amp;1 关闭80端口的占用程序 1fuser -k -n tcp 80 查看80端口的占用程序 1lsof -i :80 获取网卡的IP地址 1ip addr show dev eth0 | awk &apos;/inet/ &#123;sub(/\//, &quot; &quot;); print $2&#125;&apos;|head -1 端口流量查询 123iftop -i eth1 -n -P# 命令安装yum -y install http://dl.fedoraproject.org/pub/epel/6/x86_64//iftop-1.0-0.14.pre4.el6.x86_64.rpm 请求网关信息 12345678# 命令行查询(详细): UNIX/Linux: #curl cip.cc Windows: &gt; telnet cip.cc &gt; ftp cip.cc# 命令行查询纯ip返回: UNIX/Linux: #curl ip.cip.cc 防火墙放开http、ssh 1lokkit -s http -s ssh date 系列 时间日期操作12345678910111213141516171819# date -d &quot;@1500000000&quot; &quot;+%d/%b/%Y:%H:%M:%S&quot;14/Jul/2017:10:40:00# date -d &quot;@1500000000&quot; &quot;+%Y-%m-%d %H:%M:%S&quot;2017-07-14 10:40:00# date -d &quot;2017-07-14 10:40:00&quot; &quot;+%s&quot;1500000000# date -d &quot;1 hours ago&quot; &quot;+%Y-%m-%d %H:%M:%S&quot;2017-08-15 08:59:59# date &quot;+%Y-%m-%d %H:%M:%S %N&quot;2017-10-04 15:43:15 911203100for i in &#123;001..100&#125; ##for i in $(seq -w 0 100)do echo -e &quot;$i\t $(date &quot;+%Y-%m-%d %H:%M:%S.%N&quot;)&quot;done find 系列 find 相关操作12345678910111213141516171819202122# 针对find查询到的结果进行多步操作find . -name &quot;*.cfg&quot; -exec echo -e &quot;=============\n&#123;&#125;&quot; \; -exec ls -1 &#123;&#125; \;# find 排除多个目录find /data/ \( -path /data/test1 -o -path /data/test2 -o -path /data/test3 \) -prune -o -type f -name &quot;fileName&quot; -exec echo -e &quot;=============\n&#123;&#125;&quot; \; -exec dirname &#123;&#125; \;固定格式： \( -path /path1 -o -path /path2 \) -prune -o# 对find查询结果执行多步操作find /data/ \( -path /data/test1 -o -path /data/test2 -o -path /data/test3 \) -prune -o -type f -name &quot;fileName&quot; -print |xargs -P3 -n1 -I &#123;&#125; sh -c &apos;[ -L &#123;&#125; ] &amp;&amp; echo -e &#123;&#125;&quot;is a Soft link.&quot; || echo -e &quot;&#123;&#125; is a File.&quot;&apos;xargs后通过sh -c &apos;&apos;执行多次命令-P num 开启num个进程加速处理# find统计/var/log目录下每一个文件的记录行数find /var/log/ -type f -name &quot;*.log&quot; -print0 | xargs -0 wc -l # -print0：假设find指令的回传值为Ture，就将文件或目录名称列出到标准输出。格式为全部的名称皆在同一行 # xargs -0将\0作为定界符# 最近7天日志文件的总大小find /var/log/ -mtime -7 -type f | xargs du -ch | tail -n1# 对文件批量重命名find /data/ -type f -name &quot;*keywords*&quot; |xargs -t -i mv &#123;&#125; &#123;&#125;.bak$(date &quot;+%Y%m%d&quot;) shell语法 变量赋值 1234$&#123;VAR:-string&#125; 如果VAR变量为空则返回string$&#123;VAR:+string&#125; 如果VAR变量不为空则返回string$&#123;VAR:=string&#125; 如果VAR变量为空则重新赋值VAR变量值为string$&#123;VAR:?string&#125; 如果VAR变量为空则将&quot;string&quot;作为报错信息输出到stderr 字符串截取及替换 符号 意义 ${var#*”分隔符”} #*”分隔符” 表示删除从左往右第一个分隔符以及其左边的所有字符 ${var##*”分隔符”} ##*”分隔符” 表示删除从左往右最后一个分隔符以及其左边的所有字符 ${var%”分隔符”*} %”分隔符”* 表示删除从右往左第一个分隔符以及其右边的所有字符 ${var%%”分隔符”*} %%”分隔符”* 表示删除从右往左最后一个分隔符以及其右边的所有字符 ${var:n:m} 从左边第n个字符开始，往右截取m个字符 ${var:n} 从左边第n个字符开始，往右截取到最后 ${var:0-n:m} 从右边第n个字符开始，往右截取m个字符 ${var:0-n} 从右边第n个字符开始，往右截取到最后 ${var/ABC/abc} 将${var}中第一个ABC用abc替换ABC ${var//ABC/abc} 将${var}中所有的ABC用abc替换ABC ${var/#ABC/abc} 如果字符串${var}以ABC开头则用abc替换ABC ${var/%ABC/abc} 如果字符串${var}以ABC结尾则用abc替换ABC ${var#start} 如果字符串${var}以start开头，则删掉 ${var%end} 如果字符串${var}以end结束，则删掉 ${var#s} 如果字符串${var}开头第一个字母是s则删掉 ${var%e} 如果字符串${var}最后一个字母是e则删掉 $- 当前设置的shell选项 ${-#*i} 删除shell选项中i以及其左边的所有字符，常用于判断是否是交互式shell $- shell选项参数说明123456789$- prints The current set of options in your current shell.himBH means following options are enabled:H - histexpandm - monitorh - hashallB - braceexpandi - interactive eg:123456789101112131415161718var=http://test.com/index.html_http://test.com/default.html$&#123;var#*//&#125;: test.com/index.html_http://test.com/default.html$&#123;var##*/&#125;: default.html$&#123;var%/*&#125;: http://test.com/index.html_http://test.com$&#123;var%%/*&#125;: http:$&#123;var:0:3&#125;: htt$&#123;var:5&#125;: //test.com/index.html_http://test.com/default.html$&#123;var:0-10:3&#125;: fau$&#123;var:0-10&#125;: fault.html$&#123;var/http/https&#125;: https://test.com/index.html_http://test.com/default.html$&#123;var//http/https&#125;: https://test.com/index.html_https://test.com/default.html$&#123;var/#http/https&#125;: https://test.com/index.html_http://test.com/default.html$&#123;var/%html/php&#125;: http://test.com/index.html_http://test.com/default.phpvar=&quot;starrend&quot;$&#123;var#start&#125;: end$&#123;var%end&#125;: start 变量的间接引用 123var1=&quot;It&apos;s a magical way&quot;var2=&quot;var1&quot;echo &quot;$&#123;!var2&#125;&quot; shell中的括号 符号 意义 () 1.定义数组变量；2.命令组，括号中的变量不能被括号外引用 $() 和反引号(``)相同，都是用来做命令替换 $(()) 和$[]相同，都是进行数学计算，bash中只能进行整数运算，浮点数作为字符串处理 [] 1.test的另一种形式;2.字符范围 $[] 和$(())相同，都是进行数学计算 [[]] bash中的关键字，不是命令，用于if判断结构 {} 代码块，又称内部组。与小括号不同，大括号内的命令不会新开一个子shell运行，括号内变量可以被括号外引用。分号隔开命令，最后一条命令也必须跟分号。 ${} 变量引用 判断字符串包含 12345678long_str=abcdedshort_str=defif [[ &quot;$&#123;long_str&#125;&quot; =~ &quot;$&#123;short_str&#125;&quot; ]]; then echo &quot;包含&quot;else echo &quot;不包含&quot;fi=~ 判断前者是否包含后者 数组操作 12345数组定义：arrayName=(&quot;elements_1&quot; &quot;elements_2&quot; &quot;elements_3&quot;)数组单个元素赋值：arrayName[$i]=&quot;value&quot;数组长度：$&#123;#arrayName[@]&#125;取数组所有元素：$&#123;arrayName[@]&#125;数组中的单个元素：$&#123;arrayName[$i]&#125; 其它命令 时间同步 1234# 硬件时间与系统时间同步/sbin/clock -w# 本地时间与时间服务器同步/usr/sbin/ntpdate ntp.server 查看单个进程的top信息 1top -p $(pidof $&#123;ProcessName&#125;|sed &apos;s/ /,/g&apos;) ab压测 1ab -c 100 -n 10000 &quot;http://127.0.0.1/&quot; 系统盘iNode使用率过高，一般的清理策略 1find /var/spool/postfix/maildrop/ -type f -delete top后台记录系统启动的进程信息 12345top -bc -n 3 -d 5-b: 批处理模式-c: 显示完整命令-d: 设置延迟间隔-n: 设置输出次数 编码转换 1iconv -f GBK -t UTF-8 gbk.txt -o utf8.txt 硬件相关 虚机硬盘坏盘修复 123456确定文件系统类型：df -T修复：umount /dev/vdbxfs_repair /dev/vdb xfs_repair: xfsprogs.x86_64 推荐文章（由hexo文章推荐插件驱动）shell脚本传参shell的分批并发操作的简单实现shell printf格式化输出Linux命令行环境下进行URL解码存储空间计算]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http不同版本及特性概括]]></title>
    <url>%2F2017%2F08%2F09%2F00013_http%E4%B8%8D%E5%90%8C%E7%89%88%E6%9C%AC%E5%8F%8A%E7%89%B9%E6%80%A7%E6%A6%82%E6%8B%AC%2F</url>
    <content type="text"><![CDATA[HTTP（HyperText Transfer Protocol）是互联网应用中最常见的一种协议。 HTTP 0.91991年，Tim Berners-Lee概述。 特性： 客户端/服务器，请求/响应； ASCII协议，运行于TCP/IP链接之上； 传输超文本文档（HTML）； 服务器和客户端之间的连接在每次请求之后都会关闭； http逃逸原理由于http0.9协议没有响应头。大多数防火墙产品只是简单地让它无法分析的数据包直接通过，对HTTP/0.9的响应包没有做进一步检测。导致http/0.9协议传输的响应包可以绕过防火墙。 HTTP 1.01996年，HTTP工作组发布 RFC 1945。 特性： HTTP1.0并不是一个正式的规范或标准 请求可以由多行首部字段构成； 响应对象前面包含响应状态行； 响应对象包含由换行符分割的首部字段； 响应对象不局限于超文本； 服务器和客户端之间的连接在每次请求之后都会关闭； HTTP1.11997年1月，定义正式http1.1标准的RFC2068发布；1999年6月，RFC2616发布，在标准中集合了很多改进和更新。 特性： 默认持久连接 分块编码传输 字节范围请求 增强的缓存机制 传输编码及请求管道 内容编码字符集以及语言的协商机制 HTTP 2.02012年1月，HTTP 2.0纲领发布。 特性： 主要目标是改进传输性能，实现低延迟和高吞吐量 二进制分帧 异步连接 多路复用 头部压缩 流量控制 请求响应管线化（管道Pipelining传输） 请求优先级 服务器推送 参考 Ilya, Grigorik. Web性能权威指南[M]. 人民邮电出版社, 2014. 推荐文章（由hexo文章推荐插件驱动）HTTP协议中的8种请求方法http请求常见状态码及解释http协议头字段说明]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置location匹配规则]]></title>
    <url>%2F2017%2F08%2F08%2F00012_nginx%E9%85%8D%E7%BD%AElocation%E5%8C%B9%E9%85%8D%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[请求路由定位是Nginx的核心功能，位于ngx_http_core_module模块中。 location匹配模式 table th:nth-of-type(2){width: 80%;} 判断条件 符号意义 ~ 区分大小写地匹配正则 ~* 不区分大小写地匹配正则 ^~ 普通字符（相对于正则）匹配，一般用来匹配目录 = 进行普通字符精确匹配 @ “@”定义一个命名的 location,用于内部重定向，不能被嵌套，不能包含嵌套的location。例如 error_page, try_files location 匹配的优先级 = 精确匹配会第一个被处理。如果发现精确匹配，nginx停止搜索其他匹配； Nginx首先检查最长前缀字符串匹配，其次检查正则表达式的匹配程度； 最长前缀匹配如果使用”^~”，则不检查正则表达式； 当没有正则表达式或者没有正则表达式被匹配的情况下，那么匹配程度最高的前缀匹配规则会被应用。 参考文档 nginx官方文档location部分 推荐文章（由hexo文章推荐插件驱动）nginx-rewrite指令中的flag参数nginx配置中的if指令基于生产环境的仿真流量测试nginx访问频率限制]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>location</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置中的if指令]]></title>
    <url>%2F2017%2F08%2F07%2F00011_nginx%E9%85%8D%E7%BD%AE%E4%B8%AD%E7%9A%84if%E6%8C%87%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[通常Nginx的if判断不支持else逻辑。 判断条件 table th:nth-of-type(2){width: 80%;} 判断条件 符号意义 = ,!= 比较字符串相等 ~ 匹配正则表达式 ~* 不区分大小写的匹配 !~ 区分大小写的不匹配 -f ，!-f 判断文件是否存在 -d, !-d 判断目录是否存在 -e ，!-e 判断文件、目录或链接是否存在 -x ， !-x 判断文件是否可被执行 说明 作用域：server,location if指令中如果一个变量是空字符串或者以0开始的字符串，则为false； nginx的if条件判断不支持else语法； 参考文档 nginx官方文档Module ngx_http_rewrite_module部分 推荐文章（由hexo文章推荐插件驱动）nginx-rewrite指令中的flag参数nginx配置location匹配规则基于生产环境的仿真流量测试nginx访问频率限制nginx-rewrite指令中的flag参数]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>rewrite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-rewrite指令中的flag参数]]></title>
    <url>%2F2017%2F08%2F06%2F00010_nginx-rewrite%E6%8C%87%E4%BB%A4%E4%B8%AD%E7%9A%84flag%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Nginx的ngx_http_rewrite_module模块使用PCRE（pcre.x86_64）正则表达式重定向URL。 table th:nth-of-type(2){width: 80%;} flag 参数 flag参数 意义 last 终止rewrite指令匹配，然后对当前重写的新URI在rewrite指令集上重新查找 break 停止处理后续rewrite指令集，并不在重新查找,但是当前location内剩余非rewrite语句和location外的的非rewrite语句可以执行 permant 返回301永久重定向，地址栏显示跳转后的地址 redirect 返回302临时重定向，地址栏显示跳转后的地址 说明 nginx可以通过增加rewrite_log on; error_log logs/error.log notice;调试 rewrite； last：将rewrite后的地址重新在server标签执行； break：将rewrite后地址重新在当前的location标签执行； last和break正常返回200状态码； last一般写在server和if中，而break一般使用在location中； last不终止重写后的url匹配，而break终止重写后的匹配； 一般使用302重定向是在一个网站或网页在24到48小时之内临时移到其它位置，建议尽量采用301重定向； rewrite指令执行过程中如果循环超过10次，则返回500 Internal Server Error错误； rewrite正则表达regex式中包含 “}” 或 “;”时整个表达式需要用双引号或单引号引起来； 参考文档 nginx官方文档Module ngx_http_rewrite_module部分 推荐文章（由hexo文章推荐插件驱动）nginx配置location匹配规则nginx配置中的if指令基于生产环境的仿真流量测试nginx访问频率限制nginx配置中的if指令]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>rewrite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows小工具]]></title>
    <url>%2F2017%2F08%2F05%2F00020_Windows%E5%B0%8F%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[table th:nth-of-type(2){width: 80%;} 工具名 描述 Chocolatey Windows 包管理器 Windows Subsystem for Linux Windows环境下的Linux模式 SysInternals 微软官方提供的免费工具集。文档 Cygwin 在 Windows 中为你提供 Unix 环境 WinMTR Windows环境下mtr工具 Listary 文件管理器 everything 本地文件搜索神器 KeePass 本地密码存储客户端 Fiddler HTTP 调试代理 Wireshark 网络封包分析软件 Snoop Visual调试工具 AnyDesk 远程连接软件（感觉比较危险） Navicat Premium 数据库客户端 Robomongo Mongo客户端 LdapAdmin 免费Ldap客户端 Redis Desktop Manager redis客户端，支持Windows、Linux、Mac OS X。 飞鸽传书 局域网聊天软件 Atom 开源编辑器 Visual Studio Code 开源编辑器 sublime_text 代码编辑器 Typora 微信公众号排版工具 LICEcap GIF录屏软件 ShareX 功能强大的截屏录屏软件，支持上传云端 亿图图示 功能强大的图形设计软件 Beyond Compare 文件比较工具 自同步 P2P同步工具，支持Windows、MAC、Android。 Dukto R6 开源跨平台文件共享工具，支持Windows、Linux、Mac OS X和移动端 FileZilla Server(Client) 免费开源的FTP软件 FreeFileSync 开源的文件夹比较和同步软件。支持Windows、Linux、Mac OS X。 NitroShare 跨平台、开源的文件共享神器，支持Windows、Linux、Mac OS X。 syncthing 文件共享同步工具 ext2explore 读取Ext文件系统，其最新版本支持ext4。支持Windows10。 Ext2Fsd 供了Windows驱动级的ext支持，该软件可以写Ext3和不带extent的Ext4的分区。支持Windows10。 motrix 免费、开源跨平台下载工具 freedownloadmanager 免费、跨平台下载工具 推荐文章（由hexo文章推荐插件驱动）chrome经典插件]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Windows</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chrome经典插件]]></title>
    <url>%2F2017%2F08%2F05%2F00019_chrome%E7%BB%8F%E5%85%B8%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[table th:nth-of-type(2){width: 80%;} 插件名 描述 Copytables 快速选择表格中的行、列、单元格等信息复制 JSON Formatter/JSONiew json格式化输出 XML Tree xml格式化输出 LastPass: Free Password Manager 密码存储 Print Friendly &amp; PDF 网页打印工具 Host Switch Plus host快速切换工具 Website IP 显示访问站点的IP，一般结合Host Switch Plus一起使用 Proxy SwitchySharp 代理切换 OneTab 快速记录并存储当前正在打开的标签页 The Great Suspender 自动暂停使用标签来释放系统资源 Octotree GitHub侧边栏插件，便于浏览代码目录 Adblock Plus 屏蔽广告 New Tab Redirect 首页设置 Stylish 客户端自定义站点样式 Postman Web调试工具 推荐文章（由hexo文章推荐插件驱动）Windows小工具]]></content>
      <categories>
        <category>chrome</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>chrome插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell printf格式化输出]]></title>
    <url>%2F2017%2F08%2F05%2F00009_shell-printf%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%BE%93%E5%87%BA%2F</url>
    <content type="text"><![CDATA[shell也可以优雅的输出。 用法1printf: usage: printf [-v var] format [arguments] 参数常用格式控制符 table th:nth-of-type(2){width: 80%;} 格式符 说明 %s 字符串 %d,%i 十进制整数 %u 不带正负号的十进制值 %o 不带正负号的八进制值 %x 不带正负号的十六进制值，使用a至f表示10至15 %X 不带正负号的十六进制值，使用A至F表示10至15 %e,%E,%f 浮点格式 %g %e或%f转换，看哪一个较短，则删除结尾的零 %G %E或%f转换，看哪一个较短，则删除结尾的零 %b 相对应的参数被视为含有要被处理的转义序列之字符串 %c ASCII字符。显示相对应参数的第一个字符 %% 字面意义的% 常用转义序列 格式符 说明 \f 换页（formfeed） \n 换行 \r 回车（Carriage return） \t 水平制表符 \v 垂直制表符 \ 一个字面上的反斜杠字符 \ddd 表示1到3位数八进制值的字符，仅在格式字符串中有效 \0ddd 表示1到3位的八进制值字符 使用场景举例12345678910111213141516# cat printf.sh#!/bin/bashprintf &quot;%-20s\t%-30s\n&quot; &quot;格式符&quot; &quot;说明&quot;printf &quot;%-20s\t\033[33m%-30s\033[0m\n&quot; &apos;%s&apos; &apos;字符串&apos;printf &apos;%-20s\t%-30s\n&apos; &apos;%d&apos; &apos;十进制整数&apos;printf &quot;%-20s\t%-30s\n&quot; &quot;%u&quot; &apos;不带正负号的十进制值&apos;printf &quot;%-20s\t%-30s\n&quot; &quot;%o&quot; &quot;不带正负号的八进制值&quot;printf &quot;\033[32m%-20s\033[0m\t%-1.15f\n&quot; %f 3.14159265358# sh printf.sh格式符 说明%s 字符串%d 十进制整数%u 不带正负号的十进制值%o 不带正负号的八进制值%f 3.141592653580000 说明 默认printf没有换行，需要手动添加\n； %-20s指一个宽度为20的左对齐字符。如果不满20个字符则以空格填充，如超出20个字符也会显示所有内容； -表示左对齐，+或者空则表示右对齐； %-1.15f 格式化小数，其中.15指保留15位小数，不足位数补零； 在格式控制符和输出字符串中单引号与双引号效果相同，但是不能将所有的输出字符串用一个引起来，必须每个字段一对引号； 格式控制中也可以引入字体颜色。 推荐文章（由hexo文章推荐插件驱动）shell脚本传参shell的分批并发操作的简单实现常用shell命令总结Linux命令行环境下进行URL解码]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>printf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible copy模块和synchronize模块说明及比较]]></title>
    <url>%2F2017%2F08%2F03%2F00008_Ansible%E7%9A%84copy%E6%A8%A1%E5%9D%97%E5%92%8Csynchronize%E6%A8%A1%E5%9D%97%E8%AF%B4%E6%98%8E%E5%8F%8A%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[对文件的批量变更是运维自动化领域中很常见的需求之一.Ansible官方针对文件操作部分提供了很多模块,这里仅对最常用的copy和synchronize模块进行一个简单的比较。 copy模块常用参数列表 table th:nth-of-type(5){width: 70%;} 参数 是否必选字段 默认值 可选值 说明 backup no no yes/no 是否备份被修改的文件 src no 本地路径；可以是绝对路径也可以是相对路径。如果是目录，则递归地复制。此种情况下，类似于rsync，如果路径以“/”结尾，则只有该目录下的文件或子目录被复制。如果不以“/”结尾，则同时复制该目录。 content no 可使用content代替”SRC”，将文件的内容直接设置为指定的简单的值。对于任何复杂的或格式化的内容使用template模块。 dest yes 文件被复制到的远端服务器上的绝对路径。说明：如果src给定的是目录，dest也必须是目录 follow no no yes/no 保留软链属性(added in 1.8) force no yes yes/no 如果文件已存在，默认强制覆盖，如果设置为no,则只有当文件不存在时才会被传输 aliases: thirsty group no 文件或目录的所属用户组 mode no 文件或目录权限，用八进制数字表示，如0644，如果没有前置0可能出现异常 owner no 文件或目录的所属用户 remote_src no False True/False 如果是true，将从远端往远端服务，相当于在远端服务器上执行copy操作。如果为false，则从本地复制到远程，默认是false。remote_src不支持递归复制。(added in 2.0) 使用场景举例12345678910111213141516# ansible all -m copy -a &quot;src=/tmp/test.txt dest=/tmp/ backup=yes&quot; -i hosts192.168.0.1 | SUCCESS =&gt; &#123; &quot;backup_file&quot;: &quot;/tmp/test.txt.7587.2017-08-04@16:58:43~&quot;, &quot;changed&quot;: true, &quot;checksum&quot;: &quot;d961c3de6d6c99429806ae3d6d03f316a1168ac6&quot;, &quot;dest&quot;: &quot;/tmp/test.txt&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;7494ab07987ba112bd5c4f9857ccfb3f&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 5, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1501837122.86-21046238098569/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125; synchronize模块常用参数列表 参数 是否必选字段 默认值 可选值 说明 archive no yes yes/no 递归保留源目录中的软链、权限、时间戳、所属用户等属性 recursive no 选项archive的值 yes/no 目录递归 group no 选项archive的值 yes/no 指定所属用户组 owner no 选项archive的值 yes/no 指定所属用户 links no 选项archive的值 yes/no 保留软链接 perms no 选项archive的值 yes/no 保留权限设置 times no 选项archive的值 yes/no 保留时间戳 compress no yes yes/no 压缩传输，除非会导致异常，多数情况下建议开启(added in 1.7) copy_links no no yes/no 复制软链指向的内容而不是软链本身 delete no no yes/no 传输完成后，删除目标路径下，源目录中不存在的文件This option requires recursive=yes. src yes 源主机上的路径，可以是绝对路径也可以是相对路径 dest yes 目标主机上的存储路径。可以是绝对路径，也可以是相对路径。 dirs no no yes/no 不递归传输 existing_only no no yes/no 跳过目标端不存在的目录或文件(added in 1.5) mode no push push/pull 指定推送方式，拉取或者推送，默认是push模式，push模式下src是源，pull模式下dest是源 rsync_opts no 通过数组指定额外的rsync选项(added in 1.6) rsync_path no 指定远程主机上的rsync命令 rsync_timeout no 指定rsync的超时时间 set_remote_user no True 当远端服务器上自定义ssh配置文件中定义的remote user和inventory user不匹配的情况下，这个参数值设置为”no” use_ssh_args no no yes/no 使用ansible.cfg中指定的ssh_args参数(added in 2.0) verify_host no 验证目标主机的秘钥(added in 2.0) 使用场景举例 报错：”msg”: “Invalid shell type specified (bash), or the plugin for that shell type is missing.” 12345# ansible all -m synchronize -a &quot;src=/tmp/test.txt dest=/tmp/&quot; -i hosts192.168.0.1 | FAILED! =&gt; &#123; &quot;failed&quot;: true, &quot;msg&quot;: &quot;Invalid shell type specified (bash), or the plugin for that shell type is missing.&quot;&#125; 解决方案： 将ansible.cfg中的executable = /bin/bash注释掉12345678910# ansible all -m synchronize -a &quot;src=/tmp/test.txt dest=/tmp/&quot; -i hosts192.168.0.1 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;cmd&quot;: &quot;/usr/bin/rsync --delay-updates -F --compress --archive --rsh &apos;ssh -S none -o StrictHostKeyChecking=no&apos; --out-format=&apos;&lt;&lt;CHANGED&gt;&gt;%i %n%L&apos; \&quot;/tmp/test.txt\&quot; \&quot;rsync.test.monitor.zw.ted:/tmp/\&quot;&quot;, &quot;msg&quot;: &quot;&lt;f.st...... test.txt\n&quot;, &quot;rc&quot;: 0, &quot;stdout_lines&quot;: [ &quot;&lt;f.st...... test.txt&quot; ]&#125; push模式拉取文件 123456789101112131415# ansible all -m synchronize -a &quot;src=/tmp/test.txt dest=/tmp/ rsync_opts=&apos;-abvzP, --suffix=.bak-$(date &quot;+%Y-%m-%d_%H&quot;)&apos;&quot; -ihosts192.168.0.1 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;cmd&quot;: &quot;/usr/bin/rsync --delay-updates -F --compress --archive --rsh &apos;ssh -S none -o StrictHostKeyChecking=no&apos; -abvzP --suffix=.bak-2017-08-04_18 --out-format=&apos;&lt;&lt;CHANGED&gt;&gt;%i %n%L&apos; \&quot;/tmp/test.txt\&quot; \&quot;rsync.test.monitor.zw.ted:/tmp/\&quot;&quot;, &quot;msg&quot;: &quot;building file list ... \n 0 files...\r1 file to consider\n&lt;f..t...... test.txt\n 6 100% 0.00kB/s 0:00:00\r6 100% 0.00kB/s 0:00:00 (xfer#1, to-check=0/1)\n\nsent 79 bytes received 37 bytes 77.33 bytes/sec\ntotal size is 6 speedup is 0.05\n&quot;, &quot;rc&quot;: 0, &quot;stdout_lines&quot;: [ &quot;building file list ... &quot;, &quot; 0 files...\r1 file to consider&quot;, &quot;&lt;f..t...... test.txt&quot;, &quot; 6 100% 0.00kB/s 0:00:00\r 6 100% 0.00kB/s 0:00:00 (xfer#1, to-check=0/1)&quot;, &quot;sent 79 bytes received 37 bytes 77.33 bytes/sec&quot;, &quot;total size is 6 speedup is 0.05&quot; ]&#125; pull模式拉取文件 123456789101112131415161718# ansible all -m synchronize -a &quot;mode=pull src=/tmp/tmp1 dest=/tmp/ rsync_opts=&apos;-abvzP, --suffix=.bak-$(date &quot;+%Y-%m-%d_%H&quot;)&apos;&quot; -i hosts192.168.0.1 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;cmd&quot;: &quot;/usr/bin/rsync --delay-updates -F --compress --archive --rsh &apos;ssh -S none -o StrictHostKeyChecking=no&apos; -abvzP --suffix=.bak-2017-08-05_13 --out-format=&apos;&lt;&lt;CHANGED&gt;&gt;%i %n%L&apos; \&quot;rsync.test.monitor.zw.ted:/tmp/tmp1\&quot; \&quot;/tmp/\&quot;&quot;, &quot;msg&quot;: &quot;receiving file list ... \n4 files to consider\ncd+++++++++ tmp1/\ncd+++++++++ tmp1/tmp2/\ncd+++++++++ tmp1/tmp2/tmp3/\n&gt;f+++++++++ tmp1/tmp2/tmp3/test.log\n 0 0% 0.00kB/s 0:00:00\r 13 100% 12.70kB/s 0:00:00 (xfer#1, to-check=0/4)\n\nsent 73 bytes received 145 bytes 436.00 bytes/sec\ntotal size is 13 speedup is 0.06\n&quot;, &quot;rc&quot;: 0, &quot;stdout_lines&quot;: [ &quot;receiving file list ... &quot;, &quot;4 files to consider&quot;, &quot;cd+++++++++ tmp1/&quot;, &quot;cd+++++++++ tmp1/tmp2/&quot;, &quot;cd+++++++++ tmp1/tmp2/tmp3/&quot;, &quot;&gt;f+++++++++ tmp1/tmp2/tmp3/test.log&quot;, &quot; 0 0% 0.00kB/s 0:00:00\r 13 100% 12.70kB/s 0:00:00 (xfer#1, to-check=0/4)&quot;, &quot;sent 73 bytes received 145 bytes 436.00 bytes/sec&quot;, &quot;total size is 13 speedup is 0.06&quot; ]&#125; copy模块和synchronize模块的简单比较 copy模块不支持从远端到本地的拉去操作，fetch模块支持，但是src参数不支持目录递归，只能回传具体文件； copy模块的remote_src参数是指定从远端服务器上往远端服务器上复制，相当于在shell模块中执行copy命令； synchronize则支持文件下发和回传，分别对应的push和pull模式。synchronize模块的功能依赖于rsync.x86_64，但是功能不依赖于rsync配置文件中定义的模块； copy模块适用于小规模文件操作，synchronize支持大规模文件操作。 synchronize模块存在的缺陷 hosts文件(inventory)中中如果使用ansible_ssh_pass通过用户名密码认证，则在使用synchronize模块时由于模块使用的是独立的ssh通道因此会再次提示输入密码，在大规模文件下发场景中使用体验较差，可以考虑通过其它途径实现。]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>运维自动化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell的分批并发操作的简单实现]]></title>
    <url>%2F2017%2F08%2F02%2F00007_shell%E7%9A%84%E5%88%86%E6%89%B9%E5%B9%B6%E5%8F%91%E6%93%8D%E4%BD%9C%E7%9A%84%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[很多情况下，计算资源是有限的。我们需要在任务时长和资源消耗之前取得一种平衡。因此需要进行并发和控制。 示例一 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# cat packetConcurrency.sh#!/bin/bash# 并发数threads=3# 任务数tasks=9function task()&#123; r=$(( $RANDOM % 30 + 1 )) echo &quot;Start $1.&quot; sleep $r echo &quot;Finished $1,took $&#123;r&#125;s.&quot;&#125;counter=1for sn in $(seq 1 $&#123;tasks&#125;)do task $&#123;sn&#125; &amp; if [ &quot;$(($&#123;counter&#125; % $&#123;threads&#125;))&quot; -eq &quot;0&quot; ]; then time wait echo &quot;===================&quot; fi counter=$(($&#123;counter&#125; + 1))done#######################################################执行结果：# sh packetConcurrency.shStart 2.Start 3.Start 1.Finished 2,took 3s.Finished 1,took 14s.Finished 3,took 15s.real 0m15.014s #每一批任务的耗时和该批任务中耗时最长的任务消耗的时间一致。user 0m0.021ssys 0m0.059s===================Start 5.Start 6.Start 4.Finished 5,took 1s.Finished 6,took 22s.Finished 4,took 26s.real 0m26.065s #每一批任务的耗时和该批任务中耗时最长的任务消耗的时间一致。user 0m0.021ssys 0m0.050s===================Start 8.Start 9.Start 7.Finished 8,took 6s.Finished 7,took 9s.Finished 9,took 22s.real 0m22.101s #每一批任务的耗时和该批任务中耗时最长的任务消耗的时间一致。user 0m0.088ssys 0m0.099s=================== 示例二 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# cat groupExec.sh#!/bin/bashgroups=5tasks=20function groupExec()&#123;for group in $(seq 0 $(($&#123;groups&#125; - 1 )))do echo &quot;======第$(($&#123;group&#125; + 1))组开始：======&quot; for task in $(seq 0 $(($&#123;tasks&#125; - 1 ))) do if [ &quot;$(($&#123;task&#125; / $(($&#123;tasks&#125; / $&#123;groups&#125;))))&quot; -eq &quot;$&#123;group&#125;&quot; ]; then &#123; echo &quot;task:$(( $&#123;task&#125; + 1 ))&quot;;sleep $(($RANDOM % 10)); &#125; &amp; else continue fi done wait echo &quot;======第$(($&#123;group&#125; + 1))组完成。======&quot;done&#125;groupExec# sh groupExec.sh======第1组开始：======task:1task:4task:3task:2======第1组完成。============第2组开始：======task:5task:7task:8task:6======第2组完成。============第3组开始：======task:9task:11task:12task:10======第3组完成。============第4组开始：======task:15task:16task:13task:14======第4组完成。============第5组开始：======task:19task:17task:18task:20======第5组完成。====== 推荐文章（由hexo文章推荐插件驱动）shell脚本传参shell printf格式化输出常用shell命令总结Linux命令行环境下进行URL解码]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL常见的两种数据库引擎比较]]></title>
    <url>%2F2017%2F08%2F02%2F00022_MySQL%E5%B8%B8%E8%A7%81%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%95%E6%93%8E%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[MySQL有多种存储引擎：MyISAM、InnoDB、MERGE、MEMORY(HEAP)、BDB(BerkeleyDB)、EXAMPLE、FEDERATED、ARCHIVE、CSV、BLACKHOLE 等。 MyISAM&amp;InnoDB比较 table th:nth-of-type(2){width: 80%;} 引擎 特点 MyISAM MySQL的默认引擎；磁盘上存储成三个文件（ .frm:表定义,.MYD:数据文件，.MYI (MYIndex):索引文件）；不支持事务处理；不支持外键；支持全文检索（FULLTEXT）；自增长字段可以和其它字段一起建立联合索引；清空表操作是直接重建该表，效率高；表级锁，并发量较小，不适合大量update；缓存索引，查询数据相对较快，适合大量的select；索引和数据分开，索引有压缩，内存使用率高；表格可以被压缩； InnoDB 磁盘存两个文件InnoDB表空间数据文件、日志文件；支持事务处理；支持外键；不支持FULLTEXT类型的索引；对于自增长的字段，InnoDB中必须包含只有该字段的索引；清空整个表时，InnoDB是一行一行的删除，效率非常慢；支持行锁；并发量较大，适合大量update；不保存表的行数；如设置成默认引擎需在配置文件my.ini中指定default-storage-engine=INNODB 索引：是对数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息。索引有助于更快地获取信息。索引的一个主要目的就是加快检索表中数据的方法，也就是能协助信息搜索者尽快的找到符合限制条件的记录ID的辅助数据结构。 存储结构划分 聚簇索引：是按照数据存放的物理位置为顺序的，能提高多行检索的速度。 非聚簇索引：对于单行的检索很快。 功能划分 唯一索引：不允许其中任何两行具有相同索引值的索引。 主键索引：数据库表中一列或多列组合，其值唯一标识表中的的一行。在数据库关系图中为表定义主键将自动创建主键索引，主键索引是唯一索引的特定类型。该索引要求主键中的每个值都唯一。当在查询中使用主键索引时，它还允许对数据的快速访问。 聚集索引：在聚集索引中，表中行的物理顺序与键值的逻辑（索引）顺序相同。一个表只能包含一个聚集索引。如果某索引不是聚集索引，则表中行的物理顺序与键值的逻辑顺序不匹配。与非聚集索引相比，聚集索引通常提供更快的数据访问速度。 事务处理：事务是数据库运行中的逻辑工作单位。是指作为单个逻辑工作单元执行的一系列操作，要么完全地执行，要么完全地不执行。一个逻辑工作单元要成为事务，必须满足所谓的ACID（原子性、一致性、隔离性和持久性）属性。 原子性：一组事务，要么成功；要么撤回。 稳定性 ：有非法数据（外键约束之类），事务撤回。 隔离性：事务独立运行。一个事务处理后的结果，影响了其他事务，那么其他事务会撤回。事务的100%隔离，需要牺牲速度。 可靠性：软、硬件崩溃后，InnoDB数据表驱动会利用日志文件重构修改。可靠性和高速度不可兼得，innodb_flush_log_at_trx_commit 选项 决定什么时候吧事务保存到日志里。在 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作。因此要显式地开启一个事务务须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交。 参考 MySQL存储引擎InnoDB与Myisam的六大区别 MySQL 事务 数据库事务 推荐文章（由hexo文章推荐插件驱动）zabbix表分区优化]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell脚本传参]]></title>
    <url>%2F2017%2F08%2F01%2F00006_shell%E8%84%9A%E6%9C%AC%E4%BC%A0%E5%8F%82%2F</url>
    <content type="text"><![CDATA[shell脚本通常有三种传参方式： 手工处理 getopts getopt 手工处理方式 内置变量 $0 脚本文件名 $1—$9 穿入的第1—9个参数。第10个参数用${10}表示 $# 参数个数 $@ 参数列表 $* $$ 脚本进程1234567891011121314# cat test.sh#!/bin/bashn=0for parameter in $@do echo &quot;第$((++n))个参数值为:$&#123;parameter&#125;&quot;done# sh test.sh a b c d e第1个参数值为:a第2个参数值为:b第3个参数值为:c第4个参数值为:d第5个参数值为:e getopts getopts是由bash内置,不支持长参数选项，使用简单,不会重排所有参数的顺序。 参数说明：1234567所有选项参数必须写在其它参数的前面不支持长选项usage: getopts optstring name [arg]&quot;:&quot; 选项后面跟单个冒号表示该选项跟参数&quot;$OPTARG&quot; 内置变量，用于存放参数值&quot;$OPTIND&quot; 代表当前选项在参数列表中的位移。参数从1开始编号，getopts在处理参数的时候，处理一个开关型选项，OPTIND加1，处理一个带值的选项参数，OPTIND则会加2。 范例12345678910111213141516171819202122232425262728293031323334353637383940414243444546# cat getopts.sh#!/bin/bashwhile getopts &quot;a:b:cd&quot; argsdo echo -e &quot;\$args:$args \t\$OPTARG:$OPTARG\t\$OPTIND:$OPTIND&quot; case $args in a) echo &quot;$args&apos;s arg:$OPTARG,\$OPTIND:$OPTIND&quot; ;; b) echo &quot;$args&apos;s arg:$OPTARG,\$OPTIND:$OPTIND&quot; ;; c) echo &quot;$args&apos;s arg:$OPTARG,\$OPTIND:$OPTIND&quot; ;; d) echo &quot;$args&apos;s arg:$OPTARG,\$OPTIND:$OPTIND&quot; ;; #当遇到未定义的选项时args值为? #*) # echo &quot;$args&apos;s arg:$OPTARG,\$OPTIND:$OPTIND&quot; # exit 1 esacdone# 参数不被重新排序，当遇到不能被识别的参数&quot;3&quot;时，循环退出。# sh getopts.sh -a 1 -b 2 -c 3 -d 4$args:a $OPTARG:1 $OPTIND:3a&apos;s arg:1,$OPTIND:3$args:b $OPTARG:2 $OPTIND:5b&apos;s arg:2,$OPTIND:5$args:c $OPTARG: $OPTIND:6c&apos;s arg:,$OPTIND:6#参数合并# sh getopts.sh -a1 -b2 -cd$args:a $OPTARG:1 $OPTIND:2a&apos;s arg:1,$OPTIND:2$args:b $OPTARG:2 $OPTIND:3b&apos;s arg:2,$OPTIND:3$args:c $OPTARG: $OPTIND:3c&apos;s arg:,$OPTIND:3$args:d $OPTARG: $OPTIND:4d&apos;s arg:,$OPTIND:4 getopt getopt是独立的可执行文件 常用参数说明1234567891011121314−a, −−alternative 使getopt长参数支持&quot;-&quot;符号打头，必须与-l同时使用−l, −−longoptions 表示长选项，后面接getopt支持长参数列表，逗号分隔−n, −−name progname 如果getopt处理参数出错，返回错误提示−o, −−options shortopts 表示短选项，后面接短参数列表，这种用法与getopts类似。两个冒号表示该选项有一个可选参数，可选参数必须紧贴选项。−q, −−quiet 关闭错误输出−Q, −−quiet−output 关闭正常输出−s, −−shell shell 指定shell类型，&quot;sh&quot;,&quot;bash&quot;,&quot;csh&quot;,&quot;tcsh&quot;.−u, −−unquoted 不给参数列表加引号，默认是加引号的（不使用-u选项）−T, −−test 测试getopt是增强版或旧版，不生成输出。−V, −−version−h, −−help$@ 参数本身的列表，也不包括命令本身&quot;:&quot; 选项后面跟单个冒号表示该选项必须跟参数&quot;::&quot; 选项后面跟两个冒号表示该选项可以跟参数 范例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# cat getopt.sh#!/bin/bashOPTS=$(getopt -s bash -o x:y::z -a --long aaaa:,bbbb::,cccc -n &apos;warning&apos; -- &quot;$@&quot;)eval set -- &quot;$OPTS&quot;while true;do case &quot;$1&quot; in -x|--aaaa) echo -e &quot;Hit $1,arg=$2&quot; shift 2 ;; -y|--bbbb) echo -e &quot;Hit $1,arg=$2&quot; shift 2 ;; -z|--cccc) echo -e &quot;Hit $1,arg=$2&quot; shift ;; --) echo -e &quot;Hit $1,arg=$2&quot; shift; break ;; *) echo -e &quot;\nNo parameters were hit.\n&quot; break ;; esacdone## -cccc后没有冒号，实际执行中后面即使跟了参数也不会被接收# sh getopt.sh -aaaa 1 -bbbb=2 -cccc 3Hit --aaaa,arg=1Hit --bbbb,arg=2Hit --cccc,arg=--Hit --,arg=3## 长参数类型中，可选参数必须由等号连接选项和参数，空格隔开无法接收# sh getopt.sh -aaaa 1 -bbbb 2 -cccc 3Hit --aaaa,arg=1Hit --bbbb,arg=Hit --cccc,arg=--Hit --,arg=2# sh getopt.sh -x 1 -y 2 -zHit -x,arg=1Hit -y,arg=Hit -z,arg=--Hit --,arg=2## 在短选项参数中，可选参数可紧跟选项传参，长选项中不支持# sh getopt.sh -aaaa 1 -bbbb2 -cccc 3warning：无法识别的选项“-bbbb2”Hit --aaaa,arg=1Hit --cccc,arg=--Hit --,arg=3## sh getopt.sh -aaaa 1 -bbbb2 -cccc 3warning：无法识别的选项“-bbbb2”Hit --aaaa,arg=1Hit --cccc,arg=--Hit --,arg=3##如果没有参数的选项后跟了参数，且不是在参数列表的最后位置，会导致参数错乱# sh getopt.sh -cccc 1 -bbbb=2 -aaaa 3Hit --cccc,arg=--bbbbHit --bbbb,arg=2Hit --aaaa,arg=3Hit --,arg=1 推荐文章（由hexo文章推荐插件驱动）shell的分批并发操作的简单实现shell printf格式化输出常用shell命令总结Linux命令行环境下进行URL解码]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>传参</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[curl命令使用范例]]></title>
    <url>%2F2017%2F07%2F31%2F00005_curl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%E8%8C%83%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[curl常用参数： table th:nth-of-type(1){width: 15%;} nth-of-type(2){width: 85%;} 参数 说明 -A/–user-agent 定义用户代理字符串 -H/–header 自定义header头信息 -i/–include 输出时包括protocol头信息 -I/–head 只显示请求的头信息 -o/–output 把输出写到该文件中 -s/–silent 静默模式 -w/–write-out [format] 在一次完整且成功的操作后输出指定格式的内容到标准输出 -X/–request 指定请求方式 -u/–user 设置服务器的用户和密码 -T/–upload-file 上传文件 -l/–list-only 列出ftp目录下的文件名称 –limit-rate 设置传输速度 -m/–max-time 设置最大传输时间 常用范例(纯shell命令)： 伪造UA绑host请求: 1curl --user-agent &quot;curl-test-agent&quot; -H &quot;Host:www.lengyuewusheng.com&quot; -I &quot;http://10.0.0.1/index.php&quot; 伪造X-Real-IP： 1curl -H &quot;X-Real-IP:1.1.1.1&quot; -H &quot;Host:www.lengyuwusheng.com&quot; &quot;http://10.0.0.1/index.php&quot; 获取请求的状态码字符串 1curl -o /dev/null -s -w &quot;%&#123;http_code&#125;\n&quot; -H &quot;Host:www.lengyuewusheng.com&quot; &quot;http://10.0.0.1/index.php&quot; 向服务器端POST数据 1curl -X POST -d &quot;a=1&amp;b=2&amp;c=3&quot; &quot;http://www.lengyuewusheng.com&quot; 指定请求的超时时间 1curl --connect-timeout 5 -m 90 -o /dev/null -s -w &quot;%&#123;http_code&#125;&quot; &quot;http://www.lengyuewusheng.com&quot; 通过curl向ftp服务器上传文件 12curl -u &quot;$&#123;USER&#125;:$&#123;PASSWD&#125;&quot; -T &quot;$&#123;DATADIR&#125;/$&#123;FILE&#125;&quot; &quot;ftp://$&#123;FTPSERVER&#125;&quot;# eg: curl -u &quot;admin:123456&quot; -T &quot;/tmp/logs/test.log&quot; &quot;ftp://10.0.0.1&quot;]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx部分常用内置变量]]></title>
    <url>%2F2017%2F07%2F29%2F00004_nginx%E9%83%A8%E5%88%86%E5%B8%B8%E7%94%A8%E5%86%85%E7%BD%AE%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[table th:nth-of-type(1){width: 15%;} nth-of-type(2){width: 45%;} nth-of-type(3){width: 40%;} 变量名 说明 备注 $host 请求中的主机头(Host)字段 如果请求中的主机头不可用或为空，则为处理请求的server名称(处理请求的server的server_name指令的值)。值为小写，不包含端口。 $server_name 服务器名称 nginx conf文件Server模块中定义的值 $server_port 服务器端的端口号 eg: 80、8080、443 $remote_port 客户端的端口 $remote_addr 客户端的IP地址 $$binary_remote_addr 二进制码形式的客户端地址 $document_root 当前请求在root指令中指定的值 $scheme 协议 eg: http、https $cookie_COOKIE cookie中COOKIE的值 eg: $cookie_iploc $http_HEADER 匹配任意请求头字段 “HEADER”可以替换成任意请求头字段，如在配置文件中需要获取http请求头：“Accept-Language”，那么将“－”替换为下划线，大写字母替换为小写，形如：$http_accept_language即可。 $sent_http_HEADER HTTP响应头中的内容，HEADER为HTTP响应中的内容转为小写，-变为_(破折号变为下划线) eg: $sent_http_cache_control、$sent_http_content_type $request_uri 请求参数的原始URI 无法修改，请查看$uri更改或重写URI $uri 请求中的当前URI(不带请求参数，参数位于$args) 不同于浏览器传递的$request_uri的值，它可以通过内部重定向，或者使用index指令进行修改。不包括协议和主机名，例如/foo/bar.html $document_uri 与$uri相同 $args GET请求中的参数 eg: foo=123&amp;bar=abc; $arg_name 请求中参数name的值 $query_string 与$args相同 $arg_PARAMETER GET请求中变量名PARAMETER参数的值 $http_referer 引导用户代理到当前页的前一页的地址信息 $http_x_forwarded-for 表示 HTTP 请求端真实 IP X-Forwarded-For格式：X-Forwarded-For: client, proxy1, proxy2XFF的内容由「英文逗号+空格」隔开的多个部分组成，第一个IP是离服务端最远的设备IP，然后是每一级代理的IP 通常情况下：$request_uri=$document_uri($uri)+$query_string($args) eg: http://localhost:8080/test1/test2/index.php?a=1&amp;b=2&amp;c=3123456789&gt;$server_port：8080&gt;$request_uri：/test1/test2/index.php?a=1&amp;b=2&amp;c=3&gt;$document_uri：/test1/test2/index.php&gt;$query_string: a=1&amp;b=2&amp;c=3&gt;$uri: /test1/test2/index.php&gt;$args: a=1&amp;b=2&amp;c=3&gt;$document_root：/usr/local/nginx/html&gt;$request_filename：/usr/local/nginx/html/test1/test2/index.php&gt;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DOS常用命令总结]]></title>
    <url>%2F2017%2F07%2F28%2F00003_DOS%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[查看历史命令（快捷键：F7） 1doskey /history 查看端口 1netstat -ano|findstr &quot;80&quot; 查看进程PID 1234tasklist# /s computer 制定远程计算机名称或IP# /u domain\user 指定用户# /p password 指定用户密码 查看进程PID 1234567taskkill# /s computer 制定远程计算机名称或IP# /u domain\user 指定用户# /p password 指定用户密码# /pid ProcessID 被终止进程的ID# /f 强制终止。远程进程可忽略此参数，所有远程进程都会被强制终止# /t 终止与父进程的所有子进程 自动关机 1234567shutdown# /m \\ComputerName 关闭远程机器# /l 注销当前用户# /s 关机# /r 重启# /f 强制关闭应用程序# /c &quot;comment&quot; 操作说明 文件系统转换 12convert D: /fs:ntfs /x# /x 强制卸除卷标 磁盘检查 1234chkdsk C: /X /R /F# /X 如果必要，则先强制卸除卷。# /R 查找坏扇区并恢复可读信息# /F 修复磁盘上的错误。 修改文件属性 1234567891011121314attrib [+R|-R] [+A|-A] [+S|-S] [+H|-H] [+I|-I] [drive:][path][filename] [/S [/D] [/L]]# + 设置属性。# - 清除属性。# R 只读文件属性。# A 存档文件属性。# S 系统文件属性。# H 隐藏文件属性。# I 无内容索引文件属性。# X 无清理文件属性。# V 完整性属性。# [drive:][path][filename]指定 attrib 要处理的文件# /S 处理当前文件夹及其所有子文件夹中的匹配文件# /D 也处理文件夹。# /L 处理符号链接和符号链接目标的属性 内网主机名IP互查 123456根据IP查主机名nbtstat -A IPping -a IP根据主机名查IPnbtstat -a 主机名ping 主机名 组策略 123456打开组策略gpedit.msc强制刷新组策略gpupdate /force仅刷新用户策略gpupdate /target:user 一般如果所有配置都正确的情况下，Mac远程桌面Windows依然连不上，就强制刷新一下组策略有可能会出现奇迹。。。 help 12help [command]# 提供 Windows 命令的帮助信息。 推荐文章（由hexo文章推荐插件驱动）Linux挂载Windows共享目录]]></content>
      <categories>
        <category>DOS</category>
      </categories>
      <tags>
        <tag>DOS</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo(Next)+GitHub Pages搭建开源博客]]></title>
    <url>%2F2017%2F07%2F28%2F00002_hexo-Next-GitHub-Pages%E6%90%AD%E5%BB%BA%E5%BC%80%E6%BA%90%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[node环境 略 初始化1234npm install hexo-cli -ghexo init MyBlogcd MyBlognpm install 安装主题1git clone https://github.com/iissnan/hexo-theme-next.git themes/next 创建页面123hexo new page &quot;tags&quot;hexo new page categorieshexo new page &quot;about&quot; 安装插件1234567891011121314151617181920212223242526npm install --save hexo-servernpm install --save hexo-wordcountnpm install --save hexo-asset-imagenpm install --save hexo-generator-tagnpm install --save hexo-generator-feednpm install --save hexo-generator-indexnpm install --save hexo-generator-archivenpm install --save hexo-generator-categorynpm install --save hexo-generator-searchnpm install --save hexo-generator-searchdbnpm install --save hexo-generator-sitemapnpm install --save hexo-generator-baidu-sitemapnpm install --save hexo-generator-seo-friendly-sitemap# npm install --save hexo-filter-indicate-the-source# 压缩npm install --save hexo-uglifynpm install --save hexo-imagemin # 安装报错 19npm install --save hexo-clean-cssnpm install --save hexo-html-minifier # 安装报错 2# 发布npm install --save hexo-deployer-gitnpm install --save hexo-deployer-rsyncnpm install --save gulp-minify-css gulp-uglify gulp-htmlmin gulp-htmlclean gulp # 其它插件npm install --save hexo-recommended-posts 常用命令1234567891011121314151617181920# 清空缓存hexo clean# 创建草稿hexo new draft &quot;My first Blog&quot;# 将草稿发布成文章hexo publish &quot;My first Blog&quot;# 直接创建文章hexo new &quot;My second Blog&quot;# 生成静态文件并部署网站hexo generate(g) --deploy( -d)# 启动本地服务hexo server -i 10.0.0.1 -p 80 -l# 获取推荐文章列表，前提是已安装hexo-recommended-posts插件hexo recommend 优化首页博客间距调整 123&gt; hexo-theme-next\source\css\_schemes\Mist\_posts-expanded.styl&gt; .post &#123; margin-top: 60px; &#125;&gt; 自定义内容区域的宽度 123456&gt; hexo-theme-next\source\css\_variables\custom.styl&gt; $content-desktop = 700px&gt; $content-desktop-large = 900px&gt; # 此方法不适用于 Pisces Scheme&gt; # 移动设备下，宽度自适应&gt; 替换文章标签图标 themes/hexo-theme-next-6.7.0/layout/_macro/post.swig 1234将rel=&quot;tag&quot;&gt;#替换为rel=&quot;tag&quot;&gt;&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt; 自定义样式优化 themes\hexo-theme-next-6.7.0\source\css_custom\custom.styl 追加 12345678910111213141516171819202122232425262728293031323334353637383940414243// 主页文章添加阴影效果.post &#123; margin-top: 2%; margin-bottom: 5%; padding: 1%; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);&#125;.main-inner &#123; margin-top: 2%; padding: 2% 2% 2% 2%; background: #fff; min-height: 95%;&#125;.footer &#123; margin-top: 1%;&#125;// 自动更新背景图片body &#123; background: url(https://source.unsplash.com/random/1600x900); background-repeat: no-repeat; background-attachment:fixed; background-size: cover; background-position:50% 50%;&#125;// 修改博客页面宽度.container .main-inner &#123; width: 85%;&#125;// 优化修改博客标题位置.posts-expand .post &#123; margin-top: 3%;&#125;// 优化标题字体大写.menu .menu-item a, .menu .menu-item span.exturl &#123; font-size: 16px;&#125; 公益404页面优化404效果 在source目录下创建404.html 12345678910111213&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8;&quot;/&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge,chrome=1&quot; /&gt; &lt;meta name=&quot;robots&quot; content=&quot;all&quot; /&gt; &lt;meta name=&quot;robots&quot; content=&quot;index,follow&quot;/&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://qzone.qq.com/gy/404/style/404style.css&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;//qzonestyle.gtimg.cn/qzone/hybrid/app/404/search_children.js&quot; charset=&quot;utf-8&quot; homePageUrl=&quot;https://www.lengyuewusheng.com&quot; homePageName=&quot;回到 www.lengyuewusheng.com&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 测试只有在发布到github pages上才生效，本地测试无法直接跳转。 文章结尾增加版权声明 themes/hexo-theme-next-6.7.0/layout/_macro/ 目录下创建 my-copyright.swig 123456789101112131415161718192021222324252627282930313233&#123;% if page.copyright %&#125;&lt;div class=&quot;my_post_copyright&quot;&gt; &lt;script src=&quot;//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js&quot;&gt;&lt;/script&gt; &lt;!-- JS库 sweetalert 可修改路径 --&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;http://jslibs.wuxubj.cn/sweetalert_mini/jquery-1.7.1.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.min.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.mini.css&quot;&gt; &lt;p&gt;&lt;span&gt;本文标题:&lt;/span&gt;&lt;a href=&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot;&gt;&#123;&#123; page.title &#125;&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;文章作者:&lt;/span&gt;&lt;a href=&quot;/&quot; title=&quot;访问 &#123;&#123; theme.author &#125;&#125; 的个人博客&quot;&gt;&#123;&#123; theme.author &#125;&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;发布时间:&lt;/span&gt;&#123;&#123; page.date.format(&quot;YYYY年MM月DD日 - HH:MM&quot;) &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;span&gt;最后更新:&lt;/span&gt;&#123;&#123; page.updated.format(&quot;YYYY年MM月DD日 - HH:MM&quot;) &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;span&gt;原始链接:&lt;/span&gt;&lt;a href=&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot; title=&quot;&#123;&#123; page.title &#125;&#125;&quot;&gt;&#123;&#123; page.permalink &#125;&#125;&lt;/a&gt; &lt;span class=&quot;copy-path&quot; title=&quot;点击复制文章链接&quot;&gt;&lt;i class=&quot;fa fa-clipboard&quot; data-clipboard-text=&quot;&#123;&#123; page.permalink &#125;&#125;&quot; aria-label=&quot;复制成功！&quot;&gt;&lt;/i&gt;&lt;/span&gt; &lt;/p&gt; &lt;!-- p&gt;&lt;span&gt;许可协议:&lt;/span&gt;&lt;i class=&quot;fa fa-creative-commons&quot;&gt;&lt;/i&gt; &lt;a rel=&quot;license&quot; href=&quot;https://creativecommons.org/licenses/by-nc-nd/4.0/&quot; target=&quot;_blank&quot; title=&quot;Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)&quot;&gt;署名-非商业性使用-禁止演绎 4.0 国际&lt;/a&gt; 转载请保留原文链接及作者。&lt;/p --&gt; &lt;p&gt;&lt;span&gt;许可协议:&lt;/span&gt;本博客所有文章除特别声明外，均采用&lt;i class=&quot;fa fa-creative-commons&quot;&gt;&lt;/i&gt;&lt;a href=&quot;https://creativecommons.org/licenses/by-nc-sa/3.0/&quot; rel=&quot;external nofollow&quot; target=&quot;_blank&quot;&gt; BY-NC-SA 3.0&lt;/a&gt;许可协议。转载请注明出处！&lt;/p&gt;&lt;/div&gt;&lt;script&gt; var clipboard = new Clipboard(&apos;.fa-clipboard&apos;); clipboard.on(&apos;success&apos;, $(function()&#123; $(&quot;.fa-clipboard&quot;).click(function()&#123; swal(&#123; title: &quot;&quot;, text: &apos;复制成功&apos;, html: false, timer: 500, showConfirmButton: false &#125;); &#125;); &#125;));&lt;/script&gt;&#123;% endif %&#125; themes/hexo-theme-next-6.7.0/source/css/_common/components/post/ 目录下创建 my-post-copyright.styl 123456789101112131415161718192021222324252627282930313233343536373839404142434445.my_post_copyright &#123; width: 85%; max-width: 45em; margin: 2.8em auto 0; padding: 0.5em 1.0em; border: 1px solid #d3d3d3; font-size: 0.93rem; line-height: 1.6em; word-break: break-all; background: rgba(255,255,255,0.4);&#125;.my_post_copyright p&#123;margin:0;&#125;.my_post_copyright span &#123; display: inline-block; width: 5.2em; color: #b5b5b5; font-weight: bold;&#125;.my_post_copyright .raw &#123; margin-left: 1em; width: 5em;&#125;.my_post_copyright a &#123; color: #808080; border-bottom:0;&#125;.my_post_copyright a:hover &#123; color: #a3d2a3; text-decoration: underline;&#125;.my_post_copyright:hover .fa-clipboard &#123; color: #000;&#125;.my_post_copyright .post-url:hover &#123; font-weight: normal;&#125;.my_post_copyright .copy-path &#123; margin-left: 1em; width: 1em; +mobile()&#123;display:none;&#125;&#125;.my_post_copyright .copy-path:hover &#123; color: #808080; cursor: pointer;&#125; 修改 themes/hexo-theme-next-6.7.0/layout/_macro/post.swig 12345678910111213141516 &#123;% if theme.wechat_subscriber.enabled and not is_index %&#125; &lt;div&gt; &#123;% include &apos;../_partials/post/wechat-subscriber.swig&apos; %&#125; &lt;/div&gt; &#123;% endif %&#125;#========在include ../_partials/post/wechat-subscriber.swig逻辑下追加以下内容============= &lt;div&gt; &#123;% if not is_index %&#125; &#123;% include &apos;passage-end-tag.swig&apos; %&#125; &#123;% endif %&#125; &lt;/div&gt; &lt;div&gt; &#123;% if not is_index %&#125; &#123;% include &apos;my-copyright.swig&apos; %&#125; &#123;% endif %&#125; &lt;/div&gt; themes/hexo-theme-next-6.7.0/source/css/_common/components/post/post.styl追加一行 1@import &quot;my-post-copyright&quot; themes/hexo-theme-next-6.7.0/layout/_macro/ 目录下新建 passage-end-tag.swig 12345&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style=&quot;text-align:center;color: #ccc;font-size:14px;&quot;&gt;-------------End of article. &lt;i class=&quot;fa fa-paw&quot;&gt;&lt;/i&gt; I appreciate whoever read and leave commends on articles.-------------&lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt; themes/hexo-theme-next-6.7.0/_config.yml中追加 12passage_end_tag: enabled: true 博客文章头中声明copyright 123---copyright: true--- 定制草稿模板 修改lengyuewusheng.com/scaffolds/draft.md 123456789101112131415161718192021---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags:---categories:-copyright: truekeywords: Blog,lengyuewushengdescription: Describe briefly.---&#123;% cq %&#125;摘要内容&#123;% endcq %&#125;&lt;!--more--&gt;正文 常见问题生成发布时报错，几乎没有有效信息。。。 报错内容： 123H:\hexo-Blog&gt;hexo g -dINFO Start processingFATAL Something&apos;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html 处理方案： 此种情况大概率是由于你的博客的Markdown文件中存在非表格格式的竖线或其它Markdown难以解析的符号导致，如果存在竖线，将竖线用&amp;#124替换，如果存在其它特殊符号将符号删除即可。 hexo generate 执行报错 报错内容: 12345678910111213141516171819202122232425262728H:\hexo-Blog&gt;hexo gINFO Start processingINFO Files loaded in 1.97 sINFO Generated: baidusitemap.xmlERROR Asset render failed: lib/canvas-ribbon/canvas-ribbon.jsSyntaxError: Unexpected token: operator (&gt;) at JS_Parse_Error.get (eval at &lt;anonymous&gt; (H:\hexo-Blog\node_modules\hexo-uglify\node_modules\uglify-js\tools\node.js:27:1), &lt;anonymous&gt;:86:23) at getFullErrorStack (H:\hexo-Blog\node_modules\hexo-bunyan\lib\bunyan.js:1129:18) at Object.Logger.stdSerializers.err (H:\hexo-Blog\node_modules\hexo-bunyan\lib\bunyan.js:1147:16) at H:\hexo-Blog\node_modules\hexo-bunyan\lib\bunyan.js:873:50 at Array.forEach (&lt;anonymous&gt;) at Logger._applySerializers (H:\hexo-Blog\node_modules\hexo-bunyan\lib\bunyan.js:865:35) at mkRecord (H:\hexo-Blog\node_modules\hexo-bunyan\lib\bunyan.js:978:17) at Logger.&lt;anonymous&gt; (H:\hexo-Blog\node_modules\hexo-bunyan\lib\bunyan.js:1044:19) at self.render.render.catch.err (H:\hexo-Blog\node_modules\hexo\lib\plugins\generator\asset.js:33:20) at tryCatcher (H:\hexo-Blog\node_modules\bluebird\js\release\util.js:16:23) at Promise._settlePromiseFromHandler (H:\hexo-Blog\node_modules\bluebird\js\release\promise.js:512:31) at Promise._settlePromise (H:\hexo-Blog\node_modules\bluebird\js\release\promise.js:569:18) at Promise._settlePromise0 (H:\hexo-Blog\node_modules\bluebird\js\release\promise.js:614:10) at Promise._settlePromises (H:\hexo-Blog\node_modules\bluebird\js\release\promise.js:689:18) at Async._drainQueue (H:\hexo-Blog\node_modules\bluebird\js\release\async.js:133:16) at Async._drainQueues (H:\hexo-Blog\node_modules\bluebird\js\release\async.js:143:10) at Immediate.Async.drainQueues (H:\hexo-Blog\node_modules\bluebird\js\release\async.js:17:14) at runCallback (timers.js:789:20) at tryOnImmediate (timers.js:751:5) at processImmediate [as _immediateCallback] (timers.js:722:5)INFO Generated: atom.xmlINFO Generated: search.xml 处理方案: 1npm uninstall hexo-uglify uglify uglify-js 报错内容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455ERROR path.substring is not a functionTypeError: path.substring is not a function at Object.urlForHelper (H:\hexo-Blog\node_modules\hexo\lib\plugins\helper\url_for.js:9:31) at wrapper (H:\hexo-Blog\node_modules\lodash\lodash.js:4941:19) at Object.eval [as tpl] (eval at precompile (H:\hexo-Blog\node_modules\swig-templates\lib\swig.js:497:13), &lt;anonymous&gt;:125:119) at compiled (H:\hexo-Blog\node_modules\swig-templates\lib\swig.js:618:18) at Object.eval [as tpl] (eval at precompile (H:\hexo-Blog\node_modules\swig-templates\lib\swig.js:497:13), &lt;anonymous&gt;:263:126) at compiled (H:\hexo-Blog\node_modules\swig-templates\lib\swig.js:618:18) at Theme._View.View._compiled (H:\hexo-Blog\node_modules\hexo\lib\theme\view.js:127:30) at Theme._View.View.View.render (H:\hexo-Blog\node_modules\hexo\lib\theme\view.js:29:15) at H:\hexo-Blog\node_modules\hexo\lib\hexo\index.js:390:29 at tryCatcher (H:\hexo-Blog\node_modules\bluebird\js\release\util.js:16:23) at H:\hexo-Blog\node_modules\bluebird\js\release\method.js:15:34 at RouteStream._read (H:\hexo-Blog\node_modules\hexo\lib\hexo\router.js:134:3) at RouteStream.Readable.read (_stream_readable.js:442:10) at resume_ (_stream_readable.js:822:12) at _combinedTickCallback (internal/process/next_tick.js:138:11) at process._tickCallback (internal/process/next_tick.js:180:9)ERROR path.substring is not a functionTypeError: path.substring is not a function at Object.urlForHelper (H:\hexo-Blog\node_modules\hexo\lib\plugins\helper\url_for.js:9:31) at wrapper (H:\hexo-Blog\node_modules\lodash\lodash.js:4941:19) at Object.eval [as tpl] (eval at precompile (H:\hexo-Blog\node_modules\swig-templates\lib\swig.js:497:13), &lt;anonymous&gt;:125:119) at compiled (H:\hexo-Blog\node_modules\swig-templates\lib\swig.js:618:18) at Object.eval [as tpl] (eval at precompile (H:\hexo-Blog\node_modules\swig-templates\lib\swig.js:497:13), &lt;anonymous&gt;:263:126) at compiled (H:\hexo-Blog\node_modules\swig-templates\lib\swig.js:618:18) at Theme._View.View._compiled (H:\hexo-Blog\node_modules\hexo\lib\theme\view.js:127:30) at Theme._View.View.View.render (H:\hexo-Blog\node_modules\hexo\lib\theme\view.js:29:15) at H:\hexo-Blog\node_modules\hexo\lib\hexo\index.js:390:29 at tryCatcher (H:\hexo-Blog\node_modules\bluebird\js\release\util.js:16:23) at H:\hexo-Blog\node_modules\bluebird\js\release\method.js:15:34 at RouteStream._read (H:\hexo-Blog\node_modules\hexo\lib\hexo\router.js:134:3) at RouteStream.Readable.read (_stream_readable.js:442:10) at resume_ (_stream_readable.js:822:12) at _combinedTickCallback (internal/process/next_tick.js:138:11) at process._tickCallback (internal/process/next_tick.js:180:9)ERROR path.substring is not a functionTypeError: path.substring is not a function at Object.urlForHelper (H:\hexo-Blog\node_modules\hexo\lib\plugins\helper\url_for.js:9:31) at wrapper (H:\hexo-Blog\node_modules\lodash\lodash.js:4941:19) at Object.eval [as tpl] (eval at precompile (H:\hexo-Blog\node_modules\swig-templates\lib\swig.js:497:13), &lt;anonymous&gt;:125:119) at compiled (H:\hexo-Blog\node_modules\swig-templates\lib\swig.js:618:18) at Object.eval [as tpl] (eval at precompile (H:\hexo-Blog\node_modules\swig-templates\lib\swig.js:497:13), &lt;anonymous&gt;:263:126) at compiled (H:\hexo-Blog\node_modules\swig-templates\lib\swig.js:618:18) at Theme._View.View._compiled (H:\hexo-Blog\node_modules\hexo\lib\theme\view.js:127:30) at Theme._View.View.View.render (H:\hexo-Blog\node_modules\hexo\lib\theme\view.js:29:15) at H:\hexo-Blog\node_modules\hexo\lib\hexo\index.js:390:29 at tryCatcher (H:\hexo-Blog\node_modules\bluebird\js\release\util.js:16:23) at H:\hexo-Blog\node_modules\bluebird\js\release\method.js:15:34 at RouteStream._read (H:\hexo-Blog\node_modules\hexo\lib\hexo\router.js:134:3) at RouteStream.Readable.read (_stream_readable.js:442:10) at resume_ (_stream_readable.js:822:12) at _combinedTickCallback (internal/process/next_tick.js:138:11) at process._tickCallback (internal/process/next_tick.js:180:9) ...... 处理方案： 1该问题是在升级Next v5.1.4时出现，首先将Next回滚，然后将本地的node_modules文件夹删除，同时删除package-lock.json，重新执行`npm install`生成node_modules目录后恢复。 hexo deploy 执行报错 报错内容： 1234567891011121314151617181920fatal: HttpRequestException encountered. ��������ʱ�����bash: /dev/tty: No such device or addresserror: failed to execute prompt script (exit code 1)fatal: could not read Username for &apos;https://github.com&apos;: No errorFATAL Something&apos;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.htmlError: fatal: HttpRequestException encountered. ��������ʱ����bash: /dev/tty: No such device or addresserror: failed to execute prompt script (exit code 1)fatal: could not read Username for &apos;https://github.com&apos;: No error at ChildProcess.&lt;anonymous&gt; (H:\hexo-Blog\node_modules\hexo-util\lib\spawn.js:37:17) at emitTwo (events.js:126:13) at ChildProcess.emit (events.js:214:7) at ChildProcess.cp.emit (H:\hexo-Blog\node_modules\cross-spawn\lib\enoent.js:40:29) at maybeClose (internal/child_process.js:925:16) at Process.ChildProcess._handle.onexit (internal/child_process.js:209:5)H:\hexo-Blog&gt; 处理方案： 1这种问题可能是因为本地git环境被破坏导致，重装或升级一下本地git即可解决问题。 参考文档 官方文档 NEXT官方文档 NEXT Wiki hexo搭建静态博客 推酷·hexo 利用Hexo在Github Page上部署个人博客]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开张之作]]></title>
    <url>%2F2017%2F07%2F28%2F00001_%E5%BC%80%E5%BC%A0%E4%B9%8B%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[不得不说，想做成一件事情真的很难。 酝酿三年，筹备半年，将近一个月的紧密实施，博客终于赶在今天悄然上线了。 不得不说，做任何事情只要肯走心，一定能够做成，如果没成，那就再花点心思。 在这个自媒体泛滥的时代，碎片化的知识无处不在， 然而我并不励志做一个媒体人，我只是希望把日常的进步积累下来， 蹉跎岁月中最后能留下点自己亲手创造的价值。 还记得QQ空间刚火起来的那些年，每隔几个月都会挤时间跑到网吧里就为了写一篇博客， 后来变成了每到寒暑假写一篇总结，再到后来每到年末回首过去展望未来写一篇， 再后来我就变得不会写字了，如今算起来已经三四年没有认真写过东西了。 从今天起，做一个爱学习爱总结的人，借助博客督促自己多读书，多学习，多努力。 如果在自己进步的同时，无意中也帮到了你，这也算是一件让人开心的事儿了。 已经很晚了，再不睡觉天都要亮了，今天就写到这儿吧，来日方长，积水成渊吧！]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
</search>
